{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IPS Chalenge.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "B9bhSJpcv1Bl"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29a28c1266a04c4e922b3d60a4944d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_156f2ae981ef4d7ebd25498992d5b0b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_585fdae73a2543a982585dcce2abd8cc",
              "IPY_MODEL_6aa73dac5a5d4b378fbc6fb85ace359f"
            ]
          }
        },
        "156f2ae981ef4d7ebd25498992d5b0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "585fdae73a2543a982585dcce2abd8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98d0af351cf14c5495014ec2ff16fddf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8520475d2cdb4dbeb45d00dd04923d32"
          }
        },
        "6aa73dac5a5d4b378fbc6fb85ace359f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c38089ea58b4bb786bc12d01f1b449d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.44MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5f9d19f7cc142be9632c39433c7cced"
          }
        },
        "98d0af351cf14c5495014ec2ff16fddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8520475d2cdb4dbeb45d00dd04923d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c38089ea58b4bb786bc12d01f1b449d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5f9d19f7cc142be9632c39433c7cced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dcf1dfccc254e1e900ed8945039d40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db556fb4b0fa453eaa7862866b0dca27",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e14436e332746f983bd73587443767e",
              "IPY_MODEL_cde5cb1ad1c74adf9d0105a764000a56"
            ]
          }
        },
        "db556fb4b0fa453eaa7862866b0dca27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e14436e332746f983bd73587443767e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53e70d62f8474c0f98435f402b58e7b8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 546,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 546,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80acc8301fa74933a352ddb0f00743d5"
          }
        },
        "cde5cb1ad1c74adf9d0105a764000a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc32e1dc9406445ab082d756c644e2d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 546/546 [00:05&lt;00:00, 103B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b756aa2579ee4f69af5a284d12ea626c"
          }
        },
        "53e70d62f8474c0f98435f402b58e7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80acc8301fa74933a352ddb0f00743d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc32e1dc9406445ab082d756c644e2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b756aa2579ee4f69af5a284d12ea626c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c8f1ae228ef4f258907359ecc1fc15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1491c5868cc94e548390666ae86a38c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5506922aab842eda17079bf536d47d5",
              "IPY_MODEL_dcb77094648d44f484976ea36fbc843f"
            ]
          }
        },
        "1491c5868cc94e548390666ae86a38c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5506922aab842eda17079bf536d47d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d4e8be24bc94f6bb8e404e4cbdc1518",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f439c9c57bc42b39c6941755bb05850"
          }
        },
        "dcb77094648d44f484976ea36fbc843f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2886778ec814a9eaa87e0211f33f516",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:04&lt;00:00, 57.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68cb45f5a7b54112bff4e175f0d105e8"
          }
        },
        "1d4e8be24bc94f6bb8e404e4cbdc1518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f439c9c57bc42b39c6941755bb05850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2886778ec814a9eaa87e0211f33f516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68cb45f5a7b54112bff4e175f0d105e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/IPS_Chalenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izA3-6kffbdT",
        "colab_type": "text"
      },
      "source": [
        "# A Visual Notebook to Using BERT for the First TIme.ipynb\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-sentence-classification.png\" />\n",
        "\n",
        "In this notebook, we will use pre-trained deep learning model to process some text. We will then use the output of that model to classify the text. The text is a list of sentences from film reviews. And we will calssify each sentence as either speaking \"positively\" about its subject of \"negatively\".\n",
        "\n",
        "## Models: Sentence Sentiment Classification\n",
        "Our goal is to create a model that takes a sentence (just like the ones in our dataset) and produces either 1 (indicating the sentence carries a positive sentiment) or a 0 (indicating the sentence carries a negative sentiment). We can think of it as looking like this:\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/sentiment-classifier-1.png\" />\n",
        "\n",
        "Under the hood, the model is actually made up of two model.\n",
        "\n",
        "* DistilBERT processes the sentence and passes along some information it extracted from it on to the next model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its performance.\n",
        "* The next model, a basic Logistic Regression model from scikit learn will take in the result of DistilBERT’s processing, and classify the sentence as either positive or negative (1 or 0, respectively).\n",
        "\n",
        "The data we pass between the two models is a vector of size 768. We can think of this of vector as an embedding for the sentence that we can use for classification.\n",
        "\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/distilbert-bert-sentiment-classifier.png\" />\n",
        "\n",
        "## Dataset\n",
        "The dataset we will use in this example is [SST2](https://nlp.stanford.edu/sentiment/index.html), which contains sentences from movie reviews, each labeled as either positive (has the value 1) or negative (has the value 0):\n",
        "\n",
        "\n",
        "<table class=\"features-table\">\n",
        "  <tr>\n",
        "    <th class=\"mdc-text-light-green-600\">\n",
        "    sentence\n",
        "    </th>\n",
        "    <th class=\"mdc-text-purple-600\">\n",
        "    label\n",
        "    </th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      apparently reassembled from the cutting room floor of any given daytime soap\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      0\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      they presume their audience won't sit still for a sociology lesson\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      0\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      this is a visually stunning rumination on love , memory , history and the war between art and commerce\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      jonathan parker 's bartleby should have been the be all end all of the modern office anomie films\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "## Installing the transformers library\n",
        "Let's start by installing the huggingface transformers library so we can load our deep learning NLP model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9ENLU90WGl",
        "colab_type": "code",
        "outputId": "c2cb7a8d-f9fe-408d-9243-b9f5262e04a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 16.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.35)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.35 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.35)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=4037c5ac06680f1b837d7b67a71db264ea1d7aff280ee41fd38ee28d8065d7ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import clear_output\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ-42fh0hjsF",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset\n",
        "We'll use pandas to read the dataset and load it into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyoj29J24hPX",
        "colab_type": "code",
        "outputId": "d05877a2-7ca0-4363-c7e8-5d2c9d58e1e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1yaW1WK-VQ5",
        "colab_type": "code",
        "outputId": "86a6dd56-1c4d-416b-a999-72e21c78689a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# load data\n",
        "#data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "#data.emotions.value_counts().plot.bar()\n",
        "\n",
        "\n",
        "data=pd.read_csv(r\"/gdrive/My Drive/IL/ips.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Case ID</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Case Description</th>\n",
              "      <th>Case Category</th>\n",
              "      <th>Case Subcategory</th>\n",
              "      <th>Product Type</th>\n",
              "      <th>Product Organization: Support Org Name</th>\n",
              "      <th>Product Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5001J00000aBjFH</td>\n",
              "      <td>Other Licensing Issue</td>\n",
              "      <td>Error Msg : \\nPO#: \\nLAC/SN: aeff9593\\nHOST ID...</td>\n",
              "      <td>Design Tools</td>\n",
              "      <td>Installation / Licensing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Programmable Solutions Group</td>\n",
              "      <td>Licensed Products</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5001J00000aDDRH</td>\n",
              "      <td>CANON ICB Common PF : Leaf_Hill_CRB_Schematics...</td>\n",
              "      <td>Hello,\\nPlease answer the following customer's...</td>\n",
              "      <td>Hardware</td>\n",
              "      <td>Documentation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Embedded Products</td>\n",
              "      <td>Apollo Lake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5001J00000Vdd0A</td>\n",
              "      <td>Intel DCG_Lake_Wanaka: Request to get the late...</td>\n",
              "      <td>Error Msg : \\nHi there,\\nWhere I can get the l...</td>\n",
              "      <td>Design Tools</td>\n",
              "      <td>Installation / Licensing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Programmable Solutions Group</td>\n",
              "      <td>Intel® Stratix® 10 GX FPGA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5001J00000ch1bO</td>\n",
              "      <td>Testing please ignore INC008079049</td>\n",
              "      <td>Testing INC008079049\\nplease ignore</td>\n",
              "      <td>Test/Validation</td>\n",
              "      <td>Other</td>\n",
              "      <td>Server Products</td>\n",
              "      <td>Server Platforms</td>\n",
              "      <td>Intel® Server System  ASB2224WFAFP2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5001J00000aCzh6</td>\n",
              "      <td>Need help translation IBIS models to Quartus S...</td>\n",
              "      <td>Error Msg : \\nSignal Integrity Analysis has de...</td>\n",
              "      <td>Design Tools</td>\n",
              "      <td>Design Entry/Synthesis &amp; Netlist Viewers</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Programmable Solutions Group</td>\n",
              "      <td>Cyclone® V GX FPGA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Case ID  ...                         Product Name\n",
              "0  5001J00000aBjFH  ...                    Licensed Products\n",
              "1  5001J00000aDDRH  ...                          Apollo Lake\n",
              "2  5001J00000Vdd0A  ...           Intel® Stratix® 10 GX FPGA\n",
              "3  5001J00000ch1bO  ...  Intel® Server System  ASB2224WFAFP2\n",
              "4  5001J00000aCzh6  ...                   Cyclone® V GX FPGA\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOqJ1sUgpPqV",
        "colab_type": "code",
        "outputId": "db70aabe-4bac-4ba1-c2ad-49b352e755e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "# First col & second col should be text and category \n",
        "text_col=data.columns.values[2] \n",
        "category_col=data.columns.values[3]\n",
        "\n",
        "data[category_col].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f991cec2c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAGwCAYAAACpVhJoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIC4oAQEREREQHA/we3weKrYkGa3QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9E2HOrsFjn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_filter= data[data[category_col].isin(data[category_col].value_counts()[data[category_col].value_counts()>10000].index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olsKvhFeGMbV",
        "colab_type": "code",
        "outputId": "9140b468-bca7-40a8-9a1f-53fe1731dcde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "data_filter[category_col].value_counts()\n",
        "data_filter[category_col].value_counts().plot.bar()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAFrCAYAAAAzc+X9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRxEREaQYREQEKQYREUGKQUREAP8fNfTJGWex3KYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMVE3waNhuNj",
        "colab_type": "text"
      },
      "source": [
        "For performance reasons, we'll only use 2,000 sentences from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTM3hOHW4hUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1 = data.sample(n=8000, random_state=42);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRc2L89hh1Tf",
        "colab_type": "text"
      },
      "source": [
        "We can ask pandas how many sentences are labeled as \"positive\" (value 1) and how many are labeled \"negative\" (having the value 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgl8w2cS_aVq",
        "colab_type": "code",
        "outputId": "efb5d52e-2865-48ca-a9ab-bce5b1100f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "batch_1.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Case ID</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Case Description</th>\n",
              "      <th>Case Category</th>\n",
              "      <th>Case Subcategory</th>\n",
              "      <th>Product Type</th>\n",
              "      <th>Product Organization: Support Org Name</th>\n",
              "      <th>Product Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31347</th>\n",
              "      <td>5001J00000kDJZa</td>\n",
              "      <td>[HPE-TDCA2000+] PCH(LBG) PCIE3 TX Compliance T...</td>\n",
              "      <td>After turned on lane pattern generator in IPLE...</td>\n",
              "      <td>Hardware</td>\n",
              "      <td>Electrical Validation (EV)</td>\n",
              "      <td>Server Products</td>\n",
              "      <td>Data Center</td>\n",
              "      <td>Whitley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30593</th>\n",
              "      <td>500o000000QvLWS</td>\n",
              "      <td>The RSC / IPV4 / TCP / UDP offload function of...</td>\n",
              "      <td>Dear Bruce and Daphne :\\n     PHY Board enable...</td>\n",
              "      <td>Networking/Connectivity</td>\n",
              "      <td>Ethernet/Wired LAN</td>\n",
              "      <td>Ethernet Products</td>\n",
              "      <td>Data Center</td>\n",
              "      <td>Sageville</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89028</th>\n",
              "      <td>5001J00000chB46</td>\n",
              "      <td>{NEC] Stratix V Transceiver CDR部の機能について</td>\n",
              "      <td>Error Msg : \\n日本アルテラ　安間様\\n牧田@NEC放メ・二技です。\\n下記の点...</td>\n",
              "      <td>Devices</td>\n",
              "      <td>Transceiver</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Programmable Solutions Group</td>\n",
              "      <td>Stratix® V GX FPGA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59925</th>\n",
              "      <td>500o000000GxD0B</td>\n",
              "      <td>Client cannot uninstall Unite app from control...</td>\n",
              "      <td>Client cannot uninstall app from the control p...</td>\n",
              "      <td>Software/Driver/OS</td>\n",
              "      <td>Intel® Unite™</td>\n",
              "      <td>Processors, Chipsets</td>\n",
              "      <td>Client Computing</td>\n",
              "      <td>Skylake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172455</th>\n",
              "      <td>500o000000NgatY</td>\n",
              "      <td>XEON D 1500 Board Bring Up</td>\n",
              "      <td>Hello,\\nWe are trying to bring up our XEON D 1...</td>\n",
              "      <td>Firmware/BIOS</td>\n",
              "      <td>BIOS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Data Center</td>\n",
              "      <td>Grangeville</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Case ID  ...        Product Name\n",
              "31347   5001J00000kDJZa  ...             Whitley\n",
              "30593   500o000000QvLWS  ...           Sageville\n",
              "89028   5001J00000chB46  ...  Stratix® V GX FPGA\n",
              "59925   500o000000GxD0B  ...             Skylake\n",
              "172455  500o000000NgatY  ...         Grangeville\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_MO08_KiAOb",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Pre-trained BERT model\n",
        "Let's now load a pre-trained BERT model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1InADgf5xm2",
        "colab_type": "code",
        "outputId": "b49a67db-2355-4998-e1b0-3d7f1c44438f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "29a28c1266a04c4e922b3d60a4944d99",
            "156f2ae981ef4d7ebd25498992d5b0b1",
            "585fdae73a2543a982585dcce2abd8cc",
            "6aa73dac5a5d4b378fbc6fb85ace359f",
            "98d0af351cf14c5495014ec2ff16fddf",
            "8520475d2cdb4dbeb45d00dd04923d32",
            "0c38089ea58b4bb786bc12d01f1b449d",
            "d5f9d19f7cc142be9632c39433c7cced",
            "1dcf1dfccc254e1e900ed8945039d40f",
            "db556fb4b0fa453eaa7862866b0dca27",
            "9e14436e332746f983bd73587443767e",
            "cde5cb1ad1c74adf9d0105a764000a56",
            "53e70d62f8474c0f98435f402b58e7b8",
            "80acc8301fa74933a352ddb0f00743d5",
            "dc32e1dc9406445ab082d756c644e2d0",
            "b756aa2579ee4f69af5a284d12ea626c",
            "9c8f1ae228ef4f258907359ecc1fc15a",
            "1491c5868cc94e548390666ae86a38c0",
            "e5506922aab842eda17079bf536d47d5",
            "dcb77094648d44f484976ea36fbc843f",
            "1d4e8be24bc94f6bb8e404e4cbdc1518",
            "3f439c9c57bc42b39c6941755bb05850",
            "d2886778ec814a9eaa87e0211f33f516",
            "68cb45f5a7b54112bff4e175f0d105e8"
          ]
        }
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "## Want Roberta instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "BertModel = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29a28c1266a04c4e922b3d60a4944d99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dcf1dfccc254e1e900ed8945039d40f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=546, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c8f1ae228ef4f258907359ecc1fc15a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=267967963, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDBMn3wiSX6",
        "colab_type": "text"
      },
      "source": [
        "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
        "\n",
        "## Model #1: Preparing the Dataset\n",
        "Before we can hand our sentences to BERT, we need to so some minimal processing to put them in the format it requires.\n",
        "\n",
        "### Tokenization\n",
        "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg82ndBA5xlN",
        "colab_type": "code",
        "outputId": "b65ba69e-9fc3-489a-f11f-e5bc58e7120a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tokenized = batch_1[text_col].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3143 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2474 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3951 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2389 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (833 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1862 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2207 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (933 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2852 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2110 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1868 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2721 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1720 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3188 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3026 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3141 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4370 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3673 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3357 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7452 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1862 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1761 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3945 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2348 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (933 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2498 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2148 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2479 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2158 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2370 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3890 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (16855 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2248 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (926 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7439 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2210 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2889 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3712 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2427 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3828 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1808 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3406 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4824 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2338 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3997 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3794 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1890 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (995 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1005 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4684 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3855 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (992 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2121 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2077 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2192 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4818 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2302 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3405 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (882 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2039 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4219 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3712 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4753 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (883 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (824 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2455 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHwjUwYgi-uL",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\" />\n",
        "\n",
        "### Padding\n",
        "After tokenization, `tokenized` is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URn-DWJt5xhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdi7uXo95xeq",
        "colab_type": "code",
        "outputId": "8402826b-b13e-4bb6-82d4-452215fa8d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 16857)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZBsYSDjzDV",
        "colab_type": "text"
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_iGRNa_Ozc",
        "colab_type": "code",
        "outputId": "94a0a522-290f-40c4-ba98-3a60cfd92bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 16857)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_lf3ikyauuq",
        "colab_type": "text"
      },
      "source": [
        "Convert to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI4g5ioGatDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-CQB9-kN99",
        "colab_type": "text"
      },
      "source": [
        "## Model #1: And Now, Deep Learning!\n",
        "Now that we have our model and inputs ready, let's run our model!\n",
        "\n",
        "<img src=\"http://127.0.0.1:4000/images/distilBERT/bert-distilbert-tutorial-sentence-embedding.png\" />\n",
        "\n",
        "The `model()` function runs our sentences through BERT. The results of the processing will be returned into `last_hidden_states`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39UVjAV56PJz",
        "colab_type": "code",
        "outputId": "c9e0cdf4-531d-4e13-a1e8-4a7ce74fd253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = BertModel(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "print('Time taken for convert tokens to BERT vectos in sec {} \\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken for convert tokens to BERT vectos in sec 67.54479217529297 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoCep_WVuB3v",
        "colab_type": "text"
      },
      "source": [
        "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />\n",
        "\n",
        "We'll save those in the `features` variable, as they'll serve as the features to our logitics regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9t60At16PVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZVU66Gurr-",
        "colab_type": "text"
      },
      "source": [
        "The labels indicating which sentence is positive and negative now go into the `labels` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3fX2yh6PTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = batch_1[category_col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoEvM2evRx1",
        "colab_type": "text"
      },
      "source": [
        "## Model #2: Train/Test Split\n",
        "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZLGgU2AZLK5",
        "colab_type": "text"
      },
      "source": [
        "Splite features and text with the same seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddAqbkoU6PP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5nZp5-zmwNQ",
        "colab_type": "code",
        "outputId": "4f059cd5-54d5-4e84-9cb5-9aa7ee0e9dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "test_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02563108,  0.05002639, -0.1903948 , ..., -0.09171991,\n",
              "         0.3833878 ,  0.29440573],\n",
              "       [ 0.128642  , -0.0040712 , -0.03010212, ..., -0.08118317,\n",
              "         0.26797116,  0.23729531],\n",
              "       [ 0.11033169,  0.18332395, -0.0576109 , ..., -0.02182874,\n",
              "         0.44140986,  0.37397784],\n",
              "       ...,\n",
              "       [-0.12950045,  0.0923728 , -0.14527327, ...,  0.03483703,\n",
              "         0.31825507,  0.10476423],\n",
              "       [ 0.03076752,  0.17785792, -0.01049792, ..., -0.11325731,\n",
              "         0.5243633 ,  0.38401675],\n",
              "       [ 0.03822049,  0.12644139,  0.01217839, ..., -0.09107625,\n",
              "         0.32295817,  0.44957423]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "82t1I4Y1bNkd",
        "colab": {}
      },
      "source": [
        "train_texts, test_texts = train_test_split(batch_1[text_col],test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGidwCeXXBUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_token_tensor, test_token_tensor, train_mask_tensor, test_mask_tensor = train_test_split(input_ids,attention_mask,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b239Cyn_Xr9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9bhSJpcv1Bl",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://127.0.0.1:4000/images/distilBERT/bert-distilbert-train-test-split-sentence-embedding.png\" />\n",
        "\n",
        "### [Bonus] Grid Search for Parameters\n",
        "We can dive into Logistic regression directly with the Scikit Learn default parameters, but sometimes it's worth searching for the best value of the C parameter, which determines regularization strength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyEwr7yYD3Ci",
        "colab_type": "code",
        "outputId": "fb2fbc70-03e7-4c51-f0d5-4c8098d9285a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        " #parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        " #grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        " #grid_search.fit(train_features, train_labels)\n",
        "\n",
        " #print('best parameters: ', grid_search.best_params_)\n",
        " #print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 5.263252631578947}\n",
            "best scrores:  0.5479999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCT9u8vAwnID",
        "colab_type": "text"
      },
      "source": [
        "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rUMKuVgwzkY",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://127.0.0.1:4000/images/distilBERT/bert-training-logistic-regression.png\" />\n",
        "\n",
        "## Evaluating Model #2\n",
        "So how well does our model do in classifying sentences? One way is to check the accuracy against the testing dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFBRi117XW9e",
        "colab_type": "code",
        "outputId": "50363cbd-000a-40c0-dc09-470d29eb0340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_baseline_model=lr_clf.fit(train_features, train_labels)\n",
        "lr_baseline_predicted = lr_baseline_model.predict(test_features)\n",
        "print(classification_report(test_labels, lr_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.52      0.38      0.44       229\n",
            "        fear       0.49      0.48      0.49       175\n",
            "         joy       0.63      0.77      0.70       517\n",
            "        love       0.35      0.13      0.19       129\n",
            "     sadness       0.59      0.69      0.64       485\n",
            "    surprise       0.47      0.12      0.20        65\n",
            "\n",
            "    accuracy                           0.58      1600\n",
            "   macro avg       0.51      0.43      0.44      1600\n",
            "weighted avg       0.56      0.58      0.56      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCoyxRJ7ECTA",
        "colab_type": "code",
        "outputId": "75dda2d4-ab38-46aa-996c-a3ed15099e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.58125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75oyhr3VxHoE",
        "colab_type": "text"
      },
      "source": [
        "How good is this score? What can we compare it against? Let's first look at a dummy classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnwgmqNG7i5l",
        "colab_type": "code",
        "outputId": "6e17be24-ae48-4f7d-9993-5e95c246bf3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.242 (+/- 0.01)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cUSyvq2XvVc",
        "colab_type": "text"
      },
      "source": [
        "Comare to simple baseline bi-gram count model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUqOKTDEX7EY",
        "colab_type": "code",
        "outputId": "a6833f3f-f9f9-4c96-df87-95be9c9d8916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "           Design Tools       0.84      0.75      0.79       246\n",
            "                Devices       0.77      0.79      0.78       222\n",
            "          Firmware/BIOS       0.63      0.59      0.61       274\n",
            "               Hardware       0.66      0.82      0.73       405\n",
            "Networking/Connectivity       0.64      0.35      0.45       120\n",
            "     Software/Driver/OS       0.67      0.66      0.67       333\n",
            "\n",
            "               accuracy                           0.70      1600\n",
            "              macro avg       0.70      0.66      0.67      1600\n",
            "           weighted avg       0.70      0.70      0.69      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lg4LOpoxSOR",
        "colab_type": "text"
      },
      "source": [
        "So our model clearly does better than a dummy classifier. But how does it compare against the best models?\n",
        "\n",
        "## Proper SST2 scores\n",
        "For reference, the [highest accuracy score](http://nlpprogress.com/english/sentiment_analysis.html) for this dataset is currently **96.8**. DistilBERT can be trained to improve its score on this task – a process called **fine-tuning** which updates BERT’s weights to make it achieve a better performance in this sentence classification task (which we can call the downstream task). The fine-tuned DistilBERT turns out to achieve an accuracy score of **90.7**. The full size BERT model achieves **94.9**.\n",
        "\n",
        "\n",
        "\n",
        "And that’s it! That’s a good first contact with BERT. The next step would be to head over to the documentation and try your hand at [fine-tuning](https://huggingface.co/transformers/examples.html#glue). You can also go back and switch from distilBERT to BERT and see how that works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJQuqV6cnWQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOb9fatpE22n",
        "colab_type": "text"
      },
      "source": [
        "**BERT Fine Tune**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERM6JjX9hlzq"
      },
      "source": [
        "### 2.1 Init\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X19EOhMzhpUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=64\n",
        "EPOCHS =10\n",
        "HIDDEN_SIZE=768\n",
        "\n",
        "#emotions=list(set(batch_1.emotions.unique()))\n",
        "catagories=list(set(data[category_col].unique()))\n",
        "OUTPUT_DIM= len(catagories)   #num of catagories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vXDaSYi45pyS"
      },
      "source": [
        "### 2.1 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_isxcZF5xjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(catos) & set(catagories) for catos in batch_1[[category_col]].values]\n",
        "bin_catagories = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_catagories.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x59I4xUZ9Lnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_tensor=torch.max(target_tensor_bin,1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Tranform labels to float\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6n_dCSxImBa5",
        "colab": {}
      },
      "source": [
        "#target_num_tensor2=torch.tensor(LabelEncoder().fit_transform(batch_1['emotions']))\n",
        "#target_tensor2 = target_num_tensor2.reshape(-1,1).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHJlv4C2fS3x",
        "colab_type": "code",
        "outputId": "3b1d549f-769b-4608-af19-b0681738a5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "target_tensor2[0:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c7b3b71493ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget_tensor2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'target_tensor2' is not defined",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: Current TensorFlow version is 2.2.0-rc2. To use TF 1.x instead,\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\nyou run \"import tensorflow\".\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuHU9QRriehQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wrq1bT6CgJYT"
      },
      "source": [
        "### 2.2 Convert to tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ2zgfHeiftx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens_tensor, test_tokens_tensor, train_masks_tensor, test_masks_tensor = train_test_split(input_ids,attention_mask,test_size=0.2,random_state=42)\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kwjR-vYWhFn1"
      },
      "source": [
        "### 2.3 Build DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVZMnQTEhu4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "afdeX1jOo09n"
      },
      "source": [
        "### 2.4 Define Model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdOjCoZRo_Sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rtyU2Nr5qit7"
      },
      "source": [
        "### 2.5 BERT Fine tune Training \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOm2kYTCqoo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf = BertMultiClassifier()\n",
        "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
        "criterion = torch.nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss.  Check BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esekZbEw2Txl",
        "colab_type": "code",
        "outputId": "d8f2a760-db2b-4a52-d0c2-267783494f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "losses = []\n",
        "steps = []\n",
        "step = 0\n",
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        batch_loss = criterion(probas, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        \n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        \n",
        "\n",
        "        #clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"{0}/{1} loss: {2} \".format(step_num, len(train_y_tensor) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
        "        losses.append(batch_loss.item())\n",
        "        steps.append(step)\n",
        "        step += 1\n",
        "\n",
        "#convert_to_pickle(bert_clf, \"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr10epochs.pkl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "1/100.0 loss: 1.9223171472549438 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-0fe31a0d4ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbert_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vv0JzgZmsKX2"
      },
      "source": [
        "### 2.6 Evaluation \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl70xio3sUQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        bert_predicted += list(torch.max(probas,1)[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p3aouuBFYwG",
        "colab_type": "code",
        "outputId": "2b236322-de48-4d0b-82b0-943272971f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93       229\n",
            "           1       0.82      0.90      0.86       175\n",
            "           2       0.91      0.91      0.91       517\n",
            "           3       0.75      0.76      0.75       129\n",
            "           4       0.95      0.96      0.95       485\n",
            "           5       0.87      0.71      0.78        65\n",
            "\n",
            "    accuracy                           0.90      1600\n",
            "   macro avg       0.87      0.86      0.86      1600\n",
            "weighted avg       0.90      0.90      0.90      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE5qvlp_zXHo",
        "colab_type": "code",
        "outputId": "1293e539-7962-4fb9-a115-c0bddbe66eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93       229\n",
            "           1       0.82      0.90      0.86       175\n",
            "           2       0.91      0.91      0.91       517\n",
            "           3       0.75      0.76      0.75       129\n",
            "           4       0.95      0.96      0.95       485\n",
            "           5       0.87      0.71      0.78        65\n",
            "\n",
            "    accuracy                           0.90      1600\n",
            "   macro avg       0.87      0.86      0.86      1600\n",
            "weighted avg       0.90      0.90      0.90      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDJ3A5LyRTNQ",
        "colab_type": "code",
        "outputId": "1480fc78-789d-42aa-c418-fb6cb240ce1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(confusion_matrix(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[169  14   4   4  38   0]\n",
            " [  7 142   3   0  20   3]\n",
            " [  7   5 431  48  24   2]\n",
            " [  1   2  35  84   7   0]\n",
            " [  1  18  12   5 449   0]\n",
            " [  0  16   7   1   6  35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t_vq3SGGp1GL"
      },
      "source": [
        "**Logistic Distilation with BERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY3Ld9UPLzoe",
        "colab_type": "text"
      },
      "source": [
        "Need to define class BertMultiClass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSwwEzkzL7TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vA0AfhKrQKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf = load_from_pickle(\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr5epochs.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B9SxFXzOJbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OJvy3PMMe7R",
        "colab_type": "text"
      },
      "source": [
        "Bimarization of lables and create target_tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cUBKhDVBMkgM",
        "colab": {}
      },
      "source": [
        "#emotions=list(set(batch_1.emotions.unique()))\n",
        "catagories=list(set(data[category_col].unique()))\n",
        "\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(catos) & set(catagories) for catos in batch_1[[category_col]].values]\n",
        "bin_catagories = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_catagories.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFFKBTJpMww_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_tensor=torch.max(target_tensor_bin,1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrosUSumcB5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=64\n",
        "train_tokens_tensor, test_tokens_tensor, train_masks_tensor, test_masks_tensor = train_test_split(input_ids,attention_mask,test_size=0.2,random_state=42)\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=0.2,random_state=42)\n",
        "\n",
        "train_dataset_for_distill = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_dataloader_for_distill = DataLoader(train_dataset_for_distill, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP178NXud0-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf.eval()\n",
        "train_logits = []\n",
        "bert_predicted = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(train_dataloader_for_distill):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "        train_logits += list(logits)\n",
        "\n",
        "        bert_predicted += list(torch.max(logits,1)[1])\n",
        "\n",
        "#train_logits = np.vstack(train_logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw9-fSzLemKF",
        "colab_type": "code",
        "outputId": "943ce7ab-a72b-40c6-c2c7-6db071203c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(train_y_tensor, bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       864\n",
            "           1       0.92      0.96      0.94       754\n",
            "           2       0.97      0.96      0.97      2188\n",
            "           3       0.89      0.89      0.89       498\n",
            "           4       0.98      0.98      0.98      1866\n",
            "           5       0.90      0.87      0.88       230\n",
            "\n",
            "    accuracy                           0.96      6400\n",
            "   macro avg       0.94      0.94      0.94      6400\n",
            "weighted avg       0.96      0.96      0.96      6400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VyBgyPFjcgv",
        "colab_type": "text"
      },
      "source": [
        "**Use regression to predicte Logits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mArUUo0jX86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCk0rAESlL9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(batch_1[text_col],batch_1[category_col], test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ1cDt0Nd2gg",
        "colab_type": "code",
        "outputId": "6674496e-114e-4bbb-e4c0-536a2aae5408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "train_logits_numpy= (i.numpy() for i in train_logits)\n",
        "train_logits = np.vstack(train_logits_numpy)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4a5a5058a2df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_logits_numpy\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_logits_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_logits' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8YWtuGNdr5G",
        "colab_type": "code",
        "outputId": "45a0bb38-ef71-408b-b353-342bd8db5aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "train_logits "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6896763 , -0.5345181 ,  5.1783304 , -1.7711558 , -2.2541738 ,\n",
              "         0.7234218 ],\n",
              "       [-1.8258332 , -3.205102  ,  4.873008  , -0.5550477 ,  1.0797815 ,\n",
              "        -1.4393263 ],\n",
              "       [-2.2791028 , -2.1062865 ,  5.665677  , -0.75003266, -0.7649366 ,\n",
              "        -0.8934874 ],\n",
              "       ...,\n",
              "       [-1.0118906 , -1.3638008 , -0.13120678, -0.3857909 ,  4.7568655 ,\n",
              "        -2.6017396 ],\n",
              "       [ 0.07644066,  4.6670856 , -1.1762648 , -1.2533344 , -2.2330873 ,\n",
              "         1.7640835 ],\n",
              "       [-0.9474587 , -2.4521034 ,  5.0374484 , -1.1121345 , -1.3535795 ,\n",
              "         0.43836874]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqmyIg3gjnc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distilled_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(train_texts, train_logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6svyXGKgnHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distilled_predicted_logits = distilled_model.predict(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4TRNy5RhF42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distilled_bert_predicted=torch.max(torch.tensor(distilled_predicted_logits),1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpUo3erxgm7p",
        "colab_type": "code",
        "outputId": "38a972b3-9669-442c-f264-4cd7aad0202f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, distilled_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86       229\n",
            "           1       0.81      0.79      0.80       175\n",
            "           2       0.79      0.94      0.86       517\n",
            "           3       0.85      0.52      0.64       129\n",
            "           4       0.88      0.91      0.90       485\n",
            "           5       0.87      0.52      0.65        65\n",
            "\n",
            "    accuracy                           0.84      1600\n",
            "   macro avg       0.86      0.75      0.79      1600\n",
            "weighted avg       0.85      0.84      0.84      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJOxtpcXkMcm",
        "colab_type": "code",
        "outputId": "f4fb3ca9-ee4e-4f1b-852f-160039d1826e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, distilled_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86       229\n",
            "           1       0.81      0.79      0.80       175\n",
            "           2       0.79      0.94      0.86       517\n",
            "           3       0.85      0.52      0.64       129\n",
            "           4       0.88      0.91      0.90       485\n",
            "           5       0.87      0.52      0.65        65\n",
            "\n",
            "    accuracy                           0.84      1600\n",
            "   macro avg       0.86      0.75      0.79      1600\n",
            "weighted avg       0.85      0.84      0.84      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY11TYZFj22i",
        "colab_type": "code",
        "outputId": "0f4d19da-ae84-4ccc-b8a0-e1c309ee14c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(train_logits[:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 409., 1688.,  705.,  923., 1109.,  574.,  223.,  258.,  273.,\n",
              "         238.]),\n",
              " array([-2.459845  , -1.8476666 , -1.2354882 , -0.6233098 , -0.01113138,\n",
              "         0.60104704,  1.2132255 ,  1.8254039 ,  2.4375823 ,  3.0497608 ,\n",
              "         3.6619391 ], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYuhLUkcMfUnqiKEvSR35//ouA1oTPogUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1taE8wEoKz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gwGXcoZ3oCuK"
      },
      "source": [
        "**Use unlabeled data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXpSHH1noMHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_data = data.sample(n=8000, random_state=42);     \n",
        "train_texts, test_texts = train_test_split(labeled_data[text_col],test_size=0.2,random_state=42)\n",
        "\n",
        "all_ulabeled_data = data.drop(labeled_data.index)[text_col]\n",
        "\n",
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "#all_ulabeled_data[\"token_size\"] = all_ulabeled_data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "#all_ulabeled_data = all_ulabeled_data.loc[all_ulabeled_data['token_size'] <= 70].copy()\n",
        "\n",
        "unlabeled_texts=all_ulabeled_data.sample(n=64000, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECSJDm2554eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35pBsX9hakPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "catagories=list(set(data[category_col].unique()))\n",
        "\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(catos) & set(catagories) for catos in batch_1[[category_col]].values]\n",
        "bin_catagories = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_catagories.tolist())\n",
        "\n",
        "target_tensor=torch.max(target_tensor_bin,1)[1]\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=0.2,random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc-yPXRQy2OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_tokenized = unlabeled_texts.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfICfmOEzD67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in unlabeled_tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "unlabeled_padded = np.array([i + [0]*(max_len-len(i)) for i in unlabeled_tokenized.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OitY9rcuzMWM",
        "colab_type": "code",
        "outputId": "c343390f-1e50-4d81-f764-b768739f1b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "unlabeled_attention_mask = np.where(unlabeled_padded != 0, 1, 0)\n",
        "unlabeled_attention_mask.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64000, 185)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsKZOj6zY59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_input_ids = torch.tensor(unlabeled_padded)  \n",
        "unlabeled_attention_mask = torch.tensor(unlabeled_attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU1zxPb6zwIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_tokens_tensor = torch.tensor(unlabeled_input_ids)\n",
        "unlabeled_masks_tensor = torch.tensor(unlabeled_attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO1DlO9n0Q90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=64\n",
        "unlabeled_dataset = TensorDataset(unlabeled_tokens_tensor, unlabeled_masks_tensor)\n",
        "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHNpZ5M0mez",
        "colab_type": "code",
        "outputId": "f8257b3d-8816-47a9-9486-a0e57773df62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert_clf.eval()\n",
        "unlabeled_logits = []\n",
        "#unlabeled_bert_predicted = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(unlabeled_dataloader):\n",
        "\n",
        "        token_ids, masks = tuple(t for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "        unlabeled_logits += list(logits)\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        print(\"{0}/{1}\".format(step_num, len(unlabeled_dataset) / BATCH_SIZE))\n",
        "\n",
        "        #unlabeled_bert_predicted += list(torch.max(logits,1)[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "999/1000.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF47sfDA2aFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_logits_numpy= (i.numpy() for i in unlabeled_logits)\n",
        "unlabeled_logits = np.vstack(unlabeled_logits_numpy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz_VnnX91GNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(unlabeled_texts, unlabeled_logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmaKwujU1Ljl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_predicted_logits = unlabeled_model.predict(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaaUhkXx461Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_bert_predicted=torch.max(torch.tensor(unlabeled_predicted_logits),1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SADVrOW5CRk",
        "colab_type": "code",
        "outputId": "d38871a9-81dd-42d8-d571-3a7e45a8a3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor,unlabeled_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83       229\n",
            "           1       0.75      0.73      0.74       175\n",
            "           2       0.79      0.92      0.85       517\n",
            "           3       0.81      0.53      0.64       129\n",
            "           4       0.85      0.93      0.89       485\n",
            "           5       0.85      0.34      0.48        65\n",
            "\n",
            "    accuracy                           0.82      1600\n",
            "   macro avg       0.83      0.70      0.74      1600\n",
            "weighted avg       0.83      0.82      0.81      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bF0CbciFhJ02"
      },
      "source": [
        "**Use unlabeled data (load from pkl)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27eBD2Zbmwpr",
        "colab_type": "text"
      },
      "source": [
        "Init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cybgMdaEp-XL",
        "colab_type": "text"
      },
      "source": [
        "Init/Load logits for labeled and unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE9k0NZqNDMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert_to_pickle([train_logits, unlabeled_logits], \"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr10epochsLogistList.pkl\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2P-nz8AbT-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_logits_load, unlabeled_logits_load = load_from_pickle(\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr10epochsLogistList.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShNl87808pa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_logits_pd = pd.DataFrame(unlabeled_logits_load) # convert to pandas format "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3kzujX8qLHL",
        "colab_type": "text"
      },
      "source": [
        "Init/Set train/test texts and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PavSfByavVlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "#all_ulabeled_data[\"token_size\"] = all_ulabeled_data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "#all_ulabeled_data = all_ulabeled_data.loc[all_ulabeled_data['token_size'] <= 70].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghEquYptn3k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_SIZE = 6400\n",
        "TEST_SIZE = 1600\n",
        "TRAINING_PLUS_TEST_SIZE = 8000\n",
        "UNLABELED_SIZE = 6400\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE=0.2\n",
        "\n",
        "labeled_data = data.sample(n=TRAINING_PLUS_TEST_SIZE, random_state=RANDOM_SEED);     \n",
        "all_ulabeled_text = data.drop(labeled_data.index)[text_col]\n",
        "\n",
        "unlabeled_texts=all_ulabeled_text.sample(n=64000, random_state=42)  # Must be RANDOM_SEED=42 as loaded from pkl\n",
        "\n",
        "unlabeled_logits = unlabeled_logits_pd.sample(n=UNLABELED_SIZE, random_state=RANDOM_SEED)\n",
        "unlabeled_texts = unlabeled_texts.sample(n=UNLABELED_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(labeled_data[text_col], labeled_data[category_col],test_size=TEST_SIZE,random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5joH5Wipzal",
        "colab_type": "text"
      },
      "source": [
        "Init/Build train_y_tensor and test_y_tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPOudbwQpRJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "catagories=list(set(data[category_col].unique()))\n",
        "\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(catos) & set(catagories) for catos in batch_1[[category_col]].values]\n",
        "bin_catagories = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_catagories.tolist())\n",
        "\n",
        "target_tensor=torch.max(target_tensor_bin,1)[1]\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=TEST_SIZE,random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiakjnuW-cFv",
        "colab_type": "code",
        "outputId": "8e9de396-29d0-46fa-8d0d-8320d8b37265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(vec_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method _cs_matrix.toarray of <6400x149035 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 301263 stored elements in Compressed Sparse Row format>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E-fHwog8_nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVtGjEc6mKoR",
        "colab_type": "text"
      },
      "source": [
        "Simple regression - N-gram count only (baseline)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FvU9B4QmVu7",
        "colab_type": "code",
        "outputId": "35a818fd-35c5-4b0b-968c-959e454a162d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.90      0.64      0.75       229\n",
            "        fear       0.80      0.61      0.69       175\n",
            "         joy       0.72      0.92      0.81       517\n",
            "        love       0.83      0.38      0.52       129\n",
            "     sadness       0.78      0.89      0.83       485\n",
            "    surprise       0.83      0.29      0.43        65\n",
            "\n",
            "    accuracy                           0.77      1600\n",
            "   macro avg       0.81      0.62      0.67      1600\n",
            "weighted avg       0.79      0.77      0.76      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE1jWLhSrPD8",
        "colab_type": "text"
      },
      "source": [
        "BERT Embedding (freeze BERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6HX0ItlrUDC",
        "colab_type": "text"
      },
      "source": [
        "BERT Finetuning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co5kizj3mrPo",
        "colab_type": "text"
      },
      "source": [
        "Distill with training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H9JYjcxIfmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn import linear_model\n",
        "#reg = linear_model.Ridge(alpha=.5)\n",
        "#reg = linear_model.Lasso(alpha=.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk96hkalmV0q",
        "colab_type": "code",
        "outputId": "dd732dac-05dd-4593-a8ba-39439467f738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "distilled_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(train_texts, train_logits_load)\n",
        "distilled_predicted_logits = distilled_model.predict(test_texts)\n",
        "distilled_bert_predicted=torch.max(torch.tensor(distilled_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor, distilled_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86       229\n",
            "           1       0.81      0.79      0.80       175\n",
            "           2       0.79      0.94      0.86       517\n",
            "           3       0.85      0.52      0.64       129\n",
            "           4       0.88      0.91      0.90       485\n",
            "           5       0.87      0.52      0.65        65\n",
            "\n",
            "    accuracy                           0.84      1600\n",
            "   macro avg       0.86      0.75      0.79      1600\n",
            "weighted avg       0.85      0.84      0.84      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlmjlC_7qiy2",
        "colab_type": "text"
      },
      "source": [
        "Distill with unlabeled samples "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imaZhjRDwi5o",
        "colab_type": "code",
        "outputId": "2bd6a1b3-7720-4722-c273-a8056399b32c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "unlabeled_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(unlabeled_texts, unlabeled_logits)\n",
        "unlabeled_predicted_logits = unlabeled_model.predict(test_texts)\n",
        "unlabeled_bert_predicted=torch.max(torch.tensor(unlabeled_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,unlabeled_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.76      0.82       229\n",
            "           1       0.77      0.77      0.77       175\n",
            "           2       0.77      0.89      0.82       517\n",
            "           3       0.71      0.50      0.58       129\n",
            "           4       0.85      0.89      0.87       485\n",
            "           5       0.94      0.49      0.65        65\n",
            "\n",
            "    accuracy                           0.81      1600\n",
            "   macro avg       0.82      0.72      0.75      1600\n",
            "weighted avg       0.81      0.81      0.80      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfbsSdA8q0Rt",
        "colab_type": "text"
      },
      "source": [
        "Distill with unlabeled samples + training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTtNQCdQmnkt",
        "colab_type": "code",
        "outputId": "4dce5e3b-c34c-4158-e56c-7fea44a09a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "mix_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(np.concatenate((train_texts,unlabeled_texts),axis=0), np.concatenate((train_logits_load,unlabeled_logits.to_numpy())))\n",
        "mix_predicted_logits = mix_model.predict(test_texts)\n",
        "mix_bert_predicted=torch.max(torch.tensor(mix_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,mix_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9b192d887f26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmix_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munlabeled_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_logits_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munlabeled_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmix_predicted_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmix_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmix_bert_predicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix_predicted_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmix_bert_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_logits_load' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvM79PgsmuRw",
        "colab_type": "text"
      },
      "source": [
        "Distill with STS data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eOZ5HDQujNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX4wh_XLgUai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output\n",
        "        \n",
        "bert_clf = load_from_pickle(\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr5epochs.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPe1L-aYmgcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_data = data.sample(n=TRAINING_PLUS_TEST_SIZE, random_state=RANDOM_SEED); \n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(labeled_data['text'], labeled_data['emotions'],test_size=TEST_SIZE,random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVnHrzOMnIkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "catagories=list(set(data[category_col].unique()))\n",
        "\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(catos) & set(catagories) for catos in batch_1[[category_col]].values]\n",
        "bin_catagories = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_catagories.tolist())\n",
        "\n",
        "target_tensor=torch.max(target_tensor_bin,1)[1]\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=TEST_SIZE,random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65_YWH8qx7L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=64\n",
        "sts_data = df.sample(n=6400, random_state=42)\n",
        "sts_unlabeled_texts = sts_data[0]\n",
        "sts_logits=build_bert_logits(sts_unlabeled_texts,bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPv7ZqV3vfi1",
        "colab_type": "code",
        "outputId": "28bcefe3-cd38-41ac-cba7-60645e074827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "sts_unlabeled_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(sts_unlabeled_texts, sts_logits)\n",
        "sts_unlabeled_predicted_logits = sts_unlabeled_model.predict(test_texts)\n",
        "sts_unlabeled_bert_predicted=torch.max(torch.tensor(sts_unlabeled_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,sts_unlabeled_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.00      0.01       229\n",
            "           1       0.33      0.02      0.03       175\n",
            "           2       0.39      0.86      0.54       517\n",
            "           3       0.60      0.02      0.04       129\n",
            "           4       0.48      0.42      0.45       485\n",
            "           5       0.55      0.09      0.16        65\n",
            "\n",
            "    accuracy                           0.41      1600\n",
            "   macro avg       0.41      0.24      0.20      1600\n",
            "weighted avg       0.39      0.41      0.32      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pRto5r0V02E-",
        "colab": {}
      },
      "source": [
        "def build_bert_logits(texts, bert_clf,tokenizer, batch_size):\n",
        "\n",
        "  tokenized = texts.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "  max_len = 0\n",
        "  for i in tokenized.values:\n",
        "      if len(i) > max_len:\n",
        "          max_len = len(i)\n",
        "\n",
        "  padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "  attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "  input_ids = torch.tensor(padded)  \n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "  tokens_tensor = torch.tensor(input_ids)\n",
        "  masks_tensor = torch.tensor(attention_mask)\n",
        "\n",
        "  dataset = TensorDataset(tokens_tensor, masks_tensor)\n",
        "  dataloader = DataLoader(dataset, batch_size)\n",
        "\n",
        "  bert_clf.eval()\n",
        "  list_logits = []\n",
        "  with torch.no_grad():\n",
        "      for step_num, batch_data in enumerate(dataloader):\n",
        "\n",
        "          token_ids, masks = tuple(t for t in batch_data)\n",
        "\n",
        "          logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "          list_logits += list(logits)\n",
        "\n",
        "          print(\"{0}/{1}\".format(step_num, len(dataset) / batch_size))\n",
        "\n",
        "  list_logits_numpy= (i.numpy() for i in list_logits)\n",
        "  logits = np.vstack(list_logits_numpy)\n",
        "  return(logits)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0KGGDbP2Y0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiL-UHfQ2ZNd",
        "colab_type": "text"
      },
      "source": [
        "**N-gram plus Glove embedding** \n",
        "Example code: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb \n",
        "\n",
        "https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/Glove_CNN_MultiClass.ipynb#scrollTo=tnUazzVHSuB6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHU8ABmk0ozh",
        "colab_type": "text"
      },
      "source": [
        "Simple logistic by replace CounteVecorize with mean sentence Glove "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghk3WRw3TDTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_data = data.sample(n=TRAINING_PLUS_TEST_SIZE, random_state=RANDOM_SEED); \n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(labeled_data['text'], labeled_data['emotions'],test_size=TEST_SIZE,random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1fnirjd9RGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define dict to hold a word and its vector\n",
        "glove = {}\n",
        "# read the word embeddings file ~820MB\n",
        "f = open('/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/glove.6B.100d.txt', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    glove[word] = coefs\n",
        "f.close()\n",
        "# check the length\n",
        "len(glove) # 400000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tffLEYk9Jwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "sentence_vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "for i in clean_sentences:\n",
        "    if len(i) != 0:\n",
        "        v = sum([glove.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
        "    else:\n",
        "        v = np.zeros((100,))\n",
        "    sentence_vectors.append(v)\n",
        "print('Total vectors created:',len(sentence_vectors))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3IqXqi6AcXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Glove_baseline_model = make_pipeline(MeanSentenceGlove()), LogisticRegression()).fit(train_texts, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCIhfp7vmxph",
        "colab_type": "text"
      },
      "source": [
        "Distill with Back translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXwdiqsCm8bv",
        "colab_type": "text"
      },
      "source": [
        "Distill with VAT"
      ]
    }
  ]
}