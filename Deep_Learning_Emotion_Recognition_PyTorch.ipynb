{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Emotion Recognition PyTorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/Deep_Learning_Emotion_Recognition_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StfRpRW1SuBw",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Based Emotion Recognition with PyTorch\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/emotion_classifier.png?raw=true)\n",
        "\n",
        "In this notebook we are going to learn how to train deep neural networks, such as recurrent neural networks (RNNs), for addressing a natural language task known as **emotion recognition**. We will cover everything you need to know to get started with NLP using deep learning frameworks such as TensorFlow. We will cover the common best practices, functionalities, and steps you need to understand the basics of TensorFlow APIs to build powerful predictive models via the computation graph. In the process of building our models, we will compare PyTorch and TensorFlow to let the learner appreciate the strenghts of each tool.\n",
        "\n",
        "by [Elvis Saravia](https://twitter.com/omarsar0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIkM141cSuBz",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrz3-nSrSuB1",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "1. Deep Learning Frameworks\n",
        "     - 1.1 Eager execution\n",
        "     - 1.2 Computation graph\n",
        "2. Tensors\n",
        "    - 2.1 Basic math with tensors\n",
        "    - 2.2 Transforming tensors\n",
        "3. Data\n",
        "    - 3.1 Preprocessing data\n",
        "        - Tokenization and Sampling\n",
        "        - Constructing Vocabulary and Index-Word Mapping\n",
        "    - 3.2 Converting data into tensors\n",
        "    - 3.3 Padding data\n",
        "    - 3.4 Binarization\n",
        "    - 3.5 Split data\n",
        "    - 3.6 Data Loader\n",
        "4. Model\n",
        "    - 4.1 Pretesting Model\n",
        "    - 4.2 Testing models with eager execution\n",
        "5. Training\n",
        "6. Evaluation on Testing Dataset\n",
        "    - 6.1 Confusion matrix\n",
        "- Final Words\n",
        "- References\n",
        "- *Storing models and setting checkpoints (Exercise)*\n",
        "- *Restoring models (Exercise)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy9JWaqqSuB1",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbWgC0tSuB3",
        "colab_type": "text"
      },
      "source": [
        "## 1. Deep Learning Frameworks\n",
        "There are many deep learning frameworks such as Chainer, DyNet, MXNet, PyTorch, TensorFlow, and Keras. Each framework has their own strenghts which a researcher or a developer may want to consider before choosing the right framework. In my opinion, PyTorch is great for researchers and offers eager execution by default, but its high-level APIs require some understanding of deep learning concepts such as **affine layers** and **automatic differentiation**. On the other hand, TensorFlow was originally built as a low-level API that provides a robust list of functionalities to build deep learning models from the ground up. More recently, TensorFlow also offers **eager execution** and is equipped with a high-level API known as Keras.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/dl_frameworks.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suv8DnrQSuB5",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Eager Execution\n",
        "Eager execution allows us to operate on the computation graph dynamically, also known as **imperative programming**. TensorFlow requires that you manually set this mode, while PyTorch comes with this mode by default. Below we import the necessary libraries to use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CURzvVldMJcU",
        "colab_type": "code",
        "outputId": "84d131ce-d1c5-488b-bea8-8b90cffc829b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUazzVHSuB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK69ztCKSuB-",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Computation Graph\n",
        "A simplified definition of a neural network is a string of functions that are **differentiable** and that we can combine together to get more complicated functions. An intuitive way to express this process is through computation graphs. \n",
        "\n",
        "![alt txt](http://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png)\n",
        "\n",
        "Image credit: [Chris Olah](http://colah.github.io/posts/2015-08-Backprop/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6243JBwQSuB_",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensors\n",
        "Tensors are the fundamental data structure used to store data that will be fed as input to a computation graph for processing and applying tranformations. Let's create two tensors and multiply them, and then output the result. The figure below shows a 4-D Tensor.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/tensor.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72g6eRGSuCA",
        "colab_type": "code",
        "outputId": "db89cbc8-48c9-4534-ccf1-a6eb2c7355bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "c = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "d = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n",
        "e = torch.matmul(c, d)\n",
        "print(e)\n",
        "print(c.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 3.],\n",
            "        [3., 7.]])\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTM0Y6hSuCF",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Math with Tensors\n",
        "PyTorch and other deep learning libraries like TensorFlow allow you to do **automatic differentation**. Let's try to compute the derivative of a function -- in this case that function is stored in the variable `z`. In PyTorch, the option `requires_grad=True` tracks all operations applied to the input tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855r1t0MSuCG",
        "colab_type": "code",
        "outputId": "4769ffbb-f831-4298-a536-b6e80cf72dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "### Automatic differentiation with PyTorch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "# an operation of tensor\n",
        "y = x + 2 # y inherits grad_fn\n",
        "\n",
        "# apply operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(out)\n",
        "\n",
        "out.backward()\n",
        "\n",
        "print(x.grad) # d(out)/dx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(27., grad_fn=<MeanBackward1>)\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwHvtrCLSuCK",
        "colab_type": "text"
      },
      "source": [
        "You can verfiy the output with the equations in the figure below:\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/autograd.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6j5_2wFSuCL",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Transforming Tensors\n",
        "We can also apply some transformation to a tensor such as adding a dimension or transposing it. Let's try both adding a dimension and transposing a matrix below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT8u_3rzSuCL",
        "colab_type": "code",
        "outputId": "6018aee4-08ab-4995-eeb7-005710f7835e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"X shape: \", x.size())\n",
        "\n",
        "# add dimension\n",
        "print(x.unsqueeze(1).size()) \n",
        "\n",
        "# transpose \n",
        "torch.transpose(x, 0,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:  torch.Size([2, 3])\n",
            "torch.Size([2, 1, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggtl1m6aSuCP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Emotion Dataset\n",
        "In this notebook we are working on an emotion classification task. The dataset contains tweets labeled into 6 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JqoUiTSuCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVCiiFsBNbuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bliFaijvNfIZ",
        "colab_type": "code",
        "outputId": "e368bcb2-f36f-4182-f161-671bae2d78d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2qHNv2-N9BC",
        "colab_type": "text"
      },
      "source": [
        "We had already processed the data for you. You can find the pickle file [here](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/data/merged_training.pkl)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2sYWY79SuCS",
        "colab_type": "code",
        "outputId": "dc109e02-dc77-4d45-d1fa-a1d657a347ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# load data\n",
        "data = load_from_pickle(directory=\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/merged_training.pkl\")\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f48dc4fe7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqEpIREREVUIiIiKqEhIREVH1/wGfA/dLdXaziQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNSP0G-SuCV",
        "colab_type": "code",
        "outputId": "58478956-c5d3-4621-a2dc-dc29f2ba7c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head(5)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27383</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110083</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140764</th>\n",
              "      <td>ive probably mentioned this before but i reall...</td>\n",
              "      <td>joy</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100071</th>\n",
              "      <td>i was feeling a little low few days back</td>\n",
              "      <td>sadness</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2837</th>\n",
              "      <td>i beleive that i am much more sensitive to oth...</td>\n",
              "      <td>love</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions  token_size\n",
              "27383   i feel awful about it too because it s my job ...  sadness          26\n",
              "110083                              im alone i feel awful  sadness           5\n",
              "140764  ive probably mentioned this before but i reall...      joy          27\n",
              "100071           i was feeling a little low few days back  sadness           9\n",
              "2837    i beleive that i am much more sensitive to oth...     love          18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nI00TmkSuCY",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Preprocessing Data\n",
        "In the next steps we are going to create tokenize the text, create index mapping for words, and also construct a vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCHxi2ASuCZ",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDgIXGGSuCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=50000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNrOA7mSuCe",
        "colab_type": "text"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KouYEDoNSuCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFasv0ASuCi",
        "colab_type": "code",
        "outputId": "a5860388-b890-4313-b130-d25c453c086f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aa',\n",
              " 'aaa',\n",
              " 'aaaaand',\n",
              " 'aaaand',\n",
              " 'aaah',\n",
              " 'aaahs',\n",
              " 'aabsolutely',\n",
              " 'aah',\n",
              " 'aap']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqf0tC3FSuCk",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Converting Data into Tensors \n",
        "For convenience we would like to convert the data into tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omlfNU8hSuCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AphKgs33SuCn",
        "colab_type": "code",
        "outputId": "65340549-e5a9-49c7-c94a-a3215a09053d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]\n",
        "type(input_tensor)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoIfZHjSuCr",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Padding data\n",
        "In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbSHvs0SuCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zyXKoy6SuCw",
        "colab_type": "code",
        "outputId": "4a518039-d459-4b24-93db-a0d6a49f6483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk71VEPSuC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wKDdBCSuC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dok2XcWSuC7",
        "colab_type": "code",
        "outputId": "13a59f9f-a375-4252-dbab-539e1dd13fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([11644,   779,  8776,  1146,    65, 12639, 10029, 24215, 27354,\n",
              "        16939, 11644,  6500, 11920,  1165,   901, 24215,  8542, 12639,\n",
              "        24517, 14819, 16939, 15555, 24191, 11644, 11788, 12639, 27022,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0]),\n",
              " array([11644,  8766,  8308,   686, 24215, 24460,  3252, 10150, 16939,\n",
              "          901,  6956, 24290, 26762, 14440, 14819,  8766,  2259, 16823,\n",
              "         1446, 13669, 16364,  1044, 27006,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBN6xAsGSuDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_369xrpSuDC",
        "colab_type": "code",
        "outputId": "fe99cea0-a836-47b0-9e08-8ca87654b18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "target_tensor[0:2] "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZMnNbUSuDF",
        "colab_type": "code",
        "outputId": "76858e62-6e29-4421-926a-daa956ce2ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2800</th>\n",
              "      <td>i am feeling apprehensive about it given the z...</td>\n",
              "      <td>fear</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32380</th>\n",
              "      <td>i feel exhausted all the time but going out an...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text emotions  token_size\n",
              "2800   i am feeling apprehensive about it given the z...     fear          27\n",
              "32380  i feel exhausted all the time but going out an...  sadness          23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCgbz5icSuDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bI6rF59SuDK",
        "colab_type": "code",
        "outputId": "df4dde26-b1d1-40d7-d24d-2edb9187a9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxi-STseSuDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRkO7WISuDN",
        "colab_type": "code",
        "outputId": "07352b56-f017-452e-a697-d3489df8d845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fear'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWDE42iSuDQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Split data\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQuGQReSuDR",
        "colab_type": "code",
        "outputId": "55388281-4d00-4245-e660-41b449a6e26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 40000, 5000, 5000, 5000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ0GXI9SuDX",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 Data Loader\n",
        "We can also laod the data into a data loader, which makes it easy to **manipulate the data**, **create batches**, and apply further **transformations**. In PyTorch we can use the `DataLoader` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xtwf8nSuDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDa8eJVSuDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0Of7YiSuDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgVVs1XSuDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQNqg9xSuDe",
        "colab_type": "code",
        "outputId": "c818546e-144a-4f5a-ab34-82c107a65f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_dataset.batch_size\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqYHyFGwSuDh",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model\n",
        "After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details. \n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/gru-model.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHYthQdSuDi",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Constructing the Model\n",
        "Below we construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVXtMhf3SuDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6GVV87SuDk",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Pretesting model\n",
        "Since eager execution is enabled we can print the output of the model by passing a sample of the dataset and making sure that the dimensions of the outputs are the expected ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjomHaHbSuDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhymNqRSuDn",
        "colab_type": "code",
        "outputId": "c2c13e64-6085-4a08-af3f-eef4fbd7667d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(output.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([68, 64])\n",
            "torch.Size([64, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRXfA2NSuDp",
        "colab_type": "text"
      },
      "source": [
        "## 5. Training the Model\n",
        "Now that we have tested the model, it is time to train it. We will define out optimization algorithm, learnin rate, and other necessary information to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFuDTsrUSuDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyvsSQrPSuDr",
        "colab_type": "code",
        "outputId": "9ca75e25-23d5-480a-c7ef-90bddf741ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.3090\n",
            "Epoch 1 Batch 100 Val. Loss 0.2593\n",
            "Epoch 1 Batch 200 Val. Loss 0.2294\n",
            "Epoch 1 Batch 300 Val. Loss 0.0999\n",
            "Epoch 1 Batch 400 Val. Loss 0.0672\n",
            "Epoch 1 Batch 500 Val. Loss 0.0121\n",
            "Epoch 1 Batch 600 Val. Loss 0.0550\n",
            "Epoch 1 Loss 0.1442 -- Train Acc. 66.6150 -- Val Acc. 90.4247\n",
            "Time taken for 1 epoch 17.20605158805847 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.0335\n",
            "Epoch 2 Batch 100 Val. Loss 0.0370\n",
            "Epoch 2 Batch 200 Val. Loss 0.0154\n",
            "Epoch 2 Batch 300 Val. Loss 0.0288\n",
            "Epoch 2 Batch 400 Val. Loss 0.0281\n",
            "Epoch 2 Batch 500 Val. Loss 0.0348\n",
            "Epoch 2 Batch 600 Val. Loss 0.0228\n",
            "Epoch 2 Loss 0.0263 -- Train Acc. 93.0175 -- Val Acc. 93.1691\n",
            "Time taken for 1 epoch 17.032180547714233 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.0125\n",
            "Epoch 3 Batch 100 Val. Loss 0.0410\n",
            "Epoch 3 Batch 200 Val. Loss 0.0233\n",
            "Epoch 3 Batch 300 Val. Loss 0.0360\n",
            "Epoch 3 Batch 400 Val. Loss 0.0124\n",
            "Epoch 3 Batch 500 Val. Loss 0.0211\n",
            "Epoch 3 Batch 600 Val. Loss 0.0237\n",
            "Epoch 3 Loss 0.0197 -- Train Acc. 94.3075 -- Val Acc. 93.7099\n",
            "Time taken for 1 epoch 16.95982336997986 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.0077\n",
            "Epoch 4 Batch 100 Val. Loss 0.0150\n",
            "Epoch 4 Batch 200 Val. Loss 0.0101\n",
            "Epoch 4 Batch 300 Val. Loss 0.0255\n",
            "Epoch 4 Batch 400 Val. Loss 0.0285\n",
            "Epoch 4 Batch 500 Val. Loss 0.0139\n",
            "Epoch 4 Batch 600 Val. Loss 0.0193\n",
            "Epoch 4 Loss 0.0186 -- Train Acc. 94.7800 -- Val Acc. 93.2292\n",
            "Time taken for 1 epoch 17.042420864105225 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.0161\n",
            "Epoch 5 Batch 100 Val. Loss 0.0241\n",
            "Epoch 5 Batch 200 Val. Loss 0.0114\n",
            "Epoch 5 Batch 300 Val. Loss 0.0319\n",
            "Epoch 5 Batch 400 Val. Loss 0.0095\n",
            "Epoch 5 Batch 500 Val. Loss 0.0114\n",
            "Epoch 5 Batch 600 Val. Loss 0.0138\n",
            "Epoch 5 Loss 0.0162 -- Train Acc. 95.6150 -- Val Acc. 93.3293\n",
            "Time taken for 1 epoch 17.073296308517456 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.0080\n",
            "Epoch 6 Batch 100 Val. Loss 0.0190\n",
            "Epoch 6 Batch 200 Val. Loss 0.0016\n",
            "Epoch 6 Batch 300 Val. Loss 0.0181\n",
            "Epoch 6 Batch 400 Val. Loss 0.0048\n",
            "Epoch 6 Batch 500 Val. Loss 0.0320\n",
            "Epoch 6 Batch 600 Val. Loss 0.0249\n",
            "Epoch 6 Loss 0.0135 -- Train Acc. 96.4000 -- Val Acc. 93.3494\n",
            "Time taken for 1 epoch 17.07611393928528 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.0064\n",
            "Epoch 7 Batch 100 Val. Loss 0.0066\n",
            "Epoch 7 Batch 200 Val. Loss 0.0082\n",
            "Epoch 7 Batch 300 Val. Loss 0.0137\n",
            "Epoch 7 Batch 400 Val. Loss 0.0168\n",
            "Epoch 7 Batch 500 Val. Loss 0.0182\n",
            "Epoch 7 Batch 600 Val. Loss 0.0032\n",
            "Epoch 7 Loss 0.0116 -- Train Acc. 97.0225 -- Val Acc. 93.2692\n",
            "Time taken for 1 epoch 17.07490110397339 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.0059\n",
            "Epoch 8 Batch 100 Val. Loss 0.0186\n",
            "Epoch 8 Batch 200 Val. Loss 0.0069\n",
            "Epoch 8 Batch 300 Val. Loss 0.0144\n",
            "Epoch 8 Batch 400 Val. Loss 0.0106\n",
            "Epoch 8 Batch 500 Val. Loss 0.0282\n",
            "Epoch 8 Batch 600 Val. Loss 0.0409\n",
            "Epoch 8 Loss 0.0115 -- Train Acc. 97.2550 -- Val Acc. 93.0088\n",
            "Time taken for 1 epoch 17.047500133514404 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.0027\n",
            "Epoch 9 Batch 100 Val. Loss 0.0091\n",
            "Epoch 9 Batch 200 Val. Loss 0.0146\n",
            "Epoch 9 Batch 300 Val. Loss 0.0027\n",
            "Epoch 9 Batch 400 Val. Loss 0.0000\n",
            "Epoch 9 Batch 500 Val. Loss 0.0037\n",
            "Epoch 9 Batch 600 Val. Loss 0.0313\n",
            "Epoch 9 Loss 0.0100 -- Train Acc. 97.6825 -- Val Acc. 92.8686\n",
            "Time taken for 1 epoch 17.06778049468994 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.0009\n",
            "Epoch 10 Batch 100 Val. Loss 0.0080\n",
            "Epoch 10 Batch 200 Val. Loss 0.0015\n",
            "Epoch 10 Batch 300 Val. Loss 0.0148\n",
            "Epoch 10 Batch 400 Val. Loss 0.0144\n",
            "Epoch 10 Batch 500 Val. Loss 0.0279\n",
            "Epoch 10 Batch 600 Val. Loss 0.0009\n",
            "Epoch 10 Loss 0.0087 -- Train Acc. 98.1175 -- Val Acc. 93.3093\n",
            "Time taken for 1 epoch 16.98222780227661 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72jYWoxDSuDt",
        "colab_type": "code",
        "outputId": "f2285dad-045c-488e-b0e2-a08dbc1b9617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(27367, 256)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiF3LKuSuDu",
        "colab_type": "text"
      },
      "source": [
        "## 6. Evaluation on the Testing Data\n",
        "Now we will evaluate the model with the holdout dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IORQgwSuDv",
        "colab_type": "code",
        "outputId": "f8a53dcc-9dfa-4a47-bd42-c9773a59dbaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(\"cuda\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  92.52804487179488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTLKA47iSuDz",
        "colab_type": "text"
      },
      "source": [
        "### 6.1 Confusion Matrix\n",
        "The test accuracy alone is not an interesting performance metric in this case. Let's plot a confusion matrix to get a drilled down view of how the model is performing with regards to each emotion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM9g0v7sRTTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Class to Properly Evaluate our Models\n",
        "class Evaluate():\n",
        "\n",
        "    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n",
        "        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n",
        "        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n",
        "        y_va = target.dot(va_matrix)\n",
        "        F_va = prediction.dot(va_matrix)\n",
        "\n",
        "        # dist is a one row vector with size of the test data passed(emotion)\n",
        "        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n",
        "        res = stats.describe(dist)\n",
        "\n",
        "        # print by default (if silent=False)\n",
        "        if not silent:\n",
        "            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n",
        "\n",
        "        return {\n",
        "            'distances': dist,\n",
        "            'dist_stat': res\n",
        "        }\n",
        "\n",
        "    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n",
        "        \"\"\" Compute only the predicted class \"\"\"\n",
        "        p_2_annotation = dict()\n",
        "\n",
        "        precision_recall_fscore_support = [\n",
        "            (pair[0], pair[1].mean()) for pair in zip(\n",
        "                ['precision', 'recall', 'f1', 'support'],\n",
        "                metrics.precision_recall_fscore_support(target, predictions)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        metrics.precision_recall_fscore_support(target, predictions)\n",
        "\n",
        "        # confusion matrix\n",
        "        le = LabelEncoder()\n",
        "        target_le = le.fit_transform(target)\n",
        "        predictions_le = le.transform(predictions)\n",
        "        cm = metrics.confusion_matrix(target_le, predictions_le)\n",
        "\n",
        "        # prediction if two annotations are given on test data\n",
        "        if target2:\n",
        "            p_2_annotation = pd.DataFrame(\n",
        "                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n",
        "                columns=['emo','success']\n",
        "            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n",
        "\n",
        "        if not silent:\n",
        "            print(\"Default Classification report\")\n",
        "            print(metrics.classification_report(target, predictions))\n",
        "\n",
        "            # print if target2 was provided\n",
        "            if len(p_2_annotation) > 0:\n",
        "                print('\\nPrecision on 2 annotations:')\n",
        "                for emo in p_2_annotation:\n",
        "                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n",
        "\n",
        "            # print accuracies, precision, recall, and f1\n",
        "            print('\\nAccuracy:')\n",
        "            print(metrics.accuracy_score(target, predictions))\n",
        "            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n",
        "            for to_print in precision_recall_fscore_support[:3]:\n",
        "                print( \"%s: %.2f\" % to_print )\n",
        "\n",
        "            # normalizing the values of the consfusion matrix\n",
        "            print('\\nconfusion matrix\\n %s' % cm)\n",
        "            print('(row=expected, col=predicted)')\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n",
        "\n",
        "        return {\n",
        "            'precision_recall_fscore_support': precision_recall_fscore_support,\n",
        "            'accuracy': metrics.accuracy_score(target, predictions),\n",
        "            'p_2_annotation': p_2_annotation,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "    def predict_class(cls, X_train, y_train, X_test, y_test,\n",
        "                      pipeline, silent=False, target2=None):\n",
        "        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict(X_test)\n",
        "        print(\"predictions computed....\")\n",
        "        return cls.evaluate_class(predictions, y_test, target2, silent)\n",
        "\n",
        "    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Evaluate through probability \"\"\"\n",
        "        # Run normal class evaluator\n",
        "        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n",
        "        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n",
        "\n",
        "        if not silent:\n",
        "            print('\\n - First Emotion Classification Metrics -')\n",
        "            print('\\n - Multiple Emotion rank Metrics -')\n",
        "            print('VA Cosine Distance')\n",
        "\n",
        "        classes_dist = [\n",
        "            (\n",
        "                emo,\n",
        "                cls.va_dist(\n",
        "                    prediction[np.array(target_class) == emo],\n",
        "                    target_rank[np.array(target_class) == emo],\n",
        "                    va_df,\n",
        "                    binarizer,\n",
        "                    emo,\n",
        "                    silent)\n",
        "                ) for emo in binarizer.classes_\n",
        "        ]\n",
        "        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n",
        "\n",
        "        coverage_error = metrics.coverage_error(target_rank, prediction)\n",
        "        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n",
        "        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n",
        "        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n",
        "\n",
        "        # recall at 2\n",
        "        # obtain top two predictions\n",
        "        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n",
        "        recall_at_2 = pd.DataFrame(\n",
        "            [\n",
        "            t in p for t, p in zip(target_class, top2_pred)\n",
        "            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n",
        "\n",
        "        # combine target into sets\n",
        "        if target2:\n",
        "            union_target = [set(t) for t in zip(target_class, target2)]\n",
        "        else:\n",
        "            union_target = [set(t) for t in zip(target_class)]\n",
        "\n",
        "        # precision at k\n",
        "        top_k_pred = [\n",
        "            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n",
        "            for i in range(2, len(binarizer.classes_)+1)]\n",
        "        precision_at_k = [\n",
        "            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n",
        "            for k in range(len(top_k_pred))]\n",
        "\n",
        "        # do this if silent= False\n",
        "        if not silent:\n",
        "            print('\\n')\n",
        "            print(recall_at_2)\n",
        "            print('\\n')\n",
        "            print('p@k')\n",
        "            for pk in precision_at_k:\n",
        "                print(pk[0] + ':\\t' + str(pk[1]))\n",
        "            print('\\ncoverage_error: %f' % coverage_error)\n",
        "            print('average_precision_score: %f' % average_precision_score)\n",
        "            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n",
        "            print('label_ranking_loss: %f' % label_ranking_loss)\n",
        "\n",
        "        return {\n",
        "            'class_eval': class_eval,\n",
        "            'recall_at_2': recall_at_2.to_dict(),\n",
        "            'precision_at_2': precision_at_k,\n",
        "            'classes_dist': classes_dist,\n",
        "            'avg_dist': avg_dist,\n",
        "            'coverage_error': coverage_error,\n",
        "            'average_precision_score': average_precision_score,\n",
        "            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n",
        "            'label_ranking_loss': label_ranking_loss\n",
        "        }\n",
        "\n",
        "\n",
        "    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Output predcations based on training and labels \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict_proba(X_test)\n",
        "        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n",
        "        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\" Plotting the confusion_matrix\"\"\"\n",
        "        plt.rc('figure', figsize=(4, 4), dpi=100)\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(my_tags))\n",
        "        target_names = my_tags\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "        \n",
        "        # add normalized values inside the Confusion matrix\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUWz-LBSuDz",
        "colab_type": "code",
        "outputId": "9a33d83a-46e9-49ed-9b31-7496ed7b3b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "evaluator = Evaluate()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p.cpu().detach().numpy())\n",
        "        \n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
        "\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n",
        "\n",
        "model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n",
        "test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.emotion, test.emotion );"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Classification report\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "      anger       0.91      0.95      0.93       699\n",
            "       fear       0.91      0.88      0.89       533\n",
            "        joy       0.95      0.95      0.95      1721\n",
            "       love       0.81      0.85      0.83       404\n",
            "    sadness       0.98      0.97      0.97      1468\n",
            "   surprise       0.83      0.74      0.78       167\n",
            "\n",
            "avg / total       0.93      0.93      0.93      4992\n",
            "\n",
            "\n",
            "Accuracy:\n",
            "0.9324919871794872\n",
            "Correct Predictions:  4655\n",
            "precision: 0.90\n",
            "recall: 0.89\n",
            "f1: 0.89\n",
            "\n",
            "confusion matrix\n",
            " [[ 667   10   12    1    9    0]\n",
            " [  22  467    2    1   19   22]\n",
            " [   4    0 1635   74    5    3]\n",
            " [   0    1   59  344    0    0]\n",
            " [  36    6    5    3 1418    0]\n",
            " [   0   29   13    0    1  124]]\n",
            "(row=expected, col=predicted)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAGFCAYAAAAvsY4uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLD7DGhmLxWKx+AxrZCwWi8XiM/4PZv/ckn0aOhwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6e138510f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTCznkUGSuD3",
        "colab_type": "text"
      },
      "source": [
        "## Final Words\n",
        "You have learned how to perform neural-based emotion recognition using RNNs. There are many things you can do after you have completed this tutorial. You can attempt the exercises outlined in the \"Outline\" section of this notebook. You can also try other types of neural architectures such as LSTMs, Bi-LSTMS, attentions models, and CNNs. In addition, you can also store the models and conduct transfer learning to other emotion-related tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbkPHgFSuD3",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLfZrr2oSuD4",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "- [Deep Learning for NLP](https://docs.google.com/presentation/d/1cf2H1qMvP1rdKUF5000ifOIRv1_b0bvj0ZTVL7-RaVE/edit?usp=sharing)\n",
        "- [PyTorch Autograd Tutorial](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
        "- [A Simple Neural Network from Scratch with PyTorch and Google Colab](https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0)\n",
        "- [Building RNNs is Fun with PyTorch and Google Colab](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79?source=collection_home---4------2---------------------)\n",
        "- [Deep Learning for NLP: An Overview of Recent Trends](https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d)"
      ]
    }
  ]
}