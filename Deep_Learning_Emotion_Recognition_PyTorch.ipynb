{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Emotion Recognition PyTorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/Deep_Learning_Emotion_Recognition_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StfRpRW1SuBw",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Based Emotion Recognition with PyTorch\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/emotion_classifier.png?raw=true)\n",
        "\n",
        "In this notebook we are going to learn how to train deep neural networks, such as recurrent neural networks (RNNs), for addressing a natural language task known as **emotion recognition**. We will cover everything you need to know to get started with NLP using deep learning frameworks such as TensorFlow. We will cover the common best practices, functionalities, and steps you need to understand the basics of TensorFlow APIs to build powerful predictive models via the computation graph. In the process of building our models, we will compare PyTorch and TensorFlow to let the learner appreciate the strenghts of each tool.\n",
        "\n",
        "by [Elvis Saravia](https://twitter.com/omarsar0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIkM141cSuBz",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrz3-nSrSuB1",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "1. Deep Learning Frameworks\n",
        "     - 1.1 Eager execution\n",
        "     - 1.2 Computation graph\n",
        "2. Tensors\n",
        "    - 2.1 Basic math with tensors\n",
        "    - 2.2 Transforming tensors\n",
        "3. Data\n",
        "    - 3.1 Preprocessing data\n",
        "        - Tokenization and Sampling\n",
        "        - Constructing Vocabulary and Index-Word Mapping\n",
        "    - 3.2 Converting data into tensors\n",
        "    - 3.3 Padding data\n",
        "    - 3.4 Binarization\n",
        "    - 3.5 Split data\n",
        "    - 3.6 Data Loader\n",
        "4. Model\n",
        "    - 4.1 Pretesting Model\n",
        "    - 4.2 Testing models with eager execution\n",
        "5. Training\n",
        "6. Evaluation on Testing Dataset\n",
        "    - 6.1 Confusion matrix\n",
        "- Final Words\n",
        "- References\n",
        "- *Storing models and setting checkpoints (Exercise)*\n",
        "- *Restoring models (Exercise)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy9JWaqqSuB1",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbWgC0tSuB3",
        "colab_type": "text"
      },
      "source": [
        "## 1. Deep Learning Frameworks\n",
        "There are many deep learning frameworks such as Chainer, DyNet, MXNet, PyTorch, TensorFlow, and Keras. Each framework has their own strenghts which a researcher or a developer may want to consider before choosing the right framework. In my opinion, PyTorch is great for researchers and offers eager execution by default, but its high-level APIs require some understanding of deep learning concepts such as **affine layers** and **automatic differentiation**. On the other hand, TensorFlow was originally built as a low-level API that provides a robust list of functionalities to build deep learning models from the ground up. More recently, TensorFlow also offers **eager execution** and is equipped with a high-level API known as Keras.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/dl_frameworks.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suv8DnrQSuB5",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Eager Execution\n",
        "Eager execution allows us to operate on the computation graph dynamically, also known as **imperative programming**. TensorFlow requires that you manually set this mode, while PyTorch comes with this mode by default. Below we import the necessary libraries to use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CURzvVldMJcU",
        "colab_type": "code",
        "outputId": "84d131ce-d1c5-488b-bea8-8b90cffc829b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUazzVHSuB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK69ztCKSuB-",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Computation Graph\n",
        "A simplified definition of a neural network is a string of functions that are **differentiable** and that we can combine together to get more complicated functions. An intuitive way to express this process is through computation graphs. \n",
        "\n",
        "![alt txt](http://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png)\n",
        "\n",
        "Image credit: [Chris Olah](http://colah.github.io/posts/2015-08-Backprop/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6243JBwQSuB_",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensors\n",
        "Tensors are the fundamental data structure used to store data that will be fed as input to a computation graph for processing and applying tranformations. Let's create two tensors and multiply them, and then output the result. The figure below shows a 4-D Tensor.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/tensor.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72g6eRGSuCA",
        "colab_type": "code",
        "outputId": "db89cbc8-48c9-4534-ccf1-a6eb2c7355bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "c = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "d = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n",
        "e = torch.matmul(c, d)\n",
        "print(e)\n",
        "print(c.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 3.],\n",
            "        [3., 7.]])\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTM0Y6hSuCF",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Math with Tensors\n",
        "PyTorch and other deep learning libraries like TensorFlow allow you to do **automatic differentation**. Let's try to compute the derivative of a function -- in this case that function is stored in the variable `z`. In PyTorch, the option `requires_grad=True` tracks all operations applied to the input tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855r1t0MSuCG",
        "colab_type": "code",
        "outputId": "4769ffbb-f831-4298-a536-b6e80cf72dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "### Automatic differentiation with PyTorch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "# an operation of tensor\n",
        "y = x + 2 # y inherits grad_fn\n",
        "\n",
        "# apply operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(out)\n",
        "\n",
        "out.backward()\n",
        "\n",
        "print(x.grad) # d(out)/dx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(27., grad_fn=<MeanBackward1>)\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwHvtrCLSuCK",
        "colab_type": "text"
      },
      "source": [
        "You can verfiy the output with the equations in the figure below:\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/autograd.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6j5_2wFSuCL",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Transforming Tensors\n",
        "We can also apply some transformation to a tensor such as adding a dimension or transposing it. Let's try both adding a dimension and transposing a matrix below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT8u_3rzSuCL",
        "colab_type": "code",
        "outputId": "6018aee4-08ab-4995-eeb7-005710f7835e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"X shape: \", x.size())\n",
        "\n",
        "# add dimension\n",
        "print(x.unsqueeze(1).size()) \n",
        "\n",
        "# transpose \n",
        "torch.transpose(x, 0,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:  torch.Size([2, 3])\n",
            "torch.Size([2, 1, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggtl1m6aSuCP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Emotion Dataset\n",
        "In this notebook we are working on an emotion classification task. The dataset contains tweets labeled into 6 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JqoUiTSuCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVCiiFsBNbuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bliFaijvNfIZ",
        "colab_type": "code",
        "outputId": "920e6afd-3d48-43c7-aeba-9a5a71a78544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2qHNv2-N9BC",
        "colab_type": "text"
      },
      "source": [
        "We had already processed the data for you. You can find the pickle file [here](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/data/merged_training.pkl)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2sYWY79SuCS",
        "colab_type": "code",
        "outputId": "addad417-0c23-424a-e7b6-17f8cc154591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# load data\n",
        "data = load_from_pickle(directory=\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/merged_training.pkl\")\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd7d7f66470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqEpIREREVUIiIiKqEhIREVH1/wGfA/dLdXaziQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNSP0G-SuCV",
        "colab_type": "code",
        "outputId": "7d76de0d-dc6d-43e8-9b2c-a78c2c368c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "data.head(5)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-80c7d069447b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nI00TmkSuCY",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Preprocessing Data\n",
        "In the next steps we are going to create tokenize the text, create index mapping for words, and also construct a vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCHxi2ASuCZ",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDgIXGGSuCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=10000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNrOA7mSuCe",
        "colab_type": "text"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KouYEDoNSuCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFasv0ASuCi",
        "colab_type": "code",
        "outputId": "6793d5cc-aefe-4eef-c3f2-b68fd4004c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aa',\n",
              " 'aaah',\n",
              " 'aaron',\n",
              " 'ab',\n",
              " 'aba',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abandoning',\n",
              " 'abby']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqf0tC3FSuCk",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Converting Data into Tensors \n",
        "For convenience we would like to convert the data into tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omlfNU8hSuCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AphKgs33SuCn",
        "colab_type": "code",
        "outputId": "464211ec-526b-4a6b-b215-f0e21df00c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]\n",
        "type(input_tensor)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoIfZHjSuCr",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Padding data\n",
        "In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbSHvs0SuCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zyXKoy6SuCw",
        "colab_type": "code",
        "outputId": "e635ee46-cb50-416e-c292-f913fa715465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk71VEPSuC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wKDdBCSuC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dok2XcWSuC7",
        "colab_type": "code",
        "outputId": "ea15d595-d8a6-4fc0-e6fe-f5f0e0745338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 5060,  8550,  4981,  5060, 11198, 10660,  3830, 11480, 10931,\n",
              "          389,  9120,  8966,  8870,  7164,  7809,   905,  9276, 11463,\n",
              "          380,  5329, 10660,  6401,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0]),\n",
              " array([ 5060,   351,  4334, 10486,  3833,   584,  5095,  5502,  5478,\n",
              "            1,  4396,  2571,  5182, 10486,  6686,  7117,  5645,  5182,\n",
              "         6919,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBN6xAsGSuDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_369xrpSuDC",
        "colab_type": "code",
        "outputId": "cd597685-1c5d-401b-d4ce-fb097469cf3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "target_tensor[0:2] "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZMnNbUSuDF",
        "colab_type": "code",
        "outputId": "8cbb77c5-16e5-4454-9d50-059cae7db377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74807</th>\n",
              "      <td>i feel very welcomed and comfortable around th...</td>\n",
              "      <td>joy</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4666</th>\n",
              "      <td>i am feeling at weeks since i got no sleep las...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text emotions  token_size\n",
              "74807  i feel very welcomed and comfortable around th...      joy          12\n",
              "4666   i am feeling at weeks since i got no sleep las...  sadness          20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCgbz5icSuDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bI6rF59SuDK",
        "colab_type": "code",
        "outputId": "0e219674-bd37-4453-9cf6-65eb9c5161f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxi-STseSuDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRkO7WISuDN",
        "colab_type": "code",
        "outputId": "07352b56-f017-452e-a697-d3489df8d845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fear'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWDE42iSuDQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Split data\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQuGQReSuDR",
        "colab_type": "code",
        "outputId": "32030b9d-806e-46ce-9dca-170f45c02e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 8000, 1000, 1000, 1000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ0GXI9SuDX",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 Data Loader\n",
        "We can also laod the data into a data loader, which makes it easy to **manipulate the data**, **create batches**, and apply further **transformations**. In PyTorch we can use the `DataLoader` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xtwf8nSuDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDa8eJVSuDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0Of7YiSuDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgVVs1XSuDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQNqg9xSuDe",
        "colab_type": "code",
        "outputId": "649732d3-4821-4a9a-dc34-0723d2871a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_dataset.batch_size\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqYHyFGwSuDh",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model\n",
        "After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details. \n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/gru-model.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHYthQdSuDi",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Constructing the Model\n",
        "Below we construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVXtMhf3SuDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6GVV87SuDk",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Pretesting model\n",
        "Since eager execution is enabled we can print the output of the model by passing a sample of the dataset and making sure that the dimensions of the outputs are the expected ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjomHaHbSuDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhymNqRSuDn",
        "colab_type": "code",
        "outputId": "f03e24d4-811e-49d3-ec18-537c76c4bf1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(output.size())"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([68, 64])\n",
            "torch.Size([64, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRXfA2NSuDp",
        "colab_type": "text"
      },
      "source": [
        "## 5. Training the Model\n",
        "Now that we have tested the model, it is time to train it. We will define out optimization algorithm, learnin rate, and other necessary information to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFuDTsrUSuDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyvsSQrPSuDr",
        "colab_type": "code",
        "outputId": "9f75fbeb-8281-4e14-fc5a-e1282248fc93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.2955\n",
            "Epoch 1 Batch 100 Val. Loss 0.2887\n",
            "Epoch 1 Loss 0.2752 -- Train Acc. 31.7000 -- Val Acc. 33.5417\n",
            "Time taken for 1 epoch 3.3083267211914062 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.2792\n",
            "Epoch 2 Batch 100 Val. Loss 0.2223\n",
            "Epoch 2 Loss 0.2400 -- Train Acc. 44.0500 -- Val Acc. 60.2083\n",
            "Time taken for 1 epoch 3.2931888103485107 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.1641\n",
            "Epoch 3 Batch 100 Val. Loss 0.0608\n",
            "Epoch 3 Loss 0.0965 -- Train Acc. 80.5250 -- Val Acc. 82.6042\n",
            "Time taken for 1 epoch 3.2900993824005127 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.0319\n",
            "Epoch 4 Batch 100 Val. Loss 0.0603\n",
            "Epoch 4 Loss 0.0351 -- Train Acc. 92.4000 -- Val Acc. 86.8750\n",
            "Time taken for 1 epoch 3.2901852130889893 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.0057\n",
            "Epoch 5 Batch 100 Val. Loss 0.0179\n",
            "Epoch 5 Loss 0.0191 -- Train Acc. 95.9000 -- Val Acc. 87.1875\n",
            "Time taken for 1 epoch 3.296642541885376 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.0088\n",
            "Epoch 6 Batch 100 Val. Loss 0.0044\n",
            "Epoch 6 Loss 0.0139 -- Train Acc. 96.8875 -- Val Acc. 88.3333\n",
            "Time taken for 1 epoch 3.271275520324707 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.0027\n",
            "Epoch 7 Batch 100 Val. Loss 0.0073\n",
            "Epoch 7 Loss 0.0094 -- Train Acc. 97.7625 -- Val Acc. 88.6458\n",
            "Time taken for 1 epoch 3.2885892391204834 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.0034\n",
            "Epoch 8 Batch 100 Val. Loss 0.0050\n",
            "Epoch 8 Loss 0.0063 -- Train Acc. 98.7125 -- Val Acc. 86.9792\n",
            "Time taken for 1 epoch 3.2981081008911133 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.0050\n",
            "Epoch 9 Batch 100 Val. Loss 0.0035\n",
            "Epoch 9 Loss 0.0061 -- Train Acc. 98.8375 -- Val Acc. 86.2500\n",
            "Time taken for 1 epoch 3.2901382446289062 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.0017\n",
            "Epoch 10 Batch 100 Val. Loss 0.0011\n",
            "Epoch 10 Loss 0.0042 -- Train Acc. 99.1875 -- Val Acc. 88.2292\n",
            "Time taken for 1 epoch 3.2902073860168457 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72jYWoxDSuDt",
        "colab_type": "code",
        "outputId": "19d76405-7f79-42ee-8215-68cc36648e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(11899, 256)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiF3LKuSuDu",
        "colab_type": "text"
      },
      "source": [
        "## 6. Evaluation on the Testing Data\n",
        "Now we will evaluate the model with the holdout dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IORQgwSuDv",
        "colab_type": "code",
        "outputId": "1825810a-445d-4dda-887f-e0e5293abdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(\"cuda\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  88.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTLKA47iSuDz",
        "colab_type": "text"
      },
      "source": [
        "### 6.1 Confusion Matrix\n",
        "The test accuracy alone is not an interesting performance metric in this case. Let's plot a confusion matrix to get a drilled down view of how the model is performing with regards to each emotion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM9g0v7sRTTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Class to Properly Evaluate our Models\n",
        "class Evaluate():\n",
        "\n",
        "    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n",
        "        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n",
        "        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n",
        "        y_va = target.dot(va_matrix)\n",
        "        F_va = prediction.dot(va_matrix)\n",
        "\n",
        "        # dist is a one row vector with size of the test data passed(emotion)\n",
        "        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n",
        "        res = stats.describe(dist)\n",
        "\n",
        "        # print by default (if silent=False)\n",
        "        if not silent:\n",
        "            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n",
        "\n",
        "        return {\n",
        "            'distances': dist,\n",
        "            'dist_stat': res\n",
        "        }\n",
        "\n",
        "    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n",
        "        \"\"\" Compute only the predicted class \"\"\"\n",
        "        p_2_annotation = dict()\n",
        "\n",
        "        precision_recall_fscore_support = [\n",
        "            (pair[0], pair[1].mean()) for pair in zip(\n",
        "                ['precision', 'recall', 'f1', 'support'],\n",
        "                metrics.precision_recall_fscore_support(target, predictions)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        metrics.precision_recall_fscore_support(target, predictions)\n",
        "\n",
        "        # confusion matrix\n",
        "        le = LabelEncoder()\n",
        "        target_le = le.fit_transform(target)\n",
        "        predictions_le = le.transform(predictions)\n",
        "        cm = metrics.confusion_matrix(target_le, predictions_le)\n",
        "\n",
        "        # prediction if two annotations are given on test data\n",
        "        if target2:\n",
        "            p_2_annotation = pd.DataFrame(\n",
        "                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n",
        "                columns=['emo','success']\n",
        "            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n",
        "\n",
        "        if not silent:\n",
        "            print(\"Default Classification report\")\n",
        "            print(metrics.classification_report(target, predictions))\n",
        "\n",
        "            # print if target2 was provided\n",
        "            if len(p_2_annotation) > 0:\n",
        "                print('\\nPrecision on 2 annotations:')\n",
        "                for emo in p_2_annotation:\n",
        "                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n",
        "\n",
        "            # print accuracies, precision, recall, and f1\n",
        "            print('\\nAccuracy:')\n",
        "            print(metrics.accuracy_score(target, predictions))\n",
        "            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n",
        "            for to_print in precision_recall_fscore_support[:3]:\n",
        "                print( \"%s: %.2f\" % to_print )\n",
        "\n",
        "            # normalizing the values of the consfusion matrix\n",
        "            print('\\nconfusion matrix\\n %s' % cm)\n",
        "            print('(row=expected, col=predicted)')\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n",
        "\n",
        "        return {\n",
        "            'precision_recall_fscore_support': precision_recall_fscore_support,\n",
        "            'accuracy': metrics.accuracy_score(target, predictions),\n",
        "            'p_2_annotation': p_2_annotation,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "    def predict_class(cls, X_train, y_train, X_test, y_test,\n",
        "                      pipeline, silent=False, target2=None):\n",
        "        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict(X_test)\n",
        "        print(\"predictions computed....\")\n",
        "        return cls.evaluate_class(predictions, y_test, target2, silent)\n",
        "\n",
        "    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Evaluate through probability \"\"\"\n",
        "        # Run normal class evaluator\n",
        "        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n",
        "        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n",
        "\n",
        "        if not silent:\n",
        "            print('\\n - First Emotion Classification Metrics -')\n",
        "            print('\\n - Multiple Emotion rank Metrics -')\n",
        "            print('VA Cosine Distance')\n",
        "\n",
        "        classes_dist = [\n",
        "            (\n",
        "                emo,\n",
        "                cls.va_dist(\n",
        "                    prediction[np.array(target_class) == emo],\n",
        "                    target_rank[np.array(target_class) == emo],\n",
        "                    va_df,\n",
        "                    binarizer,\n",
        "                    emo,\n",
        "                    silent)\n",
        "                ) for emo in binarizer.classes_\n",
        "        ]\n",
        "        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n",
        "\n",
        "        coverage_error = metrics.coverage_error(target_rank, prediction)\n",
        "        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n",
        "        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n",
        "        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n",
        "\n",
        "        # recall at 2\n",
        "        # obtain top two predictions\n",
        "        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n",
        "        recall_at_2 = pd.DataFrame(\n",
        "            [\n",
        "            t in p for t, p in zip(target_class, top2_pred)\n",
        "            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n",
        "\n",
        "        # combine target into sets\n",
        "        if target2:\n",
        "            union_target = [set(t) for t in zip(target_class, target2)]\n",
        "        else:\n",
        "            union_target = [set(t) for t in zip(target_class)]\n",
        "\n",
        "        # precision at k\n",
        "        top_k_pred = [\n",
        "            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n",
        "            for i in range(2, len(binarizer.classes_)+1)]\n",
        "        precision_at_k = [\n",
        "            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n",
        "            for k in range(len(top_k_pred))]\n",
        "\n",
        "        # do this if silent= False\n",
        "        if not silent:\n",
        "            print('\\n')\n",
        "            print(recall_at_2)\n",
        "            print('\\n')\n",
        "            print('p@k')\n",
        "            for pk in precision_at_k:\n",
        "                print(pk[0] + ':\\t' + str(pk[1]))\n",
        "            print('\\ncoverage_error: %f' % coverage_error)\n",
        "            print('average_precision_score: %f' % average_precision_score)\n",
        "            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n",
        "            print('label_ranking_loss: %f' % label_ranking_loss)\n",
        "\n",
        "        return {\n",
        "            'class_eval': class_eval,\n",
        "            'recall_at_2': recall_at_2.to_dict(),\n",
        "            'precision_at_2': precision_at_k,\n",
        "            'classes_dist': classes_dist,\n",
        "            'avg_dist': avg_dist,\n",
        "            'coverage_error': coverage_error,\n",
        "            'average_precision_score': average_precision_score,\n",
        "            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n",
        "            'label_ranking_loss': label_ranking_loss\n",
        "        }\n",
        "\n",
        "\n",
        "    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Output predcations based on training and labels \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict_proba(X_test)\n",
        "        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n",
        "        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\" Plotting the confusion_matrix\"\"\"\n",
        "        plt.rc('figure', figsize=(4, 4), dpi=100)\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(my_tags))\n",
        "        target_names = my_tags\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "        \n",
        "        # add normalized values inside the Confusion matrix\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUWz-LBSuDz",
        "colab_type": "code",
        "outputId": "68b12153-afcd-4a8c-c5e6-5221a79a939e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "evaluator = Evaluate()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p.cpu().detach().numpy())\n",
        "        \n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
        "\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n",
        "\n",
        "model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n",
        "test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.emotion, test.emotion );"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.92      0.88      0.90       129\n",
            "        fear       0.89      0.87      0.88       117\n",
            "         joy       0.86      0.94      0.90       323\n",
            "        love       0.78      0.72      0.75        72\n",
            "     sadness       0.93      0.90      0.91       293\n",
            "    surprise       0.82      0.69      0.75        26\n",
            "\n",
            "    accuracy                           0.89       960\n",
            "   macro avg       0.87      0.83      0.85       960\n",
            "weighted avg       0.89      0.89      0.89       960\n",
            "\n",
            "\n",
            "Accuracy:\n",
            "0.8875\n",
            "Correct Predictions:  852\n",
            "precision: 0.87\n",
            "recall: 0.83\n",
            "f1: 0.85\n",
            "\n",
            "confusion matrix\n",
            " [[113   1   7   1   7   0]\n",
            " [  1 102   3   0   8   3]\n",
            " [  2   3 304  11   3   0]\n",
            " [  0   0  19  52   0   1]\n",
            " [  7   4  17   2 263   0]\n",
            " [  0   4   2   1   1  18]]\n",
            "(row=expected, col=predicted)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAGFCAYAAADJmEVqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTCznkUGSuD3",
        "colab_type": "text"
      },
      "source": [
        "## Final Words\n",
        "You have learned how to perform neural-based emotion recognition using RNNs. There are many things you can do after you have completed this tutorial. You can attempt the exercises outlined in the \"Outline\" section of this notebook. You can also try other types of neural architectures such as LSTMs, Bi-LSTMS, attentions models, and CNNs. In addition, you can also store the models and conduct transfer learning to other emotion-related tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbkPHgFSuD3",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLfZrr2oSuD4",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "- [Deep Learning for NLP](https://docs.google.com/presentation/d/1cf2H1qMvP1rdKUF5000ifOIRv1_b0bvj0ZTVL7-RaVE/edit?usp=sharing)\n",
        "- [PyTorch Autograd Tutorial](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
        "- [A Simple Neural Network from Scratch with PyTorch and Google Colab](https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0)\n",
        "- [Building RNNs is Fun with PyTorch and Google Colab](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79?source=collection_home---4------2---------------------)\n",
        "- [Deep Learning for NLP: An Overview of Recent Trends](https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d)"
      ]
    }
  ]
}