{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STS2 - BERT FT 3 convert to binary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dab28e41b97c43c690becb5f9da76ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_43195197412f4fd1aa147f9bd7db1716",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a005428a07d4bf3b6b48fa8a25a1095",
              "IPY_MODEL_6b57cad586c74258a854acd2007f5e55"
            ]
          }
        },
        "43195197412f4fd1aa147f9bd7db1716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a005428a07d4bf3b6b48fa8a25a1095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d142be0b4e442e78519166bd4f565f0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c37f32c0bc894ace934b08e74a5d2c31"
          }
        },
        "6b57cad586c74258a854acd2007f5e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f60b5b730b64a138b42a01bc0439ffb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.34MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36aac0d7bd124becaf083133fbbb1bb0"
          }
        },
        "1d142be0b4e442e78519166bd4f565f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c37f32c0bc894ace934b08e74a5d2c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f60b5b730b64a138b42a01bc0439ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36aac0d7bd124becaf083133fbbb1bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e9b1dc05ec34fe085b45bd9bcc9da94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acc43f04797148ddacfc36a8e93077e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b8e6d8344eb4a46b61ee6f51fb28a11",
              "IPY_MODEL_2529526c9ae84e58af8d6e21cb43b958"
            ]
          }
        },
        "acc43f04797148ddacfc36a8e93077e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b8e6d8344eb4a46b61ee6f51fb28a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7dbfac4919624a7e857b5583e0bc7b0b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2abfd5059c77401bacc90ae9c0661f59"
          }
        },
        "2529526c9ae84e58af8d6e21cb43b958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e360a993d154194ac0769043782ed41",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:04&lt;00:00, 90.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5133dd240f6f4d05a452894f5151c839"
          }
        },
        "7dbfac4919624a7e857b5583e0bc7b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2abfd5059c77401bacc90ae9c0661f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e360a993d154194ac0769043782ed41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5133dd240f6f4d05a452894f5151c839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94eb8c492dca4d9b81bb01ec02619d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f872b533a08f45bf96a6a30864cef44c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98372bc24b4d46f19ed910061c91a3b8",
              "IPY_MODEL_c40e9556116244c8a47236fe508690b3"
            ]
          }
        },
        "f872b533a08f45bf96a6a30864cef44c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98372bc24b4d46f19ed910061c91a3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96c89bc486324bfdbcb15049618691f8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_997a1b1460cd46978c674dc2e212dcab"
          }
        },
        "c40e9556116244c8a47236fe508690b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fe9f18152ce543b2be17b9e57de02ac1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:04&lt;00:00, 57.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_938bfee88f5c464b8ad2560b1abd5224"
          }
        },
        "96c89bc486324bfdbcb15049618691f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "997a1b1460cd46978c674dc2e212dcab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe9f18152ce543b2be17b9e57de02ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "938bfee88f5c464b8ad2560b1abd5224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/STS2_BERT_FT_3_convert_to_binary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9ENLU90WGl",
        "colab_type": "code",
        "outputId": "0f70127e-1b1e-4194-eafe-73a59206988d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 573kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 34.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.46)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.46 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.46)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=aa735e989ebdd5d59134a445c71fb1de04701abc96b4b09751a58222d82c186c\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import clear_output\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNdAPjA3-exk",
        "colab_type": "text"
      },
      "source": [
        "Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1yaW1WK-VQ5",
        "colab_type": "code",
        "outputId": "17d36309-8f99-4a5e-bab3-131e95596e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Import Training, Validation and Test csvs\n",
        "# STS2\n",
        "#data = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
        "# 6 Emotions\n",
        "#data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "# IMDB data (from Kaggle)\n",
        "#data = pd.read_csv(r\"/gdrive/My Drive/DataSet/IMDB/train2.csv\")\n",
        "# STS2 from GLUE \n",
        "data = pd.read_csv(\"/gdrive/My Drive/DataSet/GLUE/STS2/SST-2/train.tsv\", delimiter='\\t', header=None)\n",
        "\n",
        "text_col=data.columns.values[0] \n",
        "category_col=data.columns.values[1]\n",
        "\n",
        "data.head"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                        0      1\n",
              "0                                               sentence  label\n",
              "1           hide new secretions from the parental units       0\n",
              "2                   contains no wit , only labored gags       0\n",
              "3      that loves its characters and communicates som...      1\n",
              "4      remains utterly satisfied to remain the same t...      0\n",
              "...                                                  ...    ...\n",
              "67345                               a delightful comedy       1\n",
              "67346                   anguish , anger and frustration       0\n",
              "67347  at achieving the modest , crowd-pleasing goals...      1\n",
              "67348                                  a patient viewer       1\n",
              "67349  this new jangle of noise , mayhem and stupidit...      0\n",
              "\n",
              "[67350 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM0uqhO771Aa",
        "colab_type": "text"
      },
      "source": [
        "Init and set data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGvBvbzo8P3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_SIZE=0.2\n",
        "RANDOM_STATE=1\n",
        "SAMPLE_SIZE = 8000\n",
        "UNLABEL_SIZE = 5000\n",
        "AUG_SIZE = 4000\n",
        "\n",
        "max_bert_len = 70\n",
        "\n",
        "BATCH_SIZE=64\n",
        "EPOCHS =3\n",
        "HIDDEN_SIZE=768\n",
        "\n",
        "catagories=list(set(data[category_col].unique()))\n",
        "OUTPUT_DIM= 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmOj02o32X5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#aug_data_sample=aug_data.sample(n=AUG_SIZE,random_state=RANDOM_STATE)\n",
        "#aug_texts=aug_data_sample[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9fP0WJE902X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1 = data.sample(n=SAMPLE_SIZE, random_state=RANDOM_STATE);\n",
        "residue_batch = data.drop(batch_1.index)\n",
        "unlabel_texts_batch = residue_batch.sample(n=UNLABEL_SIZE, random_state=RANDOM_STATE);\n",
        "unlabel_texts=unlabel_texts_batch[text_col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umj451aL73Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(batch_1[text_col],batch_1[category_col], test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DKJtD0MvY0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "422ef176-ed25-4579-e468-95adb0e63409"
      },
      "source": [
        "list(set(test_labels.unique()))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJm9b68jDQkU",
        "colab_type": "code",
        "outputId": "f713a726-c7e0-47dd-b353-7eaaaa6d1c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_texts), len(test_texts), len(train_labels), len(test_labels)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6400, 1600, 6400, 1600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn5EAD-Q7aK-",
        "colab_type": "text"
      },
      "source": [
        "1. Ngram baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXghfhlK7euk",
        "colab_type": "code",
        "outputId": "2ca6b3bb-314d-4026-a753-7227fe893c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#CounterVecorizer(ngram_range=(1,3), min_df=0.2, max_df=0.7, max_features=10000, stop_words=\"english\")\n",
        "ngramCount_baseline_model = make_pipeline(TfidfVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "#ngramCount_baseline_model = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "#ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,2),stop_words=\"english\",max_features=30000, max_df=0.75), LogisticRegression()).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))\n",
        "print(confusion_matrix(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.65      0.73       705\n",
            "           1       0.77      0.90      0.83       895\n",
            "\n",
            "    accuracy                           0.79      1600\n",
            "   macro avg       0.80      0.78      0.78      1600\n",
            "weighted avg       0.80      0.79      0.79      1600\n",
            "\n",
            "[[458 247]\n",
            " [ 88 807]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmX-GoxI8k7a",
        "colab_type": "code",
        "outputId": "6711c82d-3175-4568-a162-591db6069fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ngramCount_baseline_model.score(test_texts,test_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.791"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV5JKT_OgY28",
        "colab_type": "text"
      },
      "source": [
        "1.1 NGRAM SGDClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzX_AnPKgfpD",
        "colab_type": "code",
        "outputId": "a51eca62-622e-4ae6-d731-b9eb21652ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ngramCount_baseline_model = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), SGDClassifier(loss = 'log')).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))\n",
        "print(confusion_matrix(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.66      0.71       175\n",
            "           1       0.76      0.85      0.80       225\n",
            "\n",
            "    accuracy                           0.77       400\n",
            "   macro avg       0.77      0.75      0.76       400\n",
            "weighted avg       0.77      0.77      0.76       400\n",
            "\n",
            "[[115  60]\n",
            " [ 34 191]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xFW4m2pnpKz",
        "colab_type": "text"
      },
      "source": [
        "2. Glove mean Logistic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5LiZUqyOnOz",
        "colab_type": "code",
        "outputId": "ec82f394-d90d-44e4-b75f-cc5657ac81cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JDXtXNRn0PH",
        "colab_type": "code",
        "outputId": "768ea0ef-b5c2-4c75-b256-1cca30539b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define dict to hold a word and its vector\n",
        "glove = {}\n",
        "# read the word embeddings file ~820MB\n",
        "f = open('/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/glove.6B.100d.txt', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    glove[word] = coefs\n",
        "f.close()\n",
        "# check the length\n",
        "len(glove) # 400000"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyInEZbrDh1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MeanSentenceGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  sentence_vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      if len(i) != 0:\n",
        "          v = sum([glove.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
        "          #print(len(i))\n",
        "      else:\n",
        "          v = np.zeros((100,))\n",
        "      sentence_vectors.append(v)\n",
        "  #print('Total vectors created:',len(sentence_vectors))\n",
        "  return(sentence_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_X4YELpn4xi",
        "colab_type": "code",
        "outputId": "14f5b4ec-cdc5-47d3-f8c0-368c10dc8ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_glove = MeanSentenceGlove(train_texts)\n",
        "test_glove = MeanSentenceGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.72      0.80      0.76       209\n",
            "    positive       0.75      0.66      0.71       191\n",
            "\n",
            "    accuracy                           0.73       400\n",
            "   macro avg       0.74      0.73      0.73       400\n",
            "weighted avg       0.74      0.73      0.73       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zshJ91heBjrM",
        "colab_type": "code",
        "outputId": "c8edee66-d41b-4406-9da3-879d9625664f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp = MeanSentenceGlove(train_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total vectors created: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNqxse4aBrNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0xFJPUgCf1g",
        "colab_type": "text"
      },
      "source": [
        "2.1 Glove - NLTK tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9YN9HHPCmHy",
        "colab_type": "code",
        "outputId": "33171b04-94ff-4e80-f8a6-a8f14c7e8114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        " #We'll use Average Glove here \n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oOsdruCCxgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AvgGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      #vectors.append(np.average(glove.get(word_tokenize(i)), axis =0))\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csPA9z5_IqSD",
        "colab_type": "code",
        "outputId": "abe18b91-8f57-4dd2-84dc-24b51879a99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_glove = AvgGlove(train_texts)\n",
        "test_glove = AvgGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.74      0.81      0.78       209\n",
            "    positive       0.77      0.70      0.73       191\n",
            "\n",
            "    accuracy                           0.76       400\n",
            "   macro avg       0.76      0.75      0.75       400\n",
            "weighted avg       0.76      0.76      0.75       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09aYVnUTPiIy",
        "colab_type": "text"
      },
      "source": [
        "2.2 Glove Weighted average tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZKNvGr1RBCW",
        "colab_type": "code",
        "outputId": "3ed41dd9-95fd-4eb0-8c64-15dd4ec79fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit(train_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z4ptVSHRctB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
        "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q-U_FJ8RqkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
        "\n",
        "def tfidfGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      weights = [idf_dict.get(word, 1) for word in word_tokenize(i)]\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0, weights = weights))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkfiZcGESKrQ",
        "colab_type": "code",
        "outputId": "e67972a3-07c9-4937-d436-700e902d1b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_glove = tfidfGlove(train_texts)\n",
        "test_glove = tfidfGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.77      0.77       209\n",
            "    positive       0.74      0.74      0.74       191\n",
            "\n",
            "    accuracy                           0.76       400\n",
            "   macro avg       0.75      0.75      0.75       400\n",
            "weighted avg       0.76      0.76      0.76       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afB7HQFeU2s6",
        "colab_type": "text"
      },
      "source": [
        "2.3 Glove Weighted average Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7oeK0SgU82U",
        "colab_type": "code",
        "outputId": "f0fc9665-d977-4f1d-9ac7-9630c6172f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "count = CountVectorizer()\n",
        "count.fit(train_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95F1x5M4VFTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
        "count_dict = count.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdtc8q6NaGG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
        "\n",
        "def countGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      weights = [count_dict.get(word, 1) for word in word_tokenize(i)]\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0, weights = weights))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx4jpinxaRTV",
        "colab_type": "code",
        "outputId": "c54518bb-1aec-423d-96c7-1b08ba8e114a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "train_glove = countGlove(train_texts)\n",
        "test_glove = countGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c31b8f3bdbe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountGlove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountGlove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGlove_baseline_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mGlove_baseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mGlove_baseline_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlove_baseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'countGlove' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puVAn6TLXAWz",
        "colab_type": "text"
      },
      "source": [
        "3. FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbiFTXfnXE_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHeLKwFah4As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.utils import tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOfKHZkKiDDz",
        "colab_type": "code",
        "outputId": "e55c6ac9-35f6-473a-9543-88f304f91d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(tokenize('I like Moshe food', lowercase=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'like', 'moshe', 'food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeGK0-JqkbGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_tokens=[[token for token in tokenize(sentence)] for sentence in train_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5t40wInXJLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fasttext_sts2 = FastText(sentences_tokens, size=100, window=5, min_count=0, workers=4,sg=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO6uRlEDlx_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fasttext_sts2.most_similar('eat')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu7jl9zWBYz1",
        "colab_type": "text"
      },
      "source": [
        "4. BERT Fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9uRf2q_BhKD",
        "colab_type": "text"
      },
      "source": [
        "Load BERT pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1InADgf5xm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "dab28e41b97c43c690becb5f9da76ed9",
            "43195197412f4fd1aa147f9bd7db1716",
            "1a005428a07d4bf3b6b48fa8a25a1095",
            "6b57cad586c74258a854acd2007f5e55",
            "1d142be0b4e442e78519166bd4f565f0",
            "c37f32c0bc894ace934b08e74a5d2c31",
            "8f60b5b730b64a138b42a01bc0439ffb",
            "36aac0d7bd124becaf083133fbbb1bb0",
            "5e9b1dc05ec34fe085b45bd9bcc9da94",
            "acc43f04797148ddacfc36a8e93077e0",
            "8b8e6d8344eb4a46b61ee6f51fb28a11",
            "2529526c9ae84e58af8d6e21cb43b958",
            "7dbfac4919624a7e857b5583e0bc7b0b",
            "2abfd5059c77401bacc90ae9c0661f59",
            "5e360a993d154194ac0769043782ed41",
            "5133dd240f6f4d05a452894f5151c839",
            "94eb8c492dca4d9b81bb01ec02619d83",
            "f872b533a08f45bf96a6a30864cef44c",
            "98372bc24b4d46f19ed910061c91a3b8",
            "c40e9556116244c8a47236fe508690b3",
            "96c89bc486324bfdbcb15049618691f8",
            "997a1b1460cd46978c674dc2e212dcab",
            "fe9f18152ce543b2be17b9e57de02ac1",
            "938bfee88f5c464b8ad2560b1abd5224"
          ]
        },
        "outputId": "87f8fef1-e311-477a-8bc3-efd345f9d91f"
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "## Want Roberta instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "BertModel = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dab28e41b97c43c690becb5f9da76ed9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e9b1dc05ec34fe085b45bd9bcc9da94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=442, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94eb8c492dca4d9b81bb01ec02619d83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=267967963, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blm0LshSE-f-",
        "colab_type": "text"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg82ndBA5xlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "tokenized = batch_1[text_col].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxIB32MKGAeE",
        "colab_type": "text"
      },
      "source": [
        "Limit tokenized to 512 max_bert_len"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynA4SkHqa4LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padded = np.array([if (len(i)>0) i=3, for i in tokenized.values])\n",
        "tokenized_limted = []\n",
        "for i in tokenized.values:\n",
        "  if len(i)>max_bert_len:\n",
        "    tokenized_limted.append(i[:max_bert_len])\n",
        "  else:\n",
        "    tokenized_limted.append(i)\n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JglXYRwDGRB0",
        "colab_type": "text"
      },
      "source": [
        "Padding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URn-DWJt5xhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded = np.array([i + [0]*(max_bert_len-len(i)) for i in tokenized_limted])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdi7uXo95xeq",
        "colab_type": "code",
        "outputId": "e1938ad5-8b3c-4e6c-e200-80193dfcfc91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjLgfvueLBd6",
        "colab_type": "text"
      },
      "source": [
        "Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3d9QSDKLCnY",
        "colab_type": "code",
        "outputId": "93c27894-fcb3-4c21-e20d-b296df55cc37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fHgYJXqLJqO",
        "colab_type": "text"
      },
      "source": [
        "Convert to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeQeyUzKLL_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n_cqR8DuT-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "250a4962-d86c-4d5a-9af0-ac43503841d5"
      },
      "source": [
        "attention_mask"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YhA8McnLTCS",
        "colab_type": "text"
      },
      "source": [
        "**And now Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6rh9UpGRUAe",
        "colab_type": "text"
      },
      "source": [
        "Biniarizatiom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ed6sC6LZuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(catos) & set(catagories) for catos in batch_1[[category_col]].values]\n",
        "bin_catagories = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_catagories.tolist())\n",
        "\n",
        "target_tensor=torch.max(target_tensor_bin,1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG5RlRdJssyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKZNeidJsz_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_labels[0:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX1GNKCsUs4E",
        "colab_type": "text"
      },
      "source": [
        "Convert to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWQRk1ZXUrFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens_tensor, test_tokens_tensor, train_masks_tensor, test_masks_tensor = train_test_split(input_ids,attention_mask,test_size=TEST_SIZE,random_state=RANDOM_STATE)\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkDsNVe5x3MV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY5BjiD9SEwS",
        "colab_type": "text"
      },
      "source": [
        "Dataloader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyFHsYASDuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqnADjn6SZJO",
        "colab_type": "text"
      },
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tCrjW7_SXv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1, freeze_bert = False):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.bert = BertModel.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        if freeze_bert:\n",
        "            for p in self.bert.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48vLQR5FShu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf = BertMultiClassifier(freeze_bert=False)\n",
        "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss.  Check BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TDXoNFhSxNX",
        "colab_type": "code",
        "outputId": "ebd29670-62b2-4f0f-ea1c-6bbf19b6ef3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "losses = []\n",
        "steps = []\n",
        "step = 0\n",
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        batch_loss = criterion(probas, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        \n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        \n",
        "\n",
        "        #clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"{0}/{1} loss: {2} \".format(step_num, len(train_y_tensor) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
        "        losses.append(batch_loss.item())\n",
        "        steps.append(step)\n",
        "        step += 1\n",
        "        \n",
        "# Other option to save: torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"]))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  3\n",
            "99/100.0 loss: 0.11000282391905784 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZtBc1U85eDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert_to_pickle(bert_clf, \"/gdrive/My Drive/DataSet/ED6/DistillBERT91.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTUPOAQhSy4o",
        "colab_type": "text"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_iL-xrxS1Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        bert_predicted += list(torch.max(probas,1)[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQluUbtSTF7s",
        "colab_type": "code",
        "outputId": "0fe21c85-00f8-41d1-889b-e9e983caffbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, bert_predicted))\n",
        "print(confusion_matrix(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.89       705\n",
            "           1       0.93      0.89      0.91       895\n",
            "\n",
            "    accuracy                           0.90      1600\n",
            "   macro avg       0.89      0.90      0.90      1600\n",
            "weighted avg       0.90      0.90      0.90      1600\n",
            "\n",
            "[[641  64]\n",
            " [102 793]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOb9fatpE22n",
        "colab_type": "text"
      },
      "source": [
        "4. BERT freeze "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1wG9Nsyx5QGW",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states = BertModel(input_ids, attention_mask=attention_mask)\n",
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Na6m4yBJ5WJA",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, batch_1[category_col],test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0fc752dc-c07b-4fea-f29d-d32dd11c6547",
        "id": "HFPjKTvj5Z_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "296f72b8-f13d-4ba4-e0c4-30abdd6eedb3",
        "id": "ZapaAoSi5gN9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfofFNz65hbo",
        "colab_type": "text"
      },
      "source": [
        "5. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wa3Iw9dJ5prf"
      },
      "source": [
        "How good is this score? What can we compare it against? Let's first look at a dummy classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6f543f40-4f75-45f7-ac7e-914b18266b13",
        "id": "ZqFcPfFV5s8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.238 (+/- 0.01)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXcwzcOI5hfU",
        "colab_type": "text"
      },
      "source": [
        "To save time load BERT model and create logit for labeled and unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chX8-PpR5aPN",
        "colab_type": "code",
        "outputId": "4b5973af-cbc4-4a18-f4f8-004fdc5e8655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2aCQBpunQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read BERT model from pkl\n",
        "\n",
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output\n",
        "\n",
        "bert_clf = load_from_pickle(\"/gdrive/My Drive/Colab Notebooks/STS2/DistillBERT.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRNV6yqOzyZw",
        "colab_type": "text"
      },
      "source": [
        "6. Distill with training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRkGgG6H0GLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logits\n",
        "train_logits = build_bert_logits(train_texts, bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8sHRpDD4qLU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc_CeKXRu1d-",
        "colab_type": "code",
        "outputId": "2e994b1c-cd68-4a2a-ac3b-631cb81f9e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Run regression \n",
        "distilled_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LinearRegression()).fit(train_texts, train_logits)\n",
        "distilled_predicted_logits = distilled_model.predict(test_texts)\n",
        "distilled_bert_predicted=torch.max(torch.tensor(distilled_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor, distilled_bert_predicted))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.67      0.72       175\n",
            "           1       0.77      0.84      0.80       225\n",
            "\n",
            "    accuracy                           0.77       400\n",
            "   macro avg       0.76      0.75      0.76       400\n",
            "weighted avg       0.76      0.77      0.76       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSk8whKo1F0X",
        "colab_type": "text"
      },
      "source": [
        "7. Distill with unlabeled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKpMzwqI1XM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logits\n",
        "unlabel_logits = build_bert_logits(unlabel_texts, bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-9KNxq61XU8",
        "colab_type": "code",
        "outputId": "43ce303c-ff64-4599-a047-37b062a8f2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# Run regression\n",
        "from sklearn import linear_model\n",
        "unlabel_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LinearRegression()).fit(unlabel_texts, unlabel_logits)\n",
        "unlabel_predicted_logits = unlabel_model.predict(test_texts)\n",
        "unlabel_bert_predicted=torch.max(torch.tensor(unlabel_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,unlabel_bert_predicted))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d638938ab046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munlabel_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munlabel_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabel_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0munlabel_predicted_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munlabel_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0munlabel_bert_predicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munlabel_predicted_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munlabel_bert_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CF7NVnC-PJQ",
        "colab_type": "text"
      },
      "source": [
        "8. Distill with unlabel with Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R85MsqAd6Y9",
        "colab_type": "code",
        "outputId": "3056d487-d309-4952-ed7c-ad53db866441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "unlabel_features_glove = AvgGlove(unlabel_texts) # output #sentences in Text x 100 features \n",
        "test_features_glove = AvgGlove(test_texts)      # output #sentences in Text x 100 features\n",
        "\n",
        "Glove_distill_model=LinearRegression()\n",
        "Glove_distill_model.fit(unlabel_features_glove, unlabel_logits)\n",
        "Glove_distill_predicted_logits = Glove_distill_model.predict(test_features_glove)\n",
        "Glove_distill_predicted = torch.max(torch.tensor(Glove_distill_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor, Glove_distill_predicted))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.82      0.77       503\n",
            "           1       0.79      0.69      0.74       497\n",
            "\n",
            "    accuracy                           0.76      1000\n",
            "   macro avg       0.76      0.76      0.76      1000\n",
            "weighted avg       0.76      0.76      0.76      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7OdfQWCvGtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd3TMzCE3yRI",
        "colab_type": "text"
      },
      "source": [
        "9. Distill with data aug - 6 ED dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOKPYY_X3xfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logits\n",
        "aug_logits = build_bert_logits(aug_texts, bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kmW2vaC3wY1",
        "colab_type": "code",
        "outputId": "878768bf-cab9-4e8b-8952-781f14dab665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Run regression\n",
        "aug_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LinearRegression()).fit(aug_texts, aug_logits)\n",
        "aug_predicted_logits = aug_model.predict(test_texts)\n",
        "aug_bert_predicted=torch.max(torch.tensor(aug_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,aug_bert_predicted))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.07      0.13       229\n",
            "           1       0.18      0.18      0.18       175\n",
            "           2       0.42      0.76      0.54       517\n",
            "           3       0.55      0.33      0.41       129\n",
            "           4       0.58      0.43      0.50       485\n",
            "           5       0.58      0.23      0.33        65\n",
            "\n",
            "    accuracy                           0.44      1600\n",
            "   macro avg       0.47      0.33      0.35      1600\n",
            "weighted avg       0.47      0.44      0.41      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPaVqMn0z57F",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRA5fkfez5-0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEt6QbuMz6Cf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4RhyMx-z6GI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5joH5Wipzal",
        "colab_type": "text"
      },
      "source": [
        "Init/Build train_y_tensor and test_y_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfbsSdA8q0Rt",
        "colab_type": "text"
      },
      "source": [
        "Distill with unlabeled samples + training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTtNQCdQmnkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mix_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(np.concatenate((train_texts,unlabeled_texts),axis=0), np.concatenate((train_logits_load,unlabeled_logits.to_numpy())))\n",
        "mix_predicted_logits = mix_model.predict(test_texts)\n",
        "mix_bert_predicted=torch.max(torch.tensor(mix_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,mix_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvM79PgsmuRw",
        "colab_type": "text"
      },
      "source": [
        "Distill with STS data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pRto5r0V02E-",
        "colab": {}
      },
      "source": [
        "def build_bert_logits(texts, bert_clf,tokenizer, batch_size):\n",
        "\n",
        "  tokenized = texts.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "  tokenized_limted = []\n",
        "  for i in tokenized.values:\n",
        "    if len(i)>max_bert_len:\n",
        "      tokenized_limted.append(i[:max_bert_len])\n",
        "    else:\n",
        "      tokenized_limted.append(i)\n",
        "\n",
        "  padded = np.array([i + [0]*(max_bert_len-len(i)) for i in tokenized_limted])\n",
        "\n",
        "  attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "  input_ids = torch.tensor(padded)  \n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "  #tokens_tensor = torch.tensor(input_ids)\n",
        "  #masks_tensor = torch.tensor(attention_mask)\n",
        "\n",
        "  dataset = TensorDataset(input_ids, attention_mask)\n",
        "  dataloader = DataLoader(dataset, batch_size)\n",
        "\n",
        "  bert_clf.eval()\n",
        "  list_logits = []\n",
        "  with torch.no_grad():\n",
        "      for step_num, batch_data in enumerate(dataloader):\n",
        "\n",
        "          token_ids, masks = tuple(t for t in batch_data)\n",
        "\n",
        "          logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "          list_logits += list(logits)\n",
        "\n",
        "          print(\"{0}/{1}\".format(step_num, len(dataset) / batch_size))\n",
        "\n",
        "  list_logits_numpy= (i.numpy() for i in list_logits)\n",
        "  logits = np.vstack(list_logits_numpy)\n",
        "  return(logits)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0KGGDbP2Y0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiL-UHfQ2ZNd",
        "colab_type": "text"
      },
      "source": [
        "**N-gram plus Glove embedding** \n",
        "Example code: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb \n",
        "\n",
        "https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/Glove_CNN_MultiClass.ipynb#scrollTo=tnUazzVHSuB6"
      ]
    }
  ]
}