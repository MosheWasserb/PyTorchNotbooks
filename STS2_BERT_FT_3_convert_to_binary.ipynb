{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STS2 - BERT FT 3 convert to binary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f27581125b4d4054881b6bd8106bce87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_690037b10f014e43b42f388ad5330a5e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d2bbdd9751364d478f198255fdca5576",
              "IPY_MODEL_0c71b9e5d7c54951a76ea4cf0724cb9f"
            ]
          }
        },
        "690037b10f014e43b42f388ad5330a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2bbdd9751364d478f198255fdca5576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0f1a3cf9aa141fab9c12a243d42e236",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c32e8e8e3c345108cc2094372f593ba"
          }
        },
        "0c71b9e5d7c54951a76ea4cf0724cb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e41b6e29665c425699464189137e2cfe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9582e6b9643d4161a27bdac02f1a05da"
          }
        },
        "a0f1a3cf9aa141fab9c12a243d42e236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c32e8e8e3c345108cc2094372f593ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e41b6e29665c425699464189137e2cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9582e6b9643d4161a27bdac02f1a05da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7557bef714f645b088a2c8cd5e1d247d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1743b9748594343b7b2d5894b2a885d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_492155274b0f408fac279560959d5258",
              "IPY_MODEL_41fc098e22cc42a2932b1e25bc28674a"
            ]
          }
        },
        "a1743b9748594343b7b2d5894b2a885d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "492155274b0f408fac279560959d5258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56d7dc4a69ca44658e1afddbf5ccf16c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cc1bb8012da4ef6abdf4ab61fdc9afe"
          }
        },
        "41fc098e22cc42a2932b1e25bc28674a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9db77bb2ebd24351b6187725b56596be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:04&lt;00:00, 89.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6def13def8c8413ca566eed7310955f0"
          }
        },
        "56d7dc4a69ca44658e1afddbf5ccf16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cc1bb8012da4ef6abdf4ab61fdc9afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9db77bb2ebd24351b6187725b56596be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6def13def8c8413ca566eed7310955f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4900fd1d5524234be6e195c8f8b879e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_66d654ef66064fb593443a842e2da491",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e495d891d1134feda55e9990027a887e",
              "IPY_MODEL_76b46bf95fb743b8b32ba6bb78de1cd2"
            ]
          }
        },
        "66d654ef66064fb593443a842e2da491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e495d891d1134feda55e9990027a887e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce104e4f564d498e91d8a3f7dbe6c729",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c39e6e915a474de88a1f73a6a0517445"
          }
        },
        "76b46bf95fb743b8b32ba6bb78de1cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85cbe4548977497c8b5d96eb3f7a1e85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:04&lt;00:00, 58.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acb4116d1f464ca1b3a920a7964e2c55"
          }
        },
        "ce104e4f564d498e91d8a3f7dbe6c729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c39e6e915a474de88a1f73a6a0517445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85cbe4548977497c8b5d96eb3f7a1e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acb4116d1f464ca1b3a920a7964e2c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/STS2_BERT_FT_3_convert_to_binary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9ENLU90WGl",
        "colab_type": "code",
        "outputId": "60ab0714-efd2-4eff-ec0d-c67ca15293f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import clear_output\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNdAPjA3-exk",
        "colab_type": "text"
      },
      "source": [
        "Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1yaW1WK-VQ5",
        "colab_type": "code",
        "outputId": "b70c0f18-dafa-4feb-e815-605db9b60fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Import Training, Validation and Test csvs\n",
        "# STS2\n",
        "#data = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
        "# 6 Emotions\n",
        "#data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "# IMDB data (from Kaggle)\n",
        "data = pd.read_csv(r\"/gdrive/My Drive/DataSet/IMDB/train2.csv\")\n",
        "# STS2 from GLUE \n",
        "#data = pd.read_csv(\"/gdrive/My Drive/DataSet/GLUE/STS2/SST-2/train.tsv\", delimiter='\\t', header=None)\n",
        "\n",
        "text_col=data.columns.values[0] \n",
        "category_col=data.columns.values[1]\n",
        "\n",
        "data.head"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                     text  sentiment\n",
              "0      For a movie that gets no respect there sure ar...          0\n",
              "1      Bizarre horror movie filled with famous faces ...          0\n",
              "2      A solid, if unremarkable film. Matthau, as Ein...          0\n",
              "3      It's a strange feeling to sit alone in a theat...          0\n",
              "4      You probably all already know this by now, but...          0\n",
              "...                                                  ...        ...\n",
              "24995  My comments may be a bit of a spoiler, for wha...          1\n",
              "24996  The \"saucy\" misadventures of four au pairs who...          1\n",
              "24997  Oh, those Italians! Assuming that movies about...          1\n",
              "24998  Eight academy nominations? It's beyond belief....          1\n",
              "24999  Not that I dislike childrens movies, but this ...          1\n",
              "\n",
              "[25000 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM0uqhO771Aa",
        "colab_type": "text"
      },
      "source": [
        "Init and set data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGvBvbzo8P3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_SIZE=0.5\n",
        "RANDOM_STATE=1\n",
        "SAMPLE_SIZE = 2000\n",
        "UNLABEL_SIZE = 20000\n",
        "AUG_SIZE = 4000\n",
        "\n",
        "max_bert_len = 70\n",
        "\n",
        "BATCH_SIZE=64\n",
        "EPOCHS =3\n",
        "HIDDEN_SIZE=768\n",
        "\n",
        "catagories=list(set(data[category_col].unique()))\n",
        "OUTPUT_DIM= 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmOj02o32X5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "e08ae817-5b8d-4e2a-b08c-8f678404c20c"
      },
      "source": [
        "aug_data_sample=aug_data.sample(n=AUG_SIZE,random_state=RANDOM_STATE)\n",
        "aug_texts=aug_data_sample[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8a1ebdac52c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maug_data_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maug_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_data_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'aug_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9fP0WJE902X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1 = data.sample(n=SAMPLE_SIZE, random_state=RANDOM_STATE);\n",
        "residue_batch = data.drop(batch_1.index)\n",
        "unlabel_texts_batch = residue_batch.sample(n=UNLABEL_SIZE, random_state=RANDOM_STATE);\n",
        "unlabel_texts=unlabel_texts_batch[text_col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umj451aL73Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(batch_1[text_col],batch_1[category_col], test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DKJtD0MvY0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "422ef176-ed25-4579-e468-95adb0e63409"
      },
      "source": [
        "list(set(test_labels.unique()))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJm9b68jDQkU",
        "colab_type": "code",
        "outputId": "17825e1b-9070-43ad-94fb-395d1516b311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_texts), len(test_texts), len(train_labels), len(test_labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000, 1000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn5EAD-Q7aK-",
        "colab_type": "text"
      },
      "source": [
        "1. Ngram baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXghfhlK7euk",
        "colab_type": "code",
        "outputId": "66da623c-b7b5-4a30-8b4c-d2c523d394ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#CounterVecorizer(ngram_range=(1,3), min_df=0.2, max_df=0.7, max_features=10000, stop_words=\"english\")\n",
        "ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "#ngramCount_baseline_model = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "#ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,2),stop_words=\"english\",max_features=10000, max_df=0.75), LogisticRegression()).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))\n",
        "print(confusion_matrix(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.79       503\n",
            "           1       0.79      0.75      0.77       497\n",
            "\n",
            "    accuracy                           0.78      1000\n",
            "   macro avg       0.78      0.78      0.78      1000\n",
            "weighted avg       0.78      0.78      0.78      1000\n",
            "\n",
            "[[407  96]\n",
            " [126 371]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmX-GoxI8k7a",
        "colab_type": "code",
        "outputId": "6711c82d-3175-4568-a162-591db6069fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ngramCount_baseline_model.score(test_texts,test_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.791"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV5JKT_OgY28",
        "colab_type": "text"
      },
      "source": [
        "1.1 NGRAM SGDClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzX_AnPKgfpD",
        "colab_type": "code",
        "outputId": "a51eca62-622e-4ae6-d731-b9eb21652ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ngramCount_baseline_model = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), SGDClassifier(loss = 'log')).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))\n",
        "print(confusion_matrix(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.66      0.71       175\n",
            "           1       0.76      0.85      0.80       225\n",
            "\n",
            "    accuracy                           0.77       400\n",
            "   macro avg       0.77      0.75      0.76       400\n",
            "weighted avg       0.77      0.77      0.76       400\n",
            "\n",
            "[[115  60]\n",
            " [ 34 191]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xFW4m2pnpKz",
        "colab_type": "text"
      },
      "source": [
        "2. Glove mean Logistic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5LiZUqyOnOz",
        "colab_type": "code",
        "outputId": "22a4b21a-8ef6-4adf-ce4c-c71a03044cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JDXtXNRn0PH",
        "colab_type": "code",
        "outputId": "768ea0ef-b5c2-4c75-b256-1cca30539b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define dict to hold a word and its vector\n",
        "glove = {}\n",
        "# read the word embeddings file ~820MB\n",
        "f = open('/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/glove.6B.100d.txt', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    glove[word] = coefs\n",
        "f.close()\n",
        "# check the length\n",
        "len(glove) # 400000"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyInEZbrDh1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MeanSentenceGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  sentence_vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      if len(i) != 0:\n",
        "          v = sum([glove.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
        "          #print(len(i))\n",
        "      else:\n",
        "          v = np.zeros((100,))\n",
        "      sentence_vectors.append(v)\n",
        "  #print('Total vectors created:',len(sentence_vectors))\n",
        "  return(sentence_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_X4YELpn4xi",
        "colab_type": "code",
        "outputId": "14f5b4ec-cdc5-47d3-f8c0-368c10dc8ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_glove = MeanSentenceGlove(train_texts)\n",
        "test_glove = MeanSentenceGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.72      0.80      0.76       209\n",
            "    positive       0.75      0.66      0.71       191\n",
            "\n",
            "    accuracy                           0.73       400\n",
            "   macro avg       0.74      0.73      0.73       400\n",
            "weighted avg       0.74      0.73      0.73       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zshJ91heBjrM",
        "colab_type": "code",
        "outputId": "c8edee66-d41b-4406-9da3-879d9625664f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp = MeanSentenceGlove(train_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total vectors created: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNqxse4aBrNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0xFJPUgCf1g",
        "colab_type": "text"
      },
      "source": [
        "2.1 Glove - NLTK tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9YN9HHPCmHy",
        "colab_type": "code",
        "outputId": "33171b04-94ff-4e80-f8a6-a8f14c7e8114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        " #We'll use Average Glove here \n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oOsdruCCxgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AvgGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      #vectors.append(np.average(glove.get(word_tokenize(i)), axis =0))\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csPA9z5_IqSD",
        "colab_type": "code",
        "outputId": "abe18b91-8f57-4dd2-84dc-24b51879a99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_glove = AvgGlove(train_texts)\n",
        "test_glove = AvgGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.74      0.81      0.78       209\n",
            "    positive       0.77      0.70      0.73       191\n",
            "\n",
            "    accuracy                           0.76       400\n",
            "   macro avg       0.76      0.75      0.75       400\n",
            "weighted avg       0.76      0.76      0.75       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09aYVnUTPiIy",
        "colab_type": "text"
      },
      "source": [
        "2.2 Glove Weighted average tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZKNvGr1RBCW",
        "colab_type": "code",
        "outputId": "3ed41dd9-95fd-4eb0-8c64-15dd4ec79fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit(train_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z4ptVSHRctB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
        "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q-U_FJ8RqkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
        "\n",
        "def tfidfGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      weights = [idf_dict.get(word, 1) for word in word_tokenize(i)]\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0, weights = weights))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkfiZcGESKrQ",
        "colab_type": "code",
        "outputId": "e67972a3-07c9-4937-d436-700e902d1b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_glove = tfidfGlove(train_texts)\n",
        "test_glove = tfidfGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.77      0.77       209\n",
            "    positive       0.74      0.74      0.74       191\n",
            "\n",
            "    accuracy                           0.76       400\n",
            "   macro avg       0.75      0.75      0.75       400\n",
            "weighted avg       0.76      0.76      0.76       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afB7HQFeU2s6",
        "colab_type": "text"
      },
      "source": [
        "2.3 Glove Weighted average Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7oeK0SgU82U",
        "colab_type": "code",
        "outputId": "f0fc9665-d977-4f1d-9ac7-9630c6172f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "count = CountVectorizer()\n",
        "count.fit(train_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95F1x5M4VFTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
        "count_dict = count.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdtc8q6NaGG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
        "\n",
        "def countGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      weights = [count_dict.get(word, 1) for word in word_tokenize(i)]\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0, weights = weights))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx4jpinxaRTV",
        "colab_type": "code",
        "outputId": "c54518bb-1aec-423d-96c7-1b08ba8e114a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "train_glove = countGlove(train_texts)\n",
        "test_glove = countGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c31b8f3bdbe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountGlove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountGlove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGlove_baseline_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mGlove_baseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mGlove_baseline_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlove_baseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'countGlove' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puVAn6TLXAWz",
        "colab_type": "text"
      },
      "source": [
        "3. FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbiFTXfnXE_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHeLKwFah4As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.utils import tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOfKHZkKiDDz",
        "colab_type": "code",
        "outputId": "e55c6ac9-35f6-473a-9543-88f304f91d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(tokenize('I like Moshe food', lowercase=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'like', 'moshe', 'food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeGK0-JqkbGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_tokens=[[token for token in tokenize(sentence)] for sentence in train_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5t40wInXJLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fasttext_sts2 = FastText(sentences_tokens, size=100, window=5, min_count=0, workers=4,sg=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO6uRlEDlx_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fasttext_sts2.most_similar('eat')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu7jl9zWBYz1",
        "colab_type": "text"
      },
      "source": [
        "4. BERT Fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9uRf2q_BhKD",
        "colab_type": "text"
      },
      "source": [
        "Load BERT pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1InADgf5xm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "f27581125b4d4054881b6bd8106bce87",
            "690037b10f014e43b42f388ad5330a5e",
            "d2bbdd9751364d478f198255fdca5576",
            "0c71b9e5d7c54951a76ea4cf0724cb9f",
            "a0f1a3cf9aa141fab9c12a243d42e236",
            "1c32e8e8e3c345108cc2094372f593ba",
            "e41b6e29665c425699464189137e2cfe",
            "9582e6b9643d4161a27bdac02f1a05da",
            "7557bef714f645b088a2c8cd5e1d247d",
            "a1743b9748594343b7b2d5894b2a885d",
            "492155274b0f408fac279560959d5258",
            "41fc098e22cc42a2932b1e25bc28674a",
            "56d7dc4a69ca44658e1afddbf5ccf16c",
            "3cc1bb8012da4ef6abdf4ab61fdc9afe",
            "9db77bb2ebd24351b6187725b56596be",
            "6def13def8c8413ca566eed7310955f0",
            "c4900fd1d5524234be6e195c8f8b879e",
            "66d654ef66064fb593443a842e2da491",
            "e495d891d1134feda55e9990027a887e",
            "76b46bf95fb743b8b32ba6bb78de1cd2",
            "ce104e4f564d498e91d8a3f7dbe6c729",
            "c39e6e915a474de88a1f73a6a0517445",
            "85cbe4548977497c8b5d96eb3f7a1e85",
            "acb4116d1f464ca1b3a920a7964e2c55"
          ]
        },
        "outputId": "d0283de2-353c-465a-81b2-d91878a43de7"
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "## Want Roberta instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "BertModel = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f27581125b4d4054881b6bd8106bce87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7557bef714f645b088a2c8cd5e1d247d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=442, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4900fd1d5524234be6e195c8f8b879e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=267967963, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blm0LshSE-f-",
        "colab_type": "text"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg82ndBA5xlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "tokenized = batch_1[text_col].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxIB32MKGAeE",
        "colab_type": "text"
      },
      "source": [
        "Limit tokenized to 512 max_bert_len"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynA4SkHqa4LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padded = np.array([if (len(i)>0) i=3, for i in tokenized.values])\n",
        "tokenized_limted = []\n",
        "for i in tokenized.values:\n",
        "  if len(i)>max_bert_len:\n",
        "    tokenized_limted.append(i[:max_bert_len])\n",
        "  else:\n",
        "    tokenized_limted.append(i)\n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JglXYRwDGRB0",
        "colab_type": "text"
      },
      "source": [
        "Padding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URn-DWJt5xhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded = np.array([i + [0]*(max_bert_len-len(i)) for i in tokenized_limted])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdi7uXo95xeq",
        "colab_type": "code",
        "outputId": "fd27c73e-4009-4ae7-b44b-91a03dd67612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjLgfvueLBd6",
        "colab_type": "text"
      },
      "source": [
        "Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3d9QSDKLCnY",
        "colab_type": "code",
        "outputId": "ee394b89-5e85-4e5e-a7d1-f0fcd0b15b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fHgYJXqLJqO",
        "colab_type": "text"
      },
      "source": [
        "Convert to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeQeyUzKLL_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n_cqR8DuT-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "250a4962-d86c-4d5a-9af0-ac43503841d5"
      },
      "source": [
        "attention_mask"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YhA8McnLTCS",
        "colab_type": "text"
      },
      "source": [
        "**And now Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6rh9UpGRUAe",
        "colab_type": "text"
      },
      "source": [
        "Biniarizatiom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ed6sC6LZuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(catos) & set(catagories) for catos in batch_1[[category_col]].values]\n",
        "bin_catagories = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_catagories.tolist())\n",
        "\n",
        "target_tensor=torch.max(target_tensor_bin,1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG5RlRdJssyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKZNeidJsz_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_labels[0:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX1GNKCsUs4E",
        "colab_type": "text"
      },
      "source": [
        "Convert to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWQRk1ZXUrFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens_tensor, test_tokens_tensor, train_masks_tensor, test_masks_tensor = train_test_split(input_ids,attention_mask,test_size=TEST_SIZE,random_state=RANDOM_STATE)\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkDsNVe5x3MV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY5BjiD9SEwS",
        "colab_type": "text"
      },
      "source": [
        "Dataloader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyFHsYASDuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqnADjn6SZJO",
        "colab_type": "text"
      },
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tCrjW7_SXv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1, freeze_bert = False):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.bert = BertModel.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        if freeze_bert:\n",
        "            for p in self.bert.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48vLQR5FShu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf = BertMultiClassifier(freeze_bert=False)\n",
        "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss.  Check BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TDXoNFhSxNX",
        "colab_type": "code",
        "outputId": "2d8c97e9-f6f4-4f34-9545-78a47bbbd70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "losses = []\n",
        "steps = []\n",
        "step = 0\n",
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        batch_loss = criterion(probas, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        \n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        \n",
        "\n",
        "        #clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"{0}/{1} loss: {2} \".format(step_num, len(train_y_tensor) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
        "        losses.append(batch_loss.item())\n",
        "        steps.append(step)\n",
        "        step += 1\n",
        "        \n",
        "# Other option to save: torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"]))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  3\n",
            "15/15.625 loss: 0.06131770147476345 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZtBc1U85eDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert_to_pickle(bert_clf, \"/gdrive/My Drive/DataSet/ED6/DistillBERT91.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTUPOAQhSy4o",
        "colab_type": "text"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_iL-xrxS1Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        bert_predicted += list(torch.max(probas,1)[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQluUbtSTF7s",
        "colab_type": "code",
        "outputId": "931944bd-7059-43ae-f195-1d8c43c63728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, bert_predicted))\n",
        "print(confusion_matrix(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.82      0.77       503\n",
            "           1       0.79      0.70      0.74       497\n",
            "\n",
            "    accuracy                           0.76      1000\n",
            "   macro avg       0.76      0.76      0.76      1000\n",
            "weighted avg       0.76      0.76      0.76      1000\n",
            "\n",
            "[[412  91]\n",
            " [151 346]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOb9fatpE22n",
        "colab_type": "text"
      },
      "source": [
        "4. BERT freeze "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1wG9Nsyx5QGW",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states = BertModel(input_ids, attention_mask=attention_mask)\n",
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Na6m4yBJ5WJA",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, batch_1[category_col],test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0fc752dc-c07b-4fea-f29d-d32dd11c6547",
        "id": "HFPjKTvj5Z_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "296f72b8-f13d-4ba4-e0c4-30abdd6eedb3",
        "id": "ZapaAoSi5gN9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfofFNz65hbo",
        "colab_type": "text"
      },
      "source": [
        "5. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wa3Iw9dJ5prf"
      },
      "source": [
        "How good is this score? What can we compare it against? Let's first look at a dummy classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6f543f40-4f75-45f7-ac7e-914b18266b13",
        "id": "ZqFcPfFV5s8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.238 (+/- 0.01)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXcwzcOI5hfU",
        "colab_type": "text"
      },
      "source": [
        "To save time load BERT model and create logit for labeled and unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chX8-PpR5aPN",
        "colab_type": "code",
        "outputId": "4b5973af-cbc4-4a18-f4f8-004fdc5e8655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2aCQBpunQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read BERT model from pkl\n",
        "\n",
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output\n",
        "\n",
        "bert_clf = load_from_pickle(\"/gdrive/My Drive/Colab Notebooks/STS2/DistillBERT.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRNV6yqOzyZw",
        "colab_type": "text"
      },
      "source": [
        "6. Distill with training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRkGgG6H0GLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logits\n",
        "train_logits = build_bert_logits(train_texts, bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8sHRpDD4qLU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc_CeKXRu1d-",
        "colab_type": "code",
        "outputId": "2e994b1c-cd68-4a2a-ac3b-631cb81f9e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Run regression \n",
        "distilled_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LinearRegression()).fit(train_texts, train_logits)\n",
        "distilled_predicted_logits = distilled_model.predict(test_texts)\n",
        "distilled_bert_predicted=torch.max(torch.tensor(distilled_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor, distilled_bert_predicted))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.67      0.72       175\n",
            "           1       0.77      0.84      0.80       225\n",
            "\n",
            "    accuracy                           0.77       400\n",
            "   macro avg       0.76      0.75      0.76       400\n",
            "weighted avg       0.76      0.77      0.76       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSk8whKo1F0X",
        "colab_type": "text"
      },
      "source": [
        "7. Distill with unlabeled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKpMzwqI1XM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logits\n",
        "unlabel_logits = build_bert_logits(unlabel_texts, bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-9KNxq61XU8",
        "colab_type": "code",
        "outputId": "5e08c641-94ac-4838-f163-b8543875828f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Run regression\n",
        "from sklearn import linear_model\n",
        "unlabel_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LinearRegression()).fit(unlabel_texts, unlabel_logits)\n",
        "unlabel_predicted_logits = unlabel_model.predict(test_texts)\n",
        "unlabel_bert_predicted=torch.max(torch.tensor(unlabel_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,unlabel_bert_predicted))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.86      0.82       503\n",
            "           1       0.84      0.76      0.80       497\n",
            "\n",
            "    accuracy                           0.81      1000\n",
            "   macro avg       0.81      0.81      0.81      1000\n",
            "weighted avg       0.81      0.81      0.81      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CF7NVnC-PJQ",
        "colab_type": "text"
      },
      "source": [
        "8. Distill with unlabel with Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R85MsqAd6Y9",
        "colab_type": "code",
        "outputId": "3056d487-d309-4952-ed7c-ad53db866441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "unlabel_features_glove = AvgGlove(unlabel_texts) # output #sentences in Text x 100 features \n",
        "test_features_glove = AvgGlove(test_texts)      # output #sentences in Text x 100 features\n",
        "\n",
        "Glove_distill_model=LinearRegression()\n",
        "Glove_distill_model.fit(unlabel_features_glove, unlabel_logits)\n",
        "Glove_distill_predicted_logits = Glove_distill_model.predict(test_features_glove)\n",
        "Glove_distill_predicted = torch.max(torch.tensor(Glove_distill_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor, Glove_distill_predicted))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.82      0.77       503\n",
            "           1       0.79      0.69      0.74       497\n",
            "\n",
            "    accuracy                           0.76      1000\n",
            "   macro avg       0.76      0.76      0.76      1000\n",
            "weighted avg       0.76      0.76      0.76      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7OdfQWCvGtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd3TMzCE3yRI",
        "colab_type": "text"
      },
      "source": [
        "9. Distill with data aug - 6 ED dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOKPYY_X3xfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logits\n",
        "aug_logits = build_bert_logits(aug_texts, bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kmW2vaC3wY1",
        "colab_type": "code",
        "outputId": "878768bf-cab9-4e8b-8952-781f14dab665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Run regression\n",
        "aug_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LinearRegression()).fit(aug_texts, aug_logits)\n",
        "aug_predicted_logits = aug_model.predict(test_texts)\n",
        "aug_bert_predicted=torch.max(torch.tensor(aug_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,aug_bert_predicted))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.07      0.13       229\n",
            "           1       0.18      0.18      0.18       175\n",
            "           2       0.42      0.76      0.54       517\n",
            "           3       0.55      0.33      0.41       129\n",
            "           4       0.58      0.43      0.50       485\n",
            "           5       0.58      0.23      0.33        65\n",
            "\n",
            "    accuracy                           0.44      1600\n",
            "   macro avg       0.47      0.33      0.35      1600\n",
            "weighted avg       0.47      0.44      0.41      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPaVqMn0z57F",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRA5fkfez5-0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEt6QbuMz6Cf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4RhyMx-z6GI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5joH5Wipzal",
        "colab_type": "text"
      },
      "source": [
        "Init/Build train_y_tensor and test_y_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfbsSdA8q0Rt",
        "colab_type": "text"
      },
      "source": [
        "Distill with unlabeled samples + training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTtNQCdQmnkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mix_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(np.concatenate((train_texts,unlabeled_texts),axis=0), np.concatenate((train_logits_load,unlabeled_logits.to_numpy())))\n",
        "mix_predicted_logits = mix_model.predict(test_texts)\n",
        "mix_bert_predicted=torch.max(torch.tensor(mix_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,mix_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvM79PgsmuRw",
        "colab_type": "text"
      },
      "source": [
        "Distill with STS data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pRto5r0V02E-",
        "colab": {}
      },
      "source": [
        "def build_bert_logits(texts, bert_clf,tokenizer, batch_size):\n",
        "\n",
        "  tokenized = texts.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "  tokenized_limted = []\n",
        "  for i in tokenized.values:\n",
        "    if len(i)>max_bert_len:\n",
        "      tokenized_limted.append(i[:max_bert_len])\n",
        "    else:\n",
        "      tokenized_limted.append(i)\n",
        "\n",
        "  padded = np.array([i + [0]*(max_bert_len-len(i)) for i in tokenized_limted])\n",
        "\n",
        "  attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "  input_ids = torch.tensor(padded)  \n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "  #tokens_tensor = torch.tensor(input_ids)\n",
        "  #masks_tensor = torch.tensor(attention_mask)\n",
        "\n",
        "  dataset = TensorDataset(input_ids, attention_mask)\n",
        "  dataloader = DataLoader(dataset, batch_size)\n",
        "\n",
        "  bert_clf.eval()\n",
        "  list_logits = []\n",
        "  with torch.no_grad():\n",
        "      for step_num, batch_data in enumerate(dataloader):\n",
        "\n",
        "          token_ids, masks = tuple(t for t in batch_data)\n",
        "\n",
        "          logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "          list_logits += list(logits)\n",
        "\n",
        "          print(\"{0}/{1}\".format(step_num, len(dataset) / batch_size))\n",
        "\n",
        "  list_logits_numpy= (i.numpy() for i in list_logits)\n",
        "  logits = np.vstack(list_logits_numpy)\n",
        "  return(logits)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0KGGDbP2Y0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiL-UHfQ2ZNd",
        "colab_type": "text"
      },
      "source": [
        "**N-gram plus Glove embedding** \n",
        "Example code: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb \n",
        "\n",
        "https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/Glove_CNN_MultiClass.ipynb#scrollTo=tnUazzVHSuB6"
      ]
    }
  ]
}