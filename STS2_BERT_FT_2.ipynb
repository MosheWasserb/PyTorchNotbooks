{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STS2 - BERT FT 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/STS2_BERT_FT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9ENLU90WGl",
        "colab_type": "code",
        "outputId": "dbcb28f4-f360-4701-8459-b417ff89c0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 3.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 16.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=00e10beca612ad27c0f2fd070f5107710a030d2e312a792e754bbb7a74f27248\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import clear_output\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNdAPjA3-exk",
        "colab_type": "text"
      },
      "source": [
        "Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1yaW1WK-VQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1c58a32b-fb0d-4826-e6ca-51e5f55a5654"
      },
      "source": [
        "# Import Training, Validation and Test csvs\n",
        "# STS2\n",
        "data = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
        "# 6 Emotions\n",
        "#data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "# IMDB\n",
        "#data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "\n",
        "text_col=data.columns.values[0] \n",
        "category_col=data.columns.values[1]\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  a stirring , funny and finally transporting re...  1\n",
              "1  apparently reassembled from the cutting room f...  0\n",
              "2  they presume their audience wo n't sit still f...  0\n",
              "3  this is a visually stunning rumination on love...  1\n",
              "4  jonathan parker 's bartleby should have been t...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM0uqhO771Aa",
        "colab_type": "text"
      },
      "source": [
        "Init and set data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGvBvbzo8P3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_SIZE=0.2\n",
        "RANDOM_STATE=42\n",
        "SAMPLE_SIZE = 2000\n",
        "UNLABEL_SIZE = 4000\n",
        "\n",
        "max_bert_len = 70\n",
        "\n",
        "BATCH_SIZE=64\n",
        "EPOCHS =5\n",
        "HIDDEN_SIZE=768\n",
        "\n",
        "catagories=list(set(data[category_col].unique()))\n",
        "OUTPUT_DIM= len(catagories)   #num of catagories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9fP0WJE902X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1 = data.sample(n=SAMPLE_SIZE, random_state=RANDOM_STATE);\n",
        "residue_batch = data.drop(batch_1.index)\n",
        "unlabel_texts_batch = residue_batch.sample(n=UNLABEL_SIZE, random_state=RANDOM_STATE);\n",
        "unlabel_texts=unlabel_texts_batch[text_col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umj451aL73Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(batch_1[text_col],batch_1[category_col], test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJm9b68jDQkU",
        "colab_type": "code",
        "outputId": "1a1e9315-f120-430e-eb4d-abcebc78390b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_texts), len(test_texts), len(train_labels), len(test_labels)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 400, 1600, 400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn5EAD-Q7aK-",
        "colab_type": "text"
      },
      "source": [
        "1. Ngram baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXghfhlK7euk",
        "colab_type": "code",
        "outputId": "047b7e82-d0e8-4fa6-aebb-64ad394240c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#CounterVecorizer(ngram_range=(1,3), min_df=0.2, max_df=0.7, max_features=10000, stop_words=\"english\")\n",
        "ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "#ngramCount_baseline_model = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "#ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,2),stop_words=\"english\",max_features=30000, max_df=0.75), LogisticRegression()).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))\n",
        "print(confusion_matrix(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.69      0.73       202\n",
            "           1       0.72      0.80      0.76       198\n",
            "\n",
            "    accuracy                           0.74       400\n",
            "   macro avg       0.75      0.75      0.74       400\n",
            "weighted avg       0.75      0.74      0.74       400\n",
            "\n",
            "[[139  63]\n",
            " [ 39 159]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmX-GoxI8k7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82afb783-873b-404e-a2e9-3e1541b1730c"
      },
      "source": [
        "ngramCount_baseline_model.score(test_texts,test_labels)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV5JKT_OgY28",
        "colab_type": "text"
      },
      "source": [
        "1.1 NGRAM SGDClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzX_AnPKgfpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e94a8ed6-04ee-4287-ee47-455068ebc331"
      },
      "source": [
        "ngramCount_baseline_model = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), SGDClassifier(loss = 'log')).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))\n",
        "print(confusion_matrix(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.79      0.42      0.54        53\n",
            "        fear       0.76      0.33      0.46        40\n",
            "         joy       0.63      0.84      0.72       158\n",
            "        love       1.00      0.15      0.26        33\n",
            "     sadness       0.57      0.77      0.66       102\n",
            "    surprise       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.63       400\n",
            "   macro avg       0.62      0.42      0.44       400\n",
            "weighted avg       0.66      0.63      0.59       400\n",
            "\n",
            "[[ 22   1  11   0  19   0]\n",
            " [  1  13  17   0   8   1]\n",
            " [  3   0 132   0  23   0]\n",
            " [  0   2  18   5   8   0]\n",
            " [  2   1  20   0  79   0]\n",
            " [  0   0  13   0   1   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xFW4m2pnpKz",
        "colab_type": "text"
      },
      "source": [
        "2. Glove mean Logistic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5LiZUqyOnOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ec22f8fe-8b2c-44bd-8580-a9c6fcba8f89"
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JDXtXNRn0PH",
        "colab_type": "code",
        "outputId": "b1216a86-2ba6-4139-e7a8-0b64e9ebc31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define dict to hold a word and its vector\n",
        "glove = {}\n",
        "# read the word embeddings file ~820MB\n",
        "f = open('/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/glove.6B.100d.txt', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    glove[word] = coefs\n",
        "f.close()\n",
        "# check the length\n",
        "len(glove) # 400000"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyInEZbrDh1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MeanSentenceGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  sentence_vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      if len(i) != 0:\n",
        "          v = sum([glove.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
        "          #print(len(i))\n",
        "      else:\n",
        "          v = np.zeros((100,))\n",
        "      sentence_vectors.append(v)\n",
        "  #print('Total vectors created:',len(sentence_vectors))\n",
        "  return(sentence_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_X4YELpn4xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d767913e-b7c4-4057-fc55-c30543561a60"
      },
      "source": [
        "train_glove = MeanSentenceGlove(train_texts)\n",
        "test_glove = MeanSentenceGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.44      0.28      0.34        53\n",
            "        fear       0.55      0.15      0.24        40\n",
            "         joy       0.61      0.81      0.70       158\n",
            "        love       0.00      0.00      0.00        33\n",
            "     sadness       0.48      0.66      0.55       102\n",
            "    surprise       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.54       400\n",
            "   macro avg       0.35      0.32      0.30       400\n",
            "weighted avg       0.47      0.54      0.48       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zshJ91heBjrM",
        "colab_type": "code",
        "outputId": "c8edee66-d41b-4406-9da3-879d9625664f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp = MeanSentenceGlove(train_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total vectors created: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNqxse4aBrNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0xFJPUgCf1g",
        "colab_type": "text"
      },
      "source": [
        "2.1 Glove - NLTK tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9YN9HHPCmHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6bbd0e1c-6ca2-4726-feea-ad7c329574a6"
      },
      "source": [
        " #We'll use Average Glove here \n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oOsdruCCxgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AvgGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      #vectors.append(np.average(glove.get(word_tokenize(i)), axis =0))\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csPA9z5_IqSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "175e0eb0-8ffa-4e86-bb58-4b09f3f40452"
      },
      "source": [
        "train_glove = AvgGlove(train_texts)\n",
        "test_glove = AvgGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.86      0.70       426\n",
            "           1       0.78      0.47      0.59       474\n",
            "\n",
            "    accuracy                           0.65       900\n",
            "   macro avg       0.69      0.66      0.64       900\n",
            "weighted avg       0.69      0.65      0.64       900\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09aYVnUTPiIy",
        "colab_type": "text"
      },
      "source": [
        "2.2 Glove Weighted average tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZKNvGr1RBCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9a913867-db71-4a4b-ca99-dd7f37387eb5"
      },
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit(train_texts)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z4ptVSHRctB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
        "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q-U_FJ8RqkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
        "\n",
        "def tfidfGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      weights = [idf_dict.get(word, 1) for word in word_tokenize(i)]\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0, weights = weights))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkfiZcGESKrQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "52f71fee-65a7-465e-e211-f005f26cab45"
      },
      "source": [
        "train_glove = tfidfGlove(train_texts)\n",
        "test_glove = tfidfGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.55      0.32      0.40        53\n",
            "        fear       0.52      0.33      0.40        40\n",
            "         joy       0.65      0.81      0.72       158\n",
            "        love       0.44      0.12      0.19        33\n",
            "     sadness       0.51      0.68      0.58       102\n",
            "    surprise       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.58       400\n",
            "   macro avg       0.44      0.38      0.38       400\n",
            "weighted avg       0.55      0.58      0.54       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afB7HQFeU2s6",
        "colab_type": "text"
      },
      "source": [
        "2.3 Glove Weighted average Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7oeK0SgU82U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d0b02142-bf16-4829-8f42-230502cebf1e"
      },
      "source": [
        "count = CountVectorizer()\n",
        "count.fit(train_texts)"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95F1x5M4VFTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
        "count_dict = count.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdtc8q6NaGG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
        "\n",
        "def countGlove(texts):\n",
        "# create vector for each sentences\n",
        "# list to hold vector \n",
        "  vectors = []\n",
        "# create vector for each clean normalized sentence\n",
        "  for i in texts:\n",
        "      weights = [count_dict.get(word, 1) for word in word_tokenize(i)]\n",
        "      vectors.append(np.average([glove.get(w, np.zeros((100,))) for w in word_tokenize(i)], axis = 0, weights = weights))\n",
        "  return np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx4jpinxaRTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2962ed9d-3006-46ac-e809-a13605907645"
      },
      "source": [
        "train_glove = countGlove(train_texts)\n",
        "test_glove = countGlove(test_texts)\n",
        "Glove_baseline_model=LogisticRegression()\n",
        "Glove_baseline_model.fit(train_glove, train_labels)\n",
        "Glove_baseline_predicted = Glove_baseline_model.predict(test_glove)\n",
        "print(classification_report(test_labels, Glove_baseline_predicted))"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.91      0.65       426\n",
            "           1       0.72      0.22      0.33       474\n",
            "\n",
            "    accuracy                           0.54       900\n",
            "   macro avg       0.62      0.56      0.49       900\n",
            "weighted avg       0.62      0.54      0.48       900\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puVAn6TLXAWz",
        "colab_type": "text"
      },
      "source": [
        "3. FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbiFTXfnXE_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHeLKwFah4As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.utils import tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOfKHZkKiDDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e55c6ac9-35f6-473a-9543-88f304f91d7f"
      },
      "source": [
        "list(tokenize('I like Moshe food', lowercase=True))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'like', 'moshe', 'food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeGK0-JqkbGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_tokens=[[token for token in tokenize(sentence)] for sentence in train_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5t40wInXJLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fasttext_sts2 = FastText(sentences_tokens, size=100, window=5, min_count=0, workers=4,sg=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO6uRlEDlx_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fasttext_sts2.most_similar('eat')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu7jl9zWBYz1",
        "colab_type": "text"
      },
      "source": [
        "4. BERT Fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9uRf2q_BhKD",
        "colab_type": "text"
      },
      "source": [
        "Load BERT pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1InADgf5xm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "## Want Roberta instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "BertModel = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blm0LshSE-f-",
        "colab_type": "text"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg82ndBA5xlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "tokenized = batch_1[text_col].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxIB32MKGAeE",
        "colab_type": "text"
      },
      "source": [
        "Limit tokenized to 512 max_bert_len"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynA4SkHqa4LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padded = np.array([if (len(i)>0) i=3, for i in tokenized.values])\n",
        "tokenized_limted = []\n",
        "for i in tokenized.values:\n",
        "  if len(i)>max_bert_len:\n",
        "    tokenized_limted.append(i[:max_bert_len])\n",
        "  else:\n",
        "    tokenized_limted.append(i)\n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JglXYRwDGRB0",
        "colab_type": "text"
      },
      "source": [
        "Padding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URn-DWJt5xhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded = np.array([i + [0]*(max_bert_len-len(i)) for i in tokenized_limted])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdi7uXo95xeq",
        "colab_type": "code",
        "outputId": "3bcb3aa3-a01b-49c8-e283-3faf5f8f8fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjLgfvueLBd6",
        "colab_type": "text"
      },
      "source": [
        "Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3d9QSDKLCnY",
        "colab_type": "code",
        "outputId": "569065b7-e501-4e48-ae16-c0e9fca71b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fHgYJXqLJqO",
        "colab_type": "text"
      },
      "source": [
        "Convert to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeQeyUzKLL_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YhA8McnLTCS",
        "colab_type": "text"
      },
      "source": [
        "**And now Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6rh9UpGRUAe",
        "colab_type": "text"
      },
      "source": [
        "Biniarizatiom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ed6sC6LZuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(catos) & set(catagories) for catos in batch_1[[category_col]].values]\n",
        "bin_catagories = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_catagories.tolist())\n",
        "\n",
        "target_tensor=torch.max(target_tensor_bin,1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX1GNKCsUs4E",
        "colab_type": "text"
      },
      "source": [
        "Convert to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWQRk1ZXUrFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens_tensor, test_tokens_tensor, train_masks_tensor, test_masks_tensor = train_test_split(input_ids,attention_mask,test_size=TEST_SIZE,random_state=RANDOM_STATE)\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY5BjiD9SEwS",
        "colab_type": "text"
      },
      "source": [
        "Dataloader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyFHsYASDuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqnADjn6SZJO",
        "colab_type": "text"
      },
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tCrjW7_SXv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1, freeze_bert = False):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        #self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        self.bert = BertModel.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        if freeze_bert:\n",
        "            for p in self.bert.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48vLQR5FShu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf = BertMultiClassifier(freeze_bert=False)\n",
        "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss.  Check BCEWithLogitsLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TDXoNFhSxNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9039c26e-3ac4-461d-a71b-b67aef3c43ad"
      },
      "source": [
        "losses = []\n",
        "steps = []\n",
        "step = 0\n",
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        batch_loss = criterion(probas, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        \n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        \n",
        "\n",
        "        #clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"{0}/{1} loss: {2} \".format(step_num, len(train_y_tensor) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
        "        losses.append(batch_loss.item())\n",
        "        steps.append(step)\n",
        "        step += 1\n",
        "\n",
        "#convert_to_pickle(bert_clf, \"/gdrive/My Drive/Colab Notebooks/STS2/DistillBERT.pkl\")\n",
        "# Other option to save: torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"]))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  5\n",
            "24/25.0 loss: 0.2989600867033005 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZtBc1U85eDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert_to_pickle(bert_clf, \"/gdrive/My Drive/Colab Notebooks/STS2/DistillBERT.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTUPOAQhSy4o",
        "colab_type": "text"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_iL-xrxS1Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        bert_predicted += list(torch.max(probas,1)[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQluUbtSTF7s",
        "colab_type": "code",
        "outputId": "590e36ca-2abc-4bf1-d038-bca5a8e8c966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, bert_predicted))\n",
        "print(confusion_matrix(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.83      0.88        53\n",
            "           1       0.74      0.85      0.79        40\n",
            "           2       0.85      0.89      0.87       158\n",
            "           3       0.62      0.48      0.54        33\n",
            "           4       0.85      0.89      0.87       102\n",
            "           5       0.90      0.64      0.75        14\n",
            "\n",
            "    accuracy                           0.83       400\n",
            "   macro avg       0.82      0.76      0.78       400\n",
            "weighted avg       0.83      0.83      0.83       400\n",
            "\n",
            "[[ 44   2   2   0   5   0]\n",
            " [  1  34   2   0   2   1]\n",
            " [  1   2 140   9   6   0]\n",
            " [  1   1  12  16   3   0]\n",
            " [  0   6   4   1  91   0]\n",
            " [  0   1   4   0   0   9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOb9fatpE22n",
        "colab_type": "text"
      },
      "source": [
        "4. BERT freeze "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1wG9Nsyx5QGW",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states = BertModel(input_ids, attention_mask=attention_mask)\n",
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Na6m4yBJ5WJA",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, batch_1[category_col],test_size=TEST_SIZE,random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9db0b46a-db98-4c2b-a8fe-954d4b68a5c2",
        "id": "HFPjKTvj5Z_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8ee90194-70bb-4e01-c793-80d03b2b5f83",
        "id": "ZapaAoSi5gN9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfofFNz65hbo",
        "colab_type": "text"
      },
      "source": [
        "5. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wa3Iw9dJ5prf"
      },
      "source": [
        "How good is this score? What can we compare it against? Let's first look at a dummy classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f3b0c3ca-2264-48f1-99ca-92e8d570c355",
        "id": "ZqFcPfFV5s8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.240 (+/- 0.07)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXcwzcOI5hfU",
        "colab_type": "text"
      },
      "source": [
        "To save time load BERT model and create logit for labeled and unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chX8-PpR5aPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4b5973af-cbc4-4a18-f4f8-004fdc5e8655"
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2aCQBpunQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read BERT model from pkl\n",
        "\n",
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output\n",
        "\n",
        "bert_clf = load_from_pickle(\"/gdrive/My Drive/Colab Notebooks/STS2/DistillBERT.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRNV6yqOzyZw",
        "colab_type": "text"
      },
      "source": [
        "6. Distill with training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRkGgG6H0GLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "d7233c0f-efe3-4b72-a9e2-b5f258969176"
      },
      "source": [
        "# Create logits\n",
        "train_logits = build_bert_logits(train_texts, bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/25.0\n",
            "1/25.0\n",
            "2/25.0\n",
            "3/25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-ef46ae38e21c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_bert_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-397b208bed2f>\u001b[0m in \u001b[0;36mbuild_bert_logits\u001b[0;34m(texts, bert_clf, tokenizer, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0mlist_logits\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-c6bc198bcc6d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_hidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#dropout_output = self.dropout(pooled_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mtfmr_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfmr_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtfmr_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Feed Forward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8sHRpDD4qLU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc_CeKXRu1d-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f97025c7-fa44-4784-cdbf-e0c3a3269baa"
      },
      "source": [
        "# Run regression \n",
        "distilled_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LinearRegression()).fit(train_texts, train_logits)\n",
        "distilled_predicted_logits = distilled_model.predict(test_texts)\n",
        "distilled_bert_predicted=torch.max(torch.tensor(distilled_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor, distilled_bert_predicted))\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.09      0.12        53\n",
            "           1       0.12      0.07      0.09        40\n",
            "           2       0.39      0.49      0.43       158\n",
            "           3       0.00      0.00      0.00        33\n",
            "           4       0.29      0.39      0.33       102\n",
            "           5       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.32       400\n",
            "   macro avg       0.16      0.18      0.16       400\n",
            "weighted avg       0.26      0.32      0.28       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSk8whKo1F0X",
        "colab_type": "text"
      },
      "source": [
        "7. Distill with unlabeled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKpMzwqI1XM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "abdfc58c-d2b8-4007-933e-5edaff3662bf"
      },
      "source": [
        "# Create logits\n",
        "unlabel_logits = build_bert_logits(unlabel_texts, bert_clf, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/62.5\n",
            "1/62.5\n",
            "2/62.5\n",
            "3/62.5\n",
            "4/62.5\n",
            "5/62.5\n",
            "6/62.5\n",
            "7/62.5\n",
            "8/62.5\n",
            "9/62.5\n",
            "10/62.5\n",
            "11/62.5\n",
            "12/62.5\n",
            "13/62.5\n",
            "14/62.5\n",
            "15/62.5\n",
            "16/62.5\n",
            "17/62.5\n",
            "18/62.5\n",
            "19/62.5\n",
            "20/62.5\n",
            "21/62.5\n",
            "22/62.5\n",
            "23/62.5\n",
            "24/62.5\n",
            "25/62.5\n",
            "26/62.5\n",
            "27/62.5\n",
            "28/62.5\n",
            "29/62.5\n",
            "30/62.5\n",
            "31/62.5\n",
            "32/62.5\n",
            "33/62.5\n",
            "34/62.5\n",
            "35/62.5\n",
            "36/62.5\n",
            "37/62.5\n",
            "38/62.5\n",
            "39/62.5\n",
            "40/62.5\n",
            "41/62.5\n",
            "42/62.5\n",
            "43/62.5\n",
            "44/62.5\n",
            "45/62.5\n",
            "46/62.5\n",
            "47/62.5\n",
            "48/62.5\n",
            "49/62.5\n",
            "50/62.5\n",
            "51/62.5\n",
            "52/62.5\n",
            "53/62.5\n",
            "54/62.5\n",
            "55/62.5\n",
            "56/62.5\n",
            "57/62.5\n",
            "58/62.5\n",
            "59/62.5\n",
            "60/62.5\n",
            "61/62.5\n",
            "62/62.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-9KNxq61XU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d73ce1ef-1c12-4541-a9b7-aad2386d041c"
      },
      "source": [
        "# Run regression\n",
        "unlabel_model = make_pipeline(CountVectorizer(ngram_range=(1,2)), LinearRegression()).fit(unlabel_texts, unlabel_logits)\n",
        "unlabel_predicted_logits = unlabel_model.predict(test_texts)\n",
        "unlabel_bert_predicted=torch.max(torch.tensor(unlabel_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,unlabel_bert_predicted))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.68      0.73       202\n",
            "           1       0.71      0.81      0.76       198\n",
            "\n",
            "    accuracy                           0.74       400\n",
            "   macro avg       0.75      0.75      0.74       400\n",
            "weighted avg       0.75      0.74      0.74       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CF7NVnC-PJQ",
        "colab_type": "text"
      },
      "source": [
        "8. Distill with unlabel with Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R85MsqAd6Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPaVqMn0z57F",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRA5fkfez5-0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEt6QbuMz6Cf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4RhyMx-z6GI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5joH5Wipzal",
        "colab_type": "text"
      },
      "source": [
        "Init/Build train_y_tensor and test_y_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfbsSdA8q0Rt",
        "colab_type": "text"
      },
      "source": [
        "Distill with unlabeled samples + training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTtNQCdQmnkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mix_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(np.concatenate((train_texts,unlabeled_texts),axis=0), np.concatenate((train_logits_load,unlabeled_logits.to_numpy())))\n",
        "mix_predicted_logits = mix_model.predict(test_texts)\n",
        "mix_bert_predicted=torch.max(torch.tensor(mix_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor,mix_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvM79PgsmuRw",
        "colab_type": "text"
      },
      "source": [
        "Distill with STS data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pRto5r0V02E-",
        "colab": {}
      },
      "source": [
        "def build_bert_logits(texts, bert_clf,tokenizer, batch_size):\n",
        "\n",
        "  tokenized = texts.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "  tokenized_limted = []\n",
        "  for i in tokenized.values:\n",
        "    if len(i)>max_bert_len:\n",
        "      tokenized_limted.append(i[:max_bert_len])\n",
        "    else:\n",
        "      tokenized_limted.append(i)\n",
        "\n",
        "  padded = np.array([i + [0]*(max_bert_len-len(i)) for i in tokenized_limted])\n",
        "\n",
        "  attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "  input_ids = torch.tensor(padded)  \n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "  #tokens_tensor = torch.tensor(input_ids)\n",
        "  #masks_tensor = torch.tensor(attention_mask)\n",
        "\n",
        "  dataset = TensorDataset(input_ids, attention_mask)\n",
        "  dataloader = DataLoader(dataset, batch_size)\n",
        "\n",
        "  bert_clf.eval()\n",
        "  list_logits = []\n",
        "  with torch.no_grad():\n",
        "      for step_num, batch_data in enumerate(dataloader):\n",
        "\n",
        "          token_ids, masks = tuple(t for t in batch_data)\n",
        "\n",
        "          logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "          list_logits += list(logits)\n",
        "\n",
        "          print(\"{0}/{1}\".format(step_num, len(dataset) / batch_size))\n",
        "\n",
        "  list_logits_numpy= (i.numpy() for i in list_logits)\n",
        "  logits = np.vstack(list_logits_numpy)\n",
        "  return(logits)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0KGGDbP2Y0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiL-UHfQ2ZNd",
        "colab_type": "text"
      },
      "source": [
        "**N-gram plus Glove embedding** \n",
        "Example code: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb \n",
        "\n",
        "https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/Glove_CNN_MultiClass.ipynb#scrollTo=tnUazzVHSuB6"
      ]
    }
  ]
}