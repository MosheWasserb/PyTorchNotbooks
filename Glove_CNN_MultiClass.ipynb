{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove CNN MultiClass.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/Glove_CNN_MultiClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StfRpRW1SuBw",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Based Emotion Recognition with PyTorch\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/emotion_classifier.png?raw=true)\n",
        "\n",
        "In this notebook we are going to learn how to train deep neural networks, such as recurrent neural networks (RNNs), for addressing a natural language task known as **emotion recognition**. We will cover everything you need to know to get started with NLP using deep learning frameworks such as TensorFlow. We will cover the common best practices, functionalities, and steps you need to understand the basics of TensorFlow APIs to build powerful predictive models via the computation graph. In the process of building our models, we will compare PyTorch and TensorFlow to let the learner appreciate the strenghts of each tool.\n",
        "\n",
        "by [Elvis Saravia](https://twitter.com/omarsar0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIkM141cSuBz",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrz3-nSrSuB1",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "1. Deep Learning Frameworks\n",
        "     - 1.1 Eager execution\n",
        "     - 1.2 Computation graph\n",
        "2. Tensors\n",
        "    - 2.1 Basic math with tensors\n",
        "    - 2.2 Transforming tensors\n",
        "3. Data\n",
        "    - 3.1 Preprocessing data\n",
        "        - Tokenization and Sampling\n",
        "        - Constructing Vocabulary and Index-Word Mapping\n",
        "    - 3.2 Converting data into tensors\n",
        "    - 3.3 Padding data\n",
        "    - 3.4 Binarization\n",
        "    - 3.5 Split data\n",
        "    - 3.6 Data Loader\n",
        "4. Model\n",
        "    - 4.1 Pretesting Model\n",
        "    - 4.2 Testing models with eager execution\n",
        "5. Training\n",
        "6. Evaluation on Testing Dataset\n",
        "    - 6.1 Confusion matrix\n",
        "- Final Words\n",
        "- References\n",
        "- *Storing models and setting checkpoints (Exercise)*\n",
        "- *Restoring models (Exercise)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy9JWaqqSuB1",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbWgC0tSuB3",
        "colab_type": "text"
      },
      "source": [
        "## 1. Deep Learning Frameworks\n",
        "There are many deep learning frameworks such as Chainer, DyNet, MXNet, PyTorch, TensorFlow, and Keras. Each framework has their own strenghts which a researcher or a developer may want to consider before choosing the right framework. In my opinion, PyTorch is great for researchers and offers eager execution by default, but its high-level APIs require some understanding of deep learning concepts such as **affine layers** and **automatic differentiation**. On the other hand, TensorFlow was originally built as a low-level API that provides a robust list of functionalities to build deep learning models from the ground up. More recently, TensorFlow also offers **eager execution** and is equipped with a high-level API known as Keras.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/dl_frameworks.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suv8DnrQSuB5",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Eager Execution\n",
        "Eager execution allows us to operate on the computation graph dynamically, also known as **imperative programming**. TensorFlow requires that you manually set this mode, while PyTorch comes with this mode by default. Below we import the necessary libraries to use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CURzvVldMJcU",
        "colab_type": "code",
        "outputId": "84d131ce-d1c5-488b-bea8-8b90cffc829b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUazzVHSuB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK69ztCKSuB-",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Computation Graph\n",
        "A simplified definition of a neural network is a string of functions that are **differentiable** and that we can combine together to get more complicated functions. An intuitive way to express this process is through computation graphs. \n",
        "\n",
        "![alt txt](http://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png)\n",
        "\n",
        "Image credit: [Chris Olah](http://colah.github.io/posts/2015-08-Backprop/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6243JBwQSuB_",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensors\n",
        "Tensors are the fundamental data structure used to store data that will be fed as input to a computation graph for processing and applying tranformations. Let's create two tensors and multiply them, and then output the result. The figure below shows a 4-D Tensor.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/tensor.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72g6eRGSuCA",
        "colab_type": "code",
        "outputId": "db89cbc8-48c9-4534-ccf1-a6eb2c7355bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "c = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "d = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n",
        "e = torch.matmul(c, d)\n",
        "print(e)\n",
        "print(c.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 3.],\n",
            "        [3., 7.]])\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTM0Y6hSuCF",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Math with Tensors\n",
        "PyTorch and other deep learning libraries like TensorFlow allow you to do **automatic differentation**. Let's try to compute the derivative of a function -- in this case that function is stored in the variable `z`. In PyTorch, the option `requires_grad=True` tracks all operations applied to the input tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855r1t0MSuCG",
        "colab_type": "code",
        "outputId": "4769ffbb-f831-4298-a536-b6e80cf72dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "### Automatic differentiation with PyTorch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "# an operation of tensor\n",
        "y = x + 2 # y inherits grad_fn\n",
        "\n",
        "# apply operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(out)\n",
        "\n",
        "out.backward()\n",
        "\n",
        "print(x.grad) # d(out)/dx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(27., grad_fn=<MeanBackward1>)\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwHvtrCLSuCK",
        "colab_type": "text"
      },
      "source": [
        "You can verfiy the output with the equations in the figure below:\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/autograd.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6j5_2wFSuCL",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Transforming Tensors\n",
        "We can also apply some transformation to a tensor such as adding a dimension or transposing it. Let's try both adding a dimension and transposing a matrix below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT8u_3rzSuCL",
        "colab_type": "code",
        "outputId": "6018aee4-08ab-4995-eeb7-005710f7835e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"X shape: \", x.size())\n",
        "\n",
        "# add dimension\n",
        "print(x.unsqueeze(1).size()) \n",
        "\n",
        "# transpose \n",
        "torch.transpose(x, 0,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:  torch.Size([2, 3])\n",
            "torch.Size([2, 1, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggtl1m6aSuCP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Emotion Dataset\n",
        "In this notebook we are working on an emotion classification task. The dataset contains tweets labeled into 6 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JqoUiTSuCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVCiiFsBNbuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bliFaijvNfIZ",
        "colab_type": "code",
        "outputId": "e8310428-98d6-418c-97ec-6ceba8950884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2qHNv2-N9BC",
        "colab_type": "text"
      },
      "source": [
        "We had already processed the data for you. You can find the pickle file [here](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/data/merged_training.pkl)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2sYWY79SuCS",
        "colab_type": "code",
        "outputId": "329e422a-6b38-414a-d349-96f696c0fbc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "data.emotions.value_counts().plot.bar()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2a7b39fc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqEpIREREVUIiIiKqEhIREVH1/wGfA/dLdXaziQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNSP0G-SuCV",
        "colab_type": "code",
        "outputId": "c0148689-0d9f-400e-fd1e-572e10315984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ive probably mentioned this before but i reall...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i was feeling a little low few days back</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i beleive that i am much more sensitive to oth...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i find myself frustrated with christians becau...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i am one of those people who feels like going ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i feel especially pleased about this as this h...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i was struggling with these awful feelings and...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i feel so enraged but helpless at the same time</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text emotions\n",
              "0  i feel awful about it too because it s my job ...  sadness\n",
              "1                              im alone i feel awful  sadness\n",
              "2  ive probably mentioned this before but i reall...      joy\n",
              "3           i was feeling a little low few days back  sadness\n",
              "4  i beleive that i am much more sensitive to oth...     love\n",
              "5  i find myself frustrated with christians becau...     love\n",
              "6  i am one of those people who feels like going ...      joy\n",
              "7  i feel especially pleased about this as this h...      joy\n",
              "8  i was struggling with these awful feelings and...      joy\n",
              "9    i feel so enraged but helpless at the same time    anger"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nI00TmkSuCY",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Preprocessing Data\n",
        "In the next steps we are going to create tokenize the text, create index mapping for words, and also construct a vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCHxi2ASuCZ",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDgIXGGSuCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=8000, random_state = 42);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzGIGsJAZL7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def generate_bigrams(x):\n",
        "      n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "      for n_gram in n_grams:\n",
        "          x.append(' '.join(n_gram))\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNrOA7mSuCe",
        "colab_type": "text"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KouYEDoNSuCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            # self.vocab.update(generate_bigrams(s.split(' ')))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFasv0ASuCi",
        "colab_type": "code",
        "outputId": "2e913c93-451d-41a2-b979-37f3d31a1099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aajao',\n",
              " 'aakhri',\n",
              " 'aarons',\n",
              " 'aba',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abandoning',\n",
              " 'abandonment',\n",
              " 'abbey']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M-xGmQZNP5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bef7232e-8f25-4618-9d83-cc496d5613e3"
      },
      "source": [
        "len(inputs.vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO2QDJhPOlnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6df761d-cfe8-4db4-d798-9409f8acf279"
      },
      "source": [
        "inputs.vocab[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqf0tC3FSuCk",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Converting Data into Tensors \n",
        "For convenience we would like to convert the data into tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omlfNU8hSuCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmSLhUdOMLPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99bc331d-a50c-4e03-e3ee-64e49e641a80"
      },
      "source": [
        "inputs.idx2word[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AphKgs33SuCn",
        "colab_type": "code",
        "outputId": "4d5124ce-abf8-44c6-be6f-bdf14d82d0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4507,\n",
              "  2716,\n",
              "  5160,\n",
              "  4532,\n",
              "  4920,\n",
              "  5055,\n",
              "  6080,\n",
              "  5969,\n",
              "  10332,\n",
              "  4507,\n",
              "  7447,\n",
              "  9446,\n",
              "  413,\n",
              "  9446,\n",
              "  5964,\n",
              "  1263,\n",
              "  4507,\n",
              "  1313,\n",
              "  685,\n",
              "  3720,\n",
              "  4911,\n",
              "  3409,\n",
              "  1,\n",
              "  5430,\n",
              "  5327,\n",
              "  9383,\n",
              "  4593],\n",
              " [4552,\n",
              "  4407,\n",
              "  9427,\n",
              "  5380,\n",
              "  9446,\n",
              "  6209,\n",
              "  2754,\n",
              "  923,\n",
              "  9446,\n",
              "  9509,\n",
              "  8570,\n",
              "  9392,\n",
              "  4507,\n",
              "  10456,\n",
              "  3025,\n",
              "  9956,\n",
              "  3409,\n",
              "  553,\n",
              "  2487,\n",
              "  553,\n",
              "  4507,\n",
              "  2517,\n",
              "  9398,\n",
              "  5236,\n",
              "  9509,\n",
              "  4507,\n",
              "  9755,\n",
              "  4605,\n",
              "  1,\n",
              "  2754,\n",
              "  4507,\n",
              "  10225,\n",
              "  2487,\n",
              "  829,\n",
              "  1,\n",
              "  4448,\n",
              "  4449,\n",
              "  6205]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoIfZHjSuCr",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Padding data\n",
        "In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbSHvs0SuCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zyXKoy6SuCw",
        "colab_type": "code",
        "outputId": "d29c7240-224c-445e-b81d-2686da7d1eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk71VEPSuC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wKDdBCSuC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dok2XcWSuC7",
        "colab_type": "code",
        "outputId": "7591f2ed-ae39-404c-a17d-178a12fcd527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 4507,  2716,  5160,  4532,  4920,  5055,  6080,  5969, 10332,\n",
              "         4507,  7447,  9446,   413,  9446,  5964,  1263,  4507,  1313,\n",
              "          685,  3720,  4911,  3409,     1,  5430,  5327,  9383,  4593,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([ 4552,  4407,  9427,  5380,  9446,  6209,  2754,   923,  9446,\n",
              "         9509,  8570,  9392,  4507, 10456,  3025,  9956,  3409,   553,\n",
              "         2487,   553,  4507,  2517,  9398,  5236,  9509,  4507,  9755,\n",
              "         4605,     1,  2754,  4507, 10225,  2487,   829,     1,  4448,\n",
              "         4449,  6205,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqU4Lo48-TAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define dict to hold a word and its vector\n",
        "glove = {}\n",
        "# read the word embeddings file ~820MB\n",
        "f = open('/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/glove.6B.100d.txt', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    glove[word] = coefs\n",
        "f.close()\n",
        "# check the length\n",
        "len(glove) # 400000\n",
        "\n",
        "# Build pre-trained embeddings \n",
        "emb_dim = 100\n",
        "matrix_len = len(inputs.vocab)+1\n",
        "weights_matrix = np.zeros((matrix_len, emb_dim))\n",
        "words_found = 0\n",
        "s=[]\n",
        "\n",
        "weights_matrix[0] = np.zeros((emb_dim,))   # <pad> \n",
        "for i, word in enumerate(inputs.vocab):\n",
        "    try: \n",
        "        weights_matrix[i+1] = glove[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i+1] = np.zeros((emb_dim,))\n",
        "\n",
        "pretrained_embeddings = weights_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BshYDyxTBTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78d61ee0-780f-49e8-af11-db5302cd32db"
      },
      "source": [
        "words_found\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10061"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMCrIKt0V2Et",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fc35c4c-d814-4999-bbee-232d75f01348"
      },
      "source": [
        "inputs.idx2word[0]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBN6xAsGSuDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_369xrpSuDC",
        "colab_type": "code",
        "outputId": "11dc91bf-e9a6-40de-8414-d184ce261299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "target_tensor[0:2] "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZMnNbUSuDF",
        "colab_type": "code",
        "outputId": "ddf95a0d-d34f-41b2-b167-4607fd9bc8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>262883</th>\n",
              "      <td>i told my mom the other day i feel like i m al...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81642</th>\n",
              "      <td>i think its the strong feelings that i have fo...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions  token_size\n",
              "262883  i told my mom the other day i feel like i m al...  sadness          23\n",
              "81642   i think its the strong feelings that i have fo...  sadness          19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCgbz5icSuDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bI6rF59SuDK",
        "colab_type": "code",
        "outputId": "deef779c-955c-4112-da62-63aef240eedd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxi-STseSuDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRkO7WISuDN",
        "colab_type": "code",
        "outputId": "06191c32-b443-43ce-aa31-931cf86c8239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b679640ce8f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memotion_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'emotion_dict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWDE42iSuDQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Split data\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQuGQReSuDR",
        "colab_type": "code",
        "outputId": "77e69c51-7cce-4452-f3b5-c3635b499a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "input_tensor_test = input_tensor_val\n",
        "target_tensor_test = target_tensor_val\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "#input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6400, 6400, 1600, 1600, 1600, 1600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ0GXI9SuDX",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 Data Loader\n",
        "We can also laod the data into a data loader, which makes it easy to **manipulate the data**, **create batches**, and apply further **transformations**. In PyTorch we can use the `DataLoader` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xtwf8nSuDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 100\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDa8eJVSuDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0Of7YiSuDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgVVs1XSuDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQNqg9xSuDe",
        "colab_type": "code",
        "outputId": "b8669f9b-307a-4f7b-9ecc-bd02cb1667c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_dataset.batch_size"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqYHyFGwSuDh",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model\n",
        "After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details. \n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/gru-model.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHYthQdSuDi",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Constructing the Model\n",
        "Below we construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVXtMhf3SuDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        with torch.no_grad():\n",
        "          x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYAaRzW6vU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "189ab17d-6130-4ce4-faa7-cc56d1d92351"
      },
      "source": [
        "\n",
        "\n",
        "# Othe option (in Model class)\n",
        "#embedding\n",
        "#self.embeddings = nn.Embedding.from_pretrained(matrix_embeddings)\n",
        "#self.embeddings.requires_grad = False"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d9299ac50790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEmoGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Othe option (in Model class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 5 required positional arguments: 'vocab_size', 'embedding_dim', 'hidden_units', 'batch_sz', and 'output_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6GVV87SuDk",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Pretesting model\n",
        "Since eager execution is enabled we can print the output of the model by passing a sample of the dataset and making sure that the dimensions of the outputs are the expected ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjomHaHbSuDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhymNqRSuDn",
        "colab_type": "code",
        "outputId": "401096b7-38d5-4e27-86c9-f4a88f112248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "\n",
        "# Load Glove parameters \n",
        "model.embedding.weight.data.copy_(torch.tensor(pretrained_embeddings))\n",
        "\n",
        "#model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(output.size())"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([69, 64])\n",
            "torch.Size([64, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRXfA2NSuDp",
        "colab_type": "text"
      },
      "source": [
        "## 5. Training the Model\n",
        "Now that we have tested the model, it is time to train it. We will define out optimization algorithm, learnin rate, and other necessary information to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFuDTsrUSuDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "# Load Glove parameters \n",
        "model.embedding.weight.data.copy_(torch.tensor(pretrained_embeddings))\n",
        "model.embeddings.requires_grad = False \n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyvsSQrPSuDr",
        "colab_type": "code",
        "outputId": "a2793d44-7618-4e54-a2a2-3345a99fc995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.2999\n",
            "Epoch 1 Loss 0.2718 -- Train Acc. 31.9688 -- Val Acc. 33.7500\n",
            "Time taken for 1 epoch 284.92946219444275 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.2485\n",
            "Epoch 2 Loss 0.2645 -- Train Acc. 32.4375 -- Val Acc. 29.4375\n",
            "Time taken for 1 epoch 284.65522360801697 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.2708\n",
            "Epoch 3 Loss 0.2641 -- Train Acc. 32.6562 -- Val Acc. 33.5625\n",
            "Time taken for 1 epoch 286.00696849823 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.2811\n",
            "Epoch 4 Loss 0.2322 -- Train Acc. 43.0469 -- Val Acc. 71.7500\n",
            "Time taken for 1 epoch 285.67919993400574 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.1087\n",
            "Epoch 5 Loss 0.0788 -- Train Acc. 83.8594 -- Val Acc. 90.0625\n",
            "Time taken for 1 epoch 283.26186513900757 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.0455\n",
            "Epoch 6 Loss 0.0330 -- Train Acc. 92.8750 -- Val Acc. 93.5625\n",
            "Time taken for 1 epoch 282.35273361206055 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.0332\n",
            "Epoch 7 Loss 0.0209 -- Train Acc. 94.9531 -- Val Acc. 93.0625\n",
            "Time taken for 1 epoch 280.1788213253021 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.0286\n",
            "Epoch 8 Loss 0.0163 -- Train Acc. 95.9375 -- Val Acc. 93.5000\n",
            "Time taken for 1 epoch 279.0558063983917 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.0054\n",
            "Epoch 9 Loss 0.0127 -- Train Acc. 96.8125 -- Val Acc. 93.8750\n",
            "Time taken for 1 epoch 279.43371200561523 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.0086\n",
            "Epoch 10 Loss 0.0109 -- Train Acc. 97.1406 -- Val Acc. 93.7500\n",
            "Time taken for 1 epoch 278.3897864818573 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72jYWoxDSuDt",
        "colab_type": "code",
        "outputId": "95994b6c-7426-4a0a-c24e-33959a7817a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(73887, 256)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiF3LKuSuDu",
        "colab_type": "text"
      },
      "source": [
        "## 6. Evaluation on the Testing Data\n",
        "Now we will evaluate the model with the holdout dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IORQgwSuDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "device = \"cuda\" # we don't need GPU to do testing\n",
        "#model.to(\"cuda\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTLKA47iSuDz",
        "colab_type": "text"
      },
      "source": [
        "### 6.1 Confusion Matrix\n",
        "The test accuracy alone is not an interesting performance metric in this case. Let's plot a confusion matrix to get a drilled down view of how the model is performing with regards to each emotion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM9g0v7sRTTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Class to Properly Evaluate our Models\n",
        "class Evaluate():\n",
        "\n",
        "    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n",
        "        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n",
        "        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n",
        "        y_va = target.dot(va_matrix)\n",
        "        F_va = prediction.dot(va_matrix)\n",
        "\n",
        "        # dist is a one row vector with size of the test data passed(emotion)\n",
        "        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n",
        "        res = stats.describe(dist)\n",
        "\n",
        "        # print by default (if silent=False)\n",
        "        if not silent:\n",
        "            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n",
        "\n",
        "        return {\n",
        "            'distances': dist,\n",
        "            'dist_stat': res\n",
        "        }\n",
        "\n",
        "    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n",
        "        \"\"\" Compute only the predicted class \"\"\"\n",
        "        p_2_annotation = dict()\n",
        "\n",
        "        precision_recall_fscore_support = [\n",
        "            (pair[0], pair[1].mean()) for pair in zip(\n",
        "                ['precision', 'recall', 'f1', 'support'],\n",
        "                metrics.precision_recall_fscore_support(target, predictions)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        metrics.precision_recall_fscore_support(target, predictions)\n",
        "\n",
        "        # confusion matrix\n",
        "        le = LabelEncoder()\n",
        "        target_le = le.fit_transform(target)\n",
        "        predictions_le = le.transform(predictions)\n",
        "        cm = metrics.confusion_matrix(target_le, predictions_le)\n",
        "\n",
        "        # prediction if two annotations are given on test data\n",
        "        if target2:\n",
        "            p_2_annotation = pd.DataFrame(\n",
        "                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n",
        "                columns=['emo','success']\n",
        "            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n",
        "\n",
        "        if not silent:\n",
        "            print(\"Default Classification report\")\n",
        "            print(metrics.classification_report(target, predictions))\n",
        "\n",
        "            # print if target2 was provided\n",
        "            if len(p_2_annotation) > 0:\n",
        "                print('\\nPrecision on 2 annotations:')\n",
        "                for emo in p_2_annotation:\n",
        "                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n",
        "\n",
        "            # print accuracies, precision, recall, and f1\n",
        "            print('\\nAccuracy:')\n",
        "            print(metrics.accuracy_score(target, predictions))\n",
        "            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n",
        "            for to_print in precision_recall_fscore_support[:3]:\n",
        "                print( \"%s: %.2f\" % to_print )\n",
        "\n",
        "            # normalizing the values of the consfusion matrix\n",
        "            print('\\nconfusion matrix\\n %s' % cm)\n",
        "            print('(row=expected, col=predicted)')\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n",
        "\n",
        "        return {\n",
        "            'precision_recall_fscore_support': precision_recall_fscore_support,\n",
        "            'accuracy': metrics.accuracy_score(target, predictions),\n",
        "            'p_2_annotation': p_2_annotation,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "    def predict_class(cls, X_train, y_train, X_test, y_test,\n",
        "                      pipeline, silent=False, target2=None):\n",
        "        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict(X_test)\n",
        "        print(\"predictions computed....\")\n",
        "        return cls.evaluate_class(predictions, y_test, target2, silent)\n",
        "\n",
        "    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Evaluate through probability \"\"\"\n",
        "        # Run normal class evaluator\n",
        "        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n",
        "        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n",
        "\n",
        "        if not silent:\n",
        "            print('\\n - First Emotion Classification Metrics -')\n",
        "            print('\\n - Multiple Emotion rank Metrics -')\n",
        "            print('VA Cosine Distance')\n",
        "\n",
        "        classes_dist = [\n",
        "            (\n",
        "                emo,\n",
        "                cls.va_dist(\n",
        "                    prediction[np.array(target_class) == emo],\n",
        "                    target_rank[np.array(target_class) == emo],\n",
        "                    va_df,\n",
        "                    binarizer,\n",
        "                    emo,\n",
        "                    silent)\n",
        "                ) for emo in binarizer.classes_\n",
        "        ]\n",
        "        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n",
        "\n",
        "        coverage_error = metrics.coverage_error(target_rank, prediction)\n",
        "        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n",
        "        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n",
        "        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n",
        "\n",
        "        # recall at 2\n",
        "        # obtain top two predictions\n",
        "        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n",
        "        recall_at_2 = pd.DataFrame(\n",
        "            [\n",
        "            t in p for t, p in zip(target_class, top2_pred)\n",
        "            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n",
        "\n",
        "        # combine target into sets\n",
        "        if target2:\n",
        "            union_target = [set(t) for t in zip(target_class, target2)]\n",
        "        else:\n",
        "            union_target = [set(t) for t in zip(target_class)]\n",
        "\n",
        "        # precision at k\n",
        "        top_k_pred = [\n",
        "            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n",
        "            for i in range(2, len(binarizer.classes_)+1)]\n",
        "        precision_at_k = [\n",
        "            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n",
        "            for k in range(len(top_k_pred))]\n",
        "\n",
        "        # do this if silent= False\n",
        "        if not silent:\n",
        "            print('\\n')\n",
        "            print(recall_at_2)\n",
        "            print('\\n')\n",
        "            print('p@k')\n",
        "            for pk in precision_at_k:\n",
        "                print(pk[0] + ':\\t' + str(pk[1]))\n",
        "            print('\\ncoverage_error: %f' % coverage_error)\n",
        "            print('average_precision_score: %f' % average_precision_score)\n",
        "            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n",
        "            print('label_ranking_loss: %f' % label_ranking_loss)\n",
        "\n",
        "        return {\n",
        "            'class_eval': class_eval,\n",
        "            'recall_at_2': recall_at_2.to_dict(),\n",
        "            'precision_at_2': precision_at_k,\n",
        "            'classes_dist': classes_dist,\n",
        "            'avg_dist': avg_dist,\n",
        "            'coverage_error': coverage_error,\n",
        "            'average_precision_score': average_precision_score,\n",
        "            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n",
        "            'label_ranking_loss': label_ranking_loss\n",
        "        }\n",
        "\n",
        "\n",
        "    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Output predcations based on training and labels \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict_proba(X_test)\n",
        "        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n",
        "        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\" Plotting the confusion_matrix\"\"\"\n",
        "        plt.rc('figure', figsize=(4, 4), dpi=100)\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(my_tags))\n",
        "        target_names = my_tags\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "        \n",
        "        # add normalized values inside the Confusion matrix\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUWz-LBSuDz",
        "colab_type": "code",
        "outputId": "57c7c8ea-fb28-4fa4-9084-67bee1bc7f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "evaluator = Evaluate()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p.cpu().detach().numpy())\n",
        "        \n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
        "\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n",
        "\n",
        "model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n",
        "test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.emotion, test.emotion );"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Classification report\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: Mean of empty slice.\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-079a0dd5c7f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0memotion_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_test_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memotion\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-68-13ede1d24b84>\u001b[0m in \u001b[0;36mevaluate_class\u001b[0;34m(cls, predictions, target, target2, silent)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Default Classification report\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# print if target2 was provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:>{width}s} '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' {:>9}'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSWw72w6VOY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTCznkUGSuD3",
        "colab_type": "text"
      },
      "source": [
        "## Final Words\n",
        "You have learned how to perform neural-based emotion recognition using RNNs. There are many things you can do after you have completed this tutorial. You can attempt the exercises outlined in the \"Outline\" section of this notebook. You can also try other types of neural architectures such as LSTMs, Bi-LSTMS, attentions models, and CNNs. In addition, you can also store the models and conduct transfer learning to other emotion-related tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbkPHgFSuD3",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLfZrr2oSuD4",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "- [Deep Learning for NLP](https://docs.google.com/presentation/d/1cf2H1qMvP1rdKUF5000ifOIRv1_b0bvj0ZTVL7-RaVE/edit?usp=sharing)\n",
        "- [PyTorch Autograd Tutorial](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
        "- [A Simple Neural Network from Scratch with PyTorch and Google Colab](https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0)\n",
        "- [Building RNNs is Fun with PyTorch and Google Colab](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79?source=collection_home---4------2---------------------)\n",
        "- [Deep Learning for NLP: An Overview of Recent Trends](https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d)"
      ]
    }
  ]
}