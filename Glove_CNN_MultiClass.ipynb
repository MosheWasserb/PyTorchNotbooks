{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove CNN MultiClass.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/Glove_CNN_MultiClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StfRpRW1SuBw",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Based Emotion Recognition with PyTorch\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/emotion_classifier.png?raw=true)\n",
        "\n",
        "In this notebook we are going to learn how to train deep neural networks, such as recurrent neural networks (RNNs), for addressing a natural language task known as **emotion recognition**. We will cover everything you need to know to get started with NLP using deep learning frameworks such as TensorFlow. We will cover the common best practices, functionalities, and steps you need to understand the basics of TensorFlow APIs to build powerful predictive models via the computation graph. In the process of building our models, we will compare PyTorch and TensorFlow to let the learner appreciate the strenghts of each tool.\n",
        "\n",
        "by [Elvis Saravia](https://twitter.com/omarsar0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIkM141cSuBz",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrz3-nSrSuB1",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "1. Deep Learning Frameworks\n",
        "     - 1.1 Eager execution\n",
        "     - 1.2 Computation graph\n",
        "2. Tensors\n",
        "    - 2.1 Basic math with tensors\n",
        "    - 2.2 Transforming tensors\n",
        "3. Data\n",
        "    - 3.1 Preprocessing data\n",
        "        - Tokenization and Sampling\n",
        "        - Constructing Vocabulary and Index-Word Mapping\n",
        "    - 3.2 Converting data into tensors\n",
        "    - 3.3 Padding data\n",
        "    - 3.4 Binarization\n",
        "    - 3.5 Split data\n",
        "    - 3.6 Data Loader\n",
        "4. Model\n",
        "    - 4.1 Pretesting Model\n",
        "    - 4.2 Testing models with eager execution\n",
        "5. Training\n",
        "6. Evaluation on Testing Dataset\n",
        "    - 6.1 Confusion matrix\n",
        "- Final Words\n",
        "- References\n",
        "- *Storing models and setting checkpoints (Exercise)*\n",
        "- *Restoring models (Exercise)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy9JWaqqSuB1",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbWgC0tSuB3",
        "colab_type": "text"
      },
      "source": [
        "## 1. Deep Learning Frameworks\n",
        "There are many deep learning frameworks such as Chainer, DyNet, MXNet, PyTorch, TensorFlow, and Keras. Each framework has their own strenghts which a researcher or a developer may want to consider before choosing the right framework. In my opinion, PyTorch is great for researchers and offers eager execution by default, but its high-level APIs require some understanding of deep learning concepts such as **affine layers** and **automatic differentiation**. On the other hand, TensorFlow was originally built as a low-level API that provides a robust list of functionalities to build deep learning models from the ground up. More recently, TensorFlow also offers **eager execution** and is equipped with a high-level API known as Keras.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/dl_frameworks.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suv8DnrQSuB5",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Eager Execution\n",
        "Eager execution allows us to operate on the computation graph dynamically, also known as **imperative programming**. TensorFlow requires that you manually set this mode, while PyTorch comes with this mode by default. Below we import the necessary libraries to use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CURzvVldMJcU",
        "colab_type": "code",
        "outputId": "84d131ce-d1c5-488b-bea8-8b90cffc829b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUazzVHSuB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK69ztCKSuB-",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Computation Graph\n",
        "A simplified definition of a neural network is a string of functions that are **differentiable** and that we can combine together to get more complicated functions. An intuitive way to express this process is through computation graphs. \n",
        "\n",
        "![alt txt](http://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png)\n",
        "\n",
        "Image credit: [Chris Olah](http://colah.github.io/posts/2015-08-Backprop/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6243JBwQSuB_",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensors\n",
        "Tensors are the fundamental data structure used to store data that will be fed as input to a computation graph for processing and applying tranformations. Let's create two tensors and multiply them, and then output the result. The figure below shows a 4-D Tensor.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/tensor.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72g6eRGSuCA",
        "colab_type": "code",
        "outputId": "db89cbc8-48c9-4534-ccf1-a6eb2c7355bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "c = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "d = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n",
        "e = torch.matmul(c, d)\n",
        "print(e)\n",
        "print(c.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 3.],\n",
            "        [3., 7.]])\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTM0Y6hSuCF",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Math with Tensors\n",
        "PyTorch and other deep learning libraries like TensorFlow allow you to do **automatic differentation**. Let's try to compute the derivative of a function -- in this case that function is stored in the variable `z`. In PyTorch, the option `requires_grad=True` tracks all operations applied to the input tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855r1t0MSuCG",
        "colab_type": "code",
        "outputId": "4769ffbb-f831-4298-a536-b6e80cf72dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "### Automatic differentiation with PyTorch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "# an operation of tensor\n",
        "y = x + 2 # y inherits grad_fn\n",
        "\n",
        "# apply operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(out)\n",
        "\n",
        "out.backward()\n",
        "\n",
        "print(x.grad) # d(out)/dx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(27., grad_fn=<MeanBackward1>)\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwHvtrCLSuCK",
        "colab_type": "text"
      },
      "source": [
        "You can verfiy the output with the equations in the figure below:\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/autograd.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6j5_2wFSuCL",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Transforming Tensors\n",
        "We can also apply some transformation to a tensor such as adding a dimension or transposing it. Let's try both adding a dimension and transposing a matrix below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT8u_3rzSuCL",
        "colab_type": "code",
        "outputId": "6018aee4-08ab-4995-eeb7-005710f7835e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"X shape: \", x.size())\n",
        "\n",
        "# add dimension\n",
        "print(x.unsqueeze(1).size()) \n",
        "\n",
        "# transpose \n",
        "torch.transpose(x, 0,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:  torch.Size([2, 3])\n",
            "torch.Size([2, 1, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggtl1m6aSuCP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Emotion Dataset\n",
        "In this notebook we are working on an emotion classification task. The dataset contains tweets labeled into 6 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JqoUiTSuCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVCiiFsBNbuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bliFaijvNfIZ",
        "colab_type": "code",
        "outputId": "8c418778-d2d9-43e0-9491-9020399bfafc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2qHNv2-N9BC",
        "colab_type": "text"
      },
      "source": [
        "We had already processed the data for you. You can find the pickle file [here](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/data/merged_training.pkl)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2sYWY79SuCS",
        "colab_type": "code",
        "outputId": "78fa2f5f-94e5-4b6e-a4b9-bf35e9e94fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "data.emotions.value_counts().plot.bar()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6c642e128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqEpIREREVUIiIiKqEhIREVH1/wGfA/dLdXaziQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNSP0G-SuCV",
        "colab_type": "code",
        "outputId": "c0148689-0d9f-400e-fd1e-572e10315984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ive probably mentioned this before but i reall...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i was feeling a little low few days back</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i beleive that i am much more sensitive to oth...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i find myself frustrated with christians becau...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i am one of those people who feels like going ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i feel especially pleased about this as this h...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i was struggling with these awful feelings and...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i feel so enraged but helpless at the same time</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text emotions\n",
              "0  i feel awful about it too because it s my job ...  sadness\n",
              "1                              im alone i feel awful  sadness\n",
              "2  ive probably mentioned this before but i reall...      joy\n",
              "3           i was feeling a little low few days back  sadness\n",
              "4  i beleive that i am much more sensitive to oth...     love\n",
              "5  i find myself frustrated with christians becau...     love\n",
              "6  i am one of those people who feels like going ...      joy\n",
              "7  i feel especially pleased about this as this h...      joy\n",
              "8  i was struggling with these awful feelings and...      joy\n",
              "9    i feel so enraged but helpless at the same time    anger"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nI00TmkSuCY",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Preprocessing Data\n",
        "In the next steps we are going to create tokenize the text, create index mapping for words, and also construct a vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCHxi2ASuCZ",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDgIXGGSuCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=8000, random_state = 42);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzGIGsJAZL7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def generate_bigrams(x):\n",
        "      n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "      for n_gram in n_grams:\n",
        "          x.append(' '.join(n_gram))\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNrOA7mSuCe",
        "colab_type": "text"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KouYEDoNSuCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            # self.vocab.update(generate_bigrams(s.split(' ')))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFasv0ASuCi",
        "colab_type": "code",
        "outputId": "be141307-ceea-47ee-cc1c-f3a3358e2fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aajao',\n",
              " 'aakhri',\n",
              " 'aarons',\n",
              " 'aba',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abandoning',\n",
              " 'abandonment',\n",
              " 'abbey']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M-xGmQZNP5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9720d837-8e72-4478-b150-bdd75ec726ec"
      },
      "source": [
        "len(inputs.vocab)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqf0tC3FSuCk",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Converting Data into Tensors \n",
        "For convenience we would like to convert the data into tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omlfNU8hSuCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AphKgs33SuCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoIfZHjSuCr",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Padding data\n",
        "In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbSHvs0SuCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zyXKoy6SuCw",
        "colab_type": "code",
        "outputId": "9548e83d-b465-46c4-906b-a99b63a1064f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk71VEPSuC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wKDdBCSuC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dok2XcWSuC7",
        "colab_type": "code",
        "outputId": "92759a89-be05-41b0-bc97-a6972e5bbe0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 4507,  2716,  5160,  4532,  4920,  5055,  6080,  5969, 10332,\n",
              "         4507,  7447,  9446,   413,  9446,  5964,  1263,  4507,  1313,\n",
              "          685,  3720,  4911,  3409,     1,  5430,  5327,  9383,  4593,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([ 4552,  4407,  9427,  5380,  9446,  6209,  2754,   923,  9446,\n",
              "         9509,  8570,  9392,  4507, 10456,  3025,  9956,  3409,   553,\n",
              "         2487,   553,  4507,  2517,  9398,  5236,  9509,  4507,  9755,\n",
              "         4605,     1,  2754,  4507, 10225,  2487,   829,     1,  4448,\n",
              "         4449,  6205,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqU4Lo48-TAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build pre-trained embeddings \n",
        "emb_dim = 100\n",
        "matrix_len = len(inputs.vocab)\n",
        "weights_matrix = np.zeros((matrix_len, emb_dim))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(inputs.vocab):\n",
        "    try: \n",
        "        weights_matrix[i] = glove[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
        "\n",
        "pretrained_embeddings = weights_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBN6xAsGSuDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_369xrpSuDC",
        "colab_type": "code",
        "outputId": "11dc91bf-e9a6-40de-8414-d184ce261299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "target_tensor[0:2] "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZMnNbUSuDF",
        "colab_type": "code",
        "outputId": "ddf95a0d-d34f-41b2-b167-4607fd9bc8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>262883</th>\n",
              "      <td>i told my mom the other day i feel like i m al...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81642</th>\n",
              "      <td>i think its the strong feelings that i have fo...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions  token_size\n",
              "262883  i told my mom the other day i feel like i m al...  sadness          23\n",
              "81642   i think its the strong feelings that i have fo...  sadness          19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCgbz5icSuDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bI6rF59SuDK",
        "colab_type": "code",
        "outputId": "deef779c-955c-4112-da62-63aef240eedd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxi-STseSuDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRkO7WISuDN",
        "colab_type": "code",
        "outputId": "47d18f46-c6c4-40be-e89d-347082fad0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'joy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWDE42iSuDQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Split data\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQuGQReSuDR",
        "colab_type": "code",
        "outputId": "4b12df38-64bc-44de-b324-0c5ecfe91398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "input_tensor_test = input_tensor_val\n",
        "target_tensor_test = target_tensor_val\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "#input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6400, 6400, 1600, 1600, 1600, 1600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ0GXI9SuDX",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 Data Loader\n",
        "We can also laod the data into a data loader, which makes it easy to **manipulate the data**, **create batches**, and apply further **transformations**. In PyTorch we can use the `DataLoader` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xtwf8nSuDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDa8eJVSuDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0Of7YiSuDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgVVs1XSuDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQNqg9xSuDe",
        "colab_type": "code",
        "outputId": "cd15f5a1-9f7e-47e4-f27a-8b1744c17d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_dataset.batch_size"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqYHyFGwSuDh",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model\n",
        "After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details. \n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/gru-model.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHYthQdSuDi",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Constructing the Model\n",
        "Below we construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VBXBpd99gGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build pre-trained embeddings \n",
        "\n",
        "pretrained_embeddings ="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVXtMhf3SuDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "f2763c65-5d07-4e58-88c7-46dfaa1a4b55"
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b05e3dd38d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEmoGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmoGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYAaRzW6vU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a942469a-ee07-4df0-e906-22519e0b6d9b"
      },
      "source": [
        "model=EmoGRU()\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "# Zero the initial weights of our unknown and padding tokens.\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-76f602c70e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEmoGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'EmoGRU' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6GVV87SuDk",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Pretesting model\n",
        "Since eager execution is enabled we can print the output of the model by passing a sample of the dataset and making sure that the dimensions of the outputs are the expected ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjomHaHbSuDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhymNqRSuDn",
        "colab_type": "code",
        "outputId": "7976ef1d-6662-4742-9042-2d01744228bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(output.size())"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([69, 64])\n",
            "torch.Size([64, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRXfA2NSuDp",
        "colab_type": "text"
      },
      "source": [
        "## 5. Training the Model\n",
        "Now that we have tested the model, it is time to train it. We will define out optimization algorithm, learnin rate, and other necessary information to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFuDTsrUSuDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyvsSQrPSuDr",
        "colab_type": "code",
        "outputId": "5d79748f-827d-4236-a589-8c24554b37ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.2985\n",
            "Epoch 1 Loss 0.2811 -- Train Acc. 31.2031 -- Val Acc. 29.7500\n",
            "Time taken for 1 epoch 2.7862167358398438 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.3062\n",
            "Epoch 2 Loss 0.2614 -- Train Acc. 37.7344 -- Val Acc. 45.9375\n",
            "Time taken for 1 epoch 2.756910800933838 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.2271\n",
            "Epoch 3 Loss 0.1571 -- Train Acc. 67.9062 -- Val Acc. 78.4375\n",
            "Time taken for 1 epoch 2.777299165725708 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.0672\n",
            "Epoch 4 Loss 0.0565 -- Train Acc. 89.3125 -- Val Acc. 84.0625\n",
            "Time taken for 1 epoch 2.773185968399048 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.0282\n",
            "Epoch 5 Loss 0.0233 -- Train Acc. 95.0156 -- Val Acc. 86.6250\n",
            "Time taken for 1 epoch 2.7717573642730713 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.0124\n",
            "Epoch 6 Loss 0.0107 -- Train Acc. 97.8594 -- Val Acc. 84.8125\n",
            "Time taken for 1 epoch 2.783438205718994 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.0042\n",
            "Epoch 7 Loss 0.0091 -- Train Acc. 97.9844 -- Val Acc. 86.3125\n",
            "Time taken for 1 epoch 2.7727713584899902 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.0030\n",
            "Epoch 8 Loss 0.0051 -- Train Acc. 98.9062 -- Val Acc. 86.6875\n",
            "Time taken for 1 epoch 2.7788283824920654 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.0207\n",
            "Epoch 9 Loss 0.0042 -- Train Acc. 99.2812 -- Val Acc. 86.6875\n",
            "Time taken for 1 epoch 2.762084484100342 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.0003\n",
            "Epoch 10 Loss 0.0030 -- Train Acc. 99.4219 -- Val Acc. 85.5625\n",
            "Time taken for 1 epoch 2.779843330383301 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72jYWoxDSuDt",
        "colab_type": "code",
        "outputId": "95994b6c-7426-4a0a-c24e-33959a7817a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(73887, 256)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiF3LKuSuDu",
        "colab_type": "text"
      },
      "source": [
        "## 6. Evaluation on the Testing Data\n",
        "Now we will evaluate the model with the holdout dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IORQgwSuDv",
        "colab_type": "code",
        "outputId": "a47e0466-3750-416e-c8c9-455cbc712b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(\"cuda\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  85.875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTLKA47iSuDz",
        "colab_type": "text"
      },
      "source": [
        "### 6.1 Confusion Matrix\n",
        "The test accuracy alone is not an interesting performance metric in this case. Let's plot a confusion matrix to get a drilled down view of how the model is performing with regards to each emotion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM9g0v7sRTTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Class to Properly Evaluate our Models\n",
        "class Evaluate():\n",
        "\n",
        "    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n",
        "        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n",
        "        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n",
        "        y_va = target.dot(va_matrix)\n",
        "        F_va = prediction.dot(va_matrix)\n",
        "\n",
        "        # dist is a one row vector with size of the test data passed(emotion)\n",
        "        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n",
        "        res = stats.describe(dist)\n",
        "\n",
        "        # print by default (if silent=False)\n",
        "        if not silent:\n",
        "            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n",
        "\n",
        "        return {\n",
        "            'distances': dist,\n",
        "            'dist_stat': res\n",
        "        }\n",
        "\n",
        "    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n",
        "        \"\"\" Compute only the predicted class \"\"\"\n",
        "        p_2_annotation = dict()\n",
        "\n",
        "        precision_recall_fscore_support = [\n",
        "            (pair[0], pair[1].mean()) for pair in zip(\n",
        "                ['precision', 'recall', 'f1', 'support'],\n",
        "                metrics.precision_recall_fscore_support(target, predictions)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        metrics.precision_recall_fscore_support(target, predictions)\n",
        "\n",
        "        # confusion matrix\n",
        "        le = LabelEncoder()\n",
        "        target_le = le.fit_transform(target)\n",
        "        predictions_le = le.transform(predictions)\n",
        "        cm = metrics.confusion_matrix(target_le, predictions_le)\n",
        "\n",
        "        # prediction if two annotations are given on test data\n",
        "        if target2:\n",
        "            p_2_annotation = pd.DataFrame(\n",
        "                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n",
        "                columns=['emo','success']\n",
        "            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n",
        "\n",
        "        if not silent:\n",
        "            print(\"Default Classification report\")\n",
        "            print(metrics.classification_report(target, predictions))\n",
        "\n",
        "            # print if target2 was provided\n",
        "            if len(p_2_annotation) > 0:\n",
        "                print('\\nPrecision on 2 annotations:')\n",
        "                for emo in p_2_annotation:\n",
        "                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n",
        "\n",
        "            # print accuracies, precision, recall, and f1\n",
        "            print('\\nAccuracy:')\n",
        "            print(metrics.accuracy_score(target, predictions))\n",
        "            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n",
        "            for to_print in precision_recall_fscore_support[:3]:\n",
        "                print( \"%s: %.2f\" % to_print )\n",
        "\n",
        "            # normalizing the values of the consfusion matrix\n",
        "            print('\\nconfusion matrix\\n %s' % cm)\n",
        "            print('(row=expected, col=predicted)')\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n",
        "\n",
        "        return {\n",
        "            'precision_recall_fscore_support': precision_recall_fscore_support,\n",
        "            'accuracy': metrics.accuracy_score(target, predictions),\n",
        "            'p_2_annotation': p_2_annotation,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "    def predict_class(cls, X_train, y_train, X_test, y_test,\n",
        "                      pipeline, silent=False, target2=None):\n",
        "        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict(X_test)\n",
        "        print(\"predictions computed....\")\n",
        "        return cls.evaluate_class(predictions, y_test, target2, silent)\n",
        "\n",
        "    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Evaluate through probability \"\"\"\n",
        "        # Run normal class evaluator\n",
        "        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n",
        "        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n",
        "\n",
        "        if not silent:\n",
        "            print('\\n - First Emotion Classification Metrics -')\n",
        "            print('\\n - Multiple Emotion rank Metrics -')\n",
        "            print('VA Cosine Distance')\n",
        "\n",
        "        classes_dist = [\n",
        "            (\n",
        "                emo,\n",
        "                cls.va_dist(\n",
        "                    prediction[np.array(target_class) == emo],\n",
        "                    target_rank[np.array(target_class) == emo],\n",
        "                    va_df,\n",
        "                    binarizer,\n",
        "                    emo,\n",
        "                    silent)\n",
        "                ) for emo in binarizer.classes_\n",
        "        ]\n",
        "        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n",
        "\n",
        "        coverage_error = metrics.coverage_error(target_rank, prediction)\n",
        "        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n",
        "        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n",
        "        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n",
        "\n",
        "        # recall at 2\n",
        "        # obtain top two predictions\n",
        "        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n",
        "        recall_at_2 = pd.DataFrame(\n",
        "            [\n",
        "            t in p for t, p in zip(target_class, top2_pred)\n",
        "            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n",
        "\n",
        "        # combine target into sets\n",
        "        if target2:\n",
        "            union_target = [set(t) for t in zip(target_class, target2)]\n",
        "        else:\n",
        "            union_target = [set(t) for t in zip(target_class)]\n",
        "\n",
        "        # precision at k\n",
        "        top_k_pred = [\n",
        "            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n",
        "            for i in range(2, len(binarizer.classes_)+1)]\n",
        "        precision_at_k = [\n",
        "            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n",
        "            for k in range(len(top_k_pred))]\n",
        "\n",
        "        # do this if silent= False\n",
        "        if not silent:\n",
        "            print('\\n')\n",
        "            print(recall_at_2)\n",
        "            print('\\n')\n",
        "            print('p@k')\n",
        "            for pk in precision_at_k:\n",
        "                print(pk[0] + ':\\t' + str(pk[1]))\n",
        "            print('\\ncoverage_error: %f' % coverage_error)\n",
        "            print('average_precision_score: %f' % average_precision_score)\n",
        "            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n",
        "            print('label_ranking_loss: %f' % label_ranking_loss)\n",
        "\n",
        "        return {\n",
        "            'class_eval': class_eval,\n",
        "            'recall_at_2': recall_at_2.to_dict(),\n",
        "            'precision_at_2': precision_at_k,\n",
        "            'classes_dist': classes_dist,\n",
        "            'avg_dist': avg_dist,\n",
        "            'coverage_error': coverage_error,\n",
        "            'average_precision_score': average_precision_score,\n",
        "            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n",
        "            'label_ranking_loss': label_ranking_loss\n",
        "        }\n",
        "\n",
        "\n",
        "    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Output predcations based on training and labels \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict_proba(X_test)\n",
        "        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n",
        "        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\" Plotting the confusion_matrix\"\"\"\n",
        "        plt.rc('figure', figsize=(4, 4), dpi=100)\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(my_tags))\n",
        "        target_names = my_tags\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "        \n",
        "        # add normalized values inside the Confusion matrix\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUWz-LBSuDz",
        "colab_type": "code",
        "outputId": "fe85630c-9a23-419a-a08d-cf0729ded7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "evaluator = Evaluate()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p.cpu().detach().numpy())\n",
        "        \n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
        "\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n",
        "\n",
        "model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n",
        "test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.emotion, test.emotion );"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.85      0.82      0.83       228\n",
            "        fear       0.88      0.79      0.83       165\n",
            "         joy       0.89      0.89      0.89       555\n",
            "        love       0.68      0.78      0.73       139\n",
            "     sadness       0.90      0.90      0.90       461\n",
            "    surprise       0.70      0.77      0.73        52\n",
            "\n",
            "    accuracy                           0.86      1600\n",
            "   macro avg       0.82      0.82      0.82      1600\n",
            "weighted avg       0.86      0.86      0.86      1600\n",
            "\n",
            "\n",
            "Accuracy:\n",
            "0.85875\n",
            "Correct Predictions:  1374\n",
            "precision: 0.82\n",
            "recall: 0.82\n",
            "f1: 0.82\n",
            "\n",
            "confusion matrix\n",
            " [[187   7  15   1  18   0]\n",
            " [  8 131   3   2  10  11]\n",
            " [  8   3 492  40   8   4]\n",
            " [  3   0  18 108   9   1]\n",
            " [ 14   3  20   7 416   1]\n",
            " [  0   5   5   0   2  40]]\n",
            "(row=expected, col=predicted)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAGFCAYAAADJmEVqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSWw72w6VOY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTCznkUGSuD3",
        "colab_type": "text"
      },
      "source": [
        "## Final Words\n",
        "You have learned how to perform neural-based emotion recognition using RNNs. There are many things you can do after you have completed this tutorial. You can attempt the exercises outlined in the \"Outline\" section of this notebook. You can also try other types of neural architectures such as LSTMs, Bi-LSTMS, attentions models, and CNNs. In addition, you can also store the models and conduct transfer learning to other emotion-related tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbkPHgFSuD3",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLfZrr2oSuD4",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "- [Deep Learning for NLP](https://docs.google.com/presentation/d/1cf2H1qMvP1rdKUF5000ifOIRv1_b0bvj0ZTVL7-RaVE/edit?usp=sharing)\n",
        "- [PyTorch Autograd Tutorial](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
        "- [A Simple Neural Network from Scratch with PyTorch and Google Colab](https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0)\n",
        "- [Building RNNs is Fun with PyTorch and Google Colab](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79?source=collection_home---4------2---------------------)\n",
        "- [Deep Learning for NLP: An Overview of Recent Trends](https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d)"
      ]
    }
  ]
}