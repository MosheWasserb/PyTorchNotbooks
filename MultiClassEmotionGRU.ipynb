{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiClassEmotionGRU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4jBsi0l18qEMzwHL0pNjp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/MultiClassEmotionGRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWIqjq4Q12x3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMxJsfoF8JOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pandas as pd\n",
        "\n",
        "#cars = {'Brand': ['Honda Civic','Toyota Corolla','Ford Focus','Audi A4'],\n",
        "        'Price': [22000,25000,27000,35000]\n",
        "        }\n",
        "\n",
        "#df = pd.DataFrame(cars, columns= ['Brand', 'Price'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dd1ewo7ILEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR9Dv9_QIh2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "eba7e555-142f-4b50-862b-7ce8dfb51bca"
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6b1UOLTI8Rg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "2f07e069-4c9b-427f-c6d0-563625f35579"
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4da76134a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqEpIREREVUIiIiKqEhIREVH1/wGfA/dLdXaziQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLYrIu6nJS6Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a67a8e83-7278-499f-c012-035d2965611f"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ive probably mentioned this before but i reall...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i was feeling a little low few days back</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i beleive that i am much more sensitive to oth...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text emotions\n",
              "0  i feel awful about it too because it s my job ...  sadness\n",
              "1                              im alone i feel awful  sadness\n",
              "2  ive probably mentioned this before but i reall...      joy\n",
              "3           i was feeling a little low few days back  sadness\n",
              "4  i beleive that i am much more sensitive to oth...     love"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nI00TmkSuCY",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Preprocessing Data\n",
        "In the next steps we are going to create tokenize the text, create index mapping for words, and also construct a vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCHxi2ASuCZ",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDgIXGGSuCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=5000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNrOA7mSuCe",
        "colab_type": "text"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KouYEDoNSuCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFasv0ASuCi",
        "colab_type": "code",
        "outputId": "d17e245c-710a-49e8-cc9d-7a2138f8a45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aac',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abated',\n",
              " 'abc',\n",
              " 'abdicate',\n",
              " 'abdul',\n",
              " 'abg',\n",
              " 'abide']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqf0tC3FSuCk",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Converting Data into Tensors \n",
        "For convenience we would like to convert the data into tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULJbpmKRQM8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gNS0pQ_QYeu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "480a3eb4-bad9-42bc-b972-ea15d3114ffe"
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]\n",
        "type(input_tensor)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQkDHZVyTsY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ad4fc4c-7919-47ee-8529-cf608d92c873"
      },
      "source": [
        "print(input_tensor[0:3])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3529, 2652, 4263, 7365], [3529, 7895, 2500, 4754, 3307, 7362, 5731, 269, 2655, 209, 3525, 269, 6375], [3529, 4992, 2652, 4186, 3566, 5110, 3424]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoIfZHjSuCr",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Padding data\n",
        "In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbSHvs0SuCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zyXKoy6SuCw",
        "colab_type": "code",
        "outputId": "6dad8fad-71d7-40af-fd7c-e17939bd5480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk71VEPSuC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wKDdBCSuC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dok2XcWSuC7",
        "colab_type": "code",
        "outputId": "5dfb31c1-dfaf-4a4e-c859-79ee6d4ccb0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([3529, 2652, 4263, 7365,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
              " array([3529, 7895, 2500, 4754, 3307, 7362, 5731,  269, 2655,  209, 3525,\n",
              "         269, 6375,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZqu4luJiZAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eaf89ccb-a041-4038-e699-21c88769080d"
      },
      "source": [
        "data.head(5)\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>162476</th>\n",
              "      <td>i feel lonely today</td>\n",
              "      <td>sadness</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333695</th>\n",
              "      <td>i was expecting my heart to race and feeling a...</td>\n",
              "      <td>fear</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222437</th>\n",
              "      <td>i often feel like im overwhelmingly homesick</td>\n",
              "      <td>sadness</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42442</th>\n",
              "      <td>when i had not understood anything after a lec...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182289</th>\n",
              "      <td>i used to feel helpless feel frustrated feel d...</td>\n",
              "      <td>fear</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions  token_size\n",
              "162476                                i feel lonely today  sadness           4\n",
              "333695  i was expecting my heart to race and feeling a...     fear          13\n",
              "222437       i often feel like im overwhelmingly homesick  sadness           7\n",
              "42442   when i had not understood anything after a lec...  sadness           9\n",
              "182289  i used to feel helpless feel frustrated feel d...     fear          10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBN6xAsGSuDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_369xrpSuDC",
        "colab_type": "code",
        "outputId": "52af89bd-0917-4ec0-f9f2-41a875bac4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "target_tensor[0:2] "
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZMnNbUSuDF",
        "colab_type": "code",
        "outputId": "88e3cadb-ab85-42f7-9d82-966c5b8e9133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>162476</th>\n",
              "      <td>i feel lonely today</td>\n",
              "      <td>sadness</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333695</th>\n",
              "      <td>i was expecting my heart to race and feeling a...</td>\n",
              "      <td>fear</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions  token_size\n",
              "162476                                i feel lonely today  sadness           4\n",
              "333695  i was expecting my heart to race and feeling a...     fear          13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCgbz5icSuDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bI6rF59SuDK",
        "colab_type": "code",
        "outputId": "0b569d60-1fd1-45c1-bfe7-7762643456d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxi-STseSuDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRkO7WISuDN",
        "colab_type": "code",
        "outputId": "f1e5304b-02d4-4f95-d213-b7967e9a6885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sadness'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWDE42iSuDQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Split data\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQuGQReSuDR",
        "colab_type": "code",
        "outputId": "5ce14f19-ae36-413b-e583-ac9beaadc1f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 4000, 500, 500, 500, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ0GXI9SuDX",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 Data Loader\n",
        "We can also laod the data into a data loader, which makes it easy to **manipulate the data**, **create batches**, and apply further **transformations**. In PyTorch we can use the `DataLoader` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xtwf8nSuDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDa8eJVSuDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0Of7YiSuDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgVVs1XSuDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQNqg9xSuDe",
        "colab_type": "code",
        "outputId": "c818546e-144a-4f5a-ab34-82c107a65f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_dataset.batch_size\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqYHyFGwSuDh",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model\n",
        "After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details. \n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/gru-model.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHYthQdSuDi",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Constructing the Model\n",
        "Below we construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVXtMhf3SuDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "b7bde623-336e-4c5b-9c30-abd3e70d0724"
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-b05e3dd38d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEmoGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmoGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6GVV87SuDk",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Pretesting model\n",
        "Since eager execution is enabled we can print the output of the model by passing a sample of the dataset and making sure that the dimensions of the outputs are the expected ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjomHaHbSuDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhymNqRSuDn",
        "colab_type": "code",
        "outputId": "c2c13e64-6085-4a08-af3f-eef4fbd7667d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([68, 64])\n",
            "torch.Size([64, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}