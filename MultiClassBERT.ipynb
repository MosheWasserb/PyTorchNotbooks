{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiClassBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "B9bhSJpcv1Bl"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff5b29b0733e40ae8d23cce9ce4003c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48ead982f18a4eed843c44342204790c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_248423a2601f4880a6bffda40aea4e52",
              "IPY_MODEL_719a88ea41234522bbcfb7bfb0eaf16b"
            ]
          }
        },
        "48ead982f18a4eed843c44342204790c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "248423a2601f4880a6bffda40aea4e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8c633c1ee0c4595af1bcfbca3904214",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ee12e31d1434162ac4e6a3758f4bb34"
          }
        },
        "719a88ea41234522bbcfb7bfb0eaf16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38bee730feb0407b96b4a89bd2315637",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.42MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d6be8dfa06845bc80d6b593251ad962"
          }
        },
        "f8c633c1ee0c4595af1bcfbca3904214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ee12e31d1434162ac4e6a3758f4bb34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38bee730feb0407b96b4a89bd2315637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d6be8dfa06845bc80d6b593251ad962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0139d43b9c7c4b5b9f69e5964e97ab0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0ad76070085b48e7b6122299f11046c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_935c9abafa7e44228ada7b72ece67786",
              "IPY_MODEL_f3f9ecc710ea457b82484ec3cc773318"
            ]
          }
        },
        "0ad76070085b48e7b6122299f11046c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "935c9abafa7e44228ada7b72ece67786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_50d6067328554e31a530bae8d3ef29b7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 546,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 546,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9393c26f5a9c4ba98021d5e3e70fb6c2"
          }
        },
        "f3f9ecc710ea457b82484ec3cc773318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a58980e728c14e0199b74d1d0ff2be59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 546/546 [00:04&lt;00:00, 133B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14482ac48fc543789b1c18bb688d92ab"
          }
        },
        "50d6067328554e31a530bae8d3ef29b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9393c26f5a9c4ba98021d5e3e70fb6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a58980e728c14e0199b74d1d0ff2be59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14482ac48fc543789b1c18bb688d92ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad8e8218675644dcba9fd996d52cf409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6245b3dab75d4436ae03edb19f85ec53",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5973195e2f6c414d9d1f8a78cd3b2e07",
              "IPY_MODEL_ace120feb3eb438b8d3a4e466804a966"
            ]
          }
        },
        "6245b3dab75d4436ae03edb19f85ec53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5973195e2f6c414d9d1f8a78cd3b2e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60f7220508c84a6b8d18fbfa2eb8362f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a72a5ded28c436d86f2e3469a8b4e35"
          }
        },
        "ace120feb3eb438b8d3a4e466804a966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5cfc0601de7147fd8599144add31dea2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:03&lt;00:00, 71.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bad1a3e28054968a45702f603aae455"
          }
        },
        "60f7220508c84a6b8d18fbfa2eb8362f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a72a5ded28c436d86f2e3469a8b4e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cfc0601de7147fd8599144add31dea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bad1a3e28054968a45702f603aae455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/PyTorchNotbooks/blob/master/MultiClassBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izA3-6kffbdT",
        "colab_type": "text"
      },
      "source": [
        "# A Visual Notebook to Using BERT for the First TIme.ipynb\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-sentence-classification.png\" />\n",
        "\n",
        "In this notebook, we will use pre-trained deep learning model to process some text. We will then use the output of that model to classify the text. The text is a list of sentences from film reviews. And we will calssify each sentence as either speaking \"positively\" about its subject of \"negatively\".\n",
        "\n",
        "## Models: Sentence Sentiment Classification\n",
        "Our goal is to create a model that takes a sentence (just like the ones in our dataset) and produces either 1 (indicating the sentence carries a positive sentiment) or a 0 (indicating the sentence carries a negative sentiment). We can think of it as looking like this:\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/sentiment-classifier-1.png\" />\n",
        "\n",
        "Under the hood, the model is actually made up of two model.\n",
        "\n",
        "* DistilBERT processes the sentence and passes along some information it extracted from it on to the next model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its performance.\n",
        "* The next model, a basic Logistic Regression model from scikit learn will take in the result of DistilBERT’s processing, and classify the sentence as either positive or negative (1 or 0, respectively).\n",
        "\n",
        "The data we pass between the two models is a vector of size 768. We can think of this of vector as an embedding for the sentence that we can use for classification.\n",
        "\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/distilbert-bert-sentiment-classifier.png\" />\n",
        "\n",
        "## Dataset\n",
        "The dataset we will use in this example is [SST2](https://nlp.stanford.edu/sentiment/index.html), which contains sentences from movie reviews, each labeled as either positive (has the value 1) or negative (has the value 0):\n",
        "\n",
        "\n",
        "<table class=\"features-table\">\n",
        "  <tr>\n",
        "    <th class=\"mdc-text-light-green-600\">\n",
        "    sentence\n",
        "    </th>\n",
        "    <th class=\"mdc-text-purple-600\">\n",
        "    label\n",
        "    </th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      apparently reassembled from the cutting room floor of any given daytime soap\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      0\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      they presume their audience won't sit still for a sociology lesson\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      0\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      this is a visually stunning rumination on love , memory , history and the war between art and commerce\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      jonathan parker 's bartleby should have been the be all end all of the modern office anomie films\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "## Installing the transformers library\n",
        "Let's start by installing the huggingface transformers library so we can load our deep learning NLP model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9ENLU90WGl",
        "colab_type": "code",
        "outputId": "b098304c-9895-4fa1-b4fe-b85ecc467207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.33)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.33 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=93df36aba6b852732a8832841279f381189ef65a8dbc048fb2fe37a93e0e096f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import clear_output\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ-42fh0hjsF",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset\n",
        "We'll use pandas to read the dataset and load it into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyoj29J24hPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cc7f1dbf-358a-4d01-d1b1-8f811608e378"
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1yaW1WK-VQ5",
        "colab_type": "code",
        "outputId": "e7901f2b-77ec-4fbe-ed07-4707ffa022d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv(r\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/multiclass6ed.csv\")\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f17ee63f7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAbzUlEQVR4nO3de7hddX3n8ffHxCBouckpg0k0UVMc\nxBukkBlsS0EgCBqqYKEqUVPyjIJaxxkJVictwjxY+8iUjjJyiYDjcCleyEgwpihjvQQIF8GAmCMX\nSQYkJQiOFBD6mT/W78jOyfklnLN39jo5+byeZz9nr+/67b2/G3LOZ6+1fmtt2SYiImIkz2u7gYiI\nGL8SEhERUZWQiIiIqoRERERUJSQiIqIqIREREVWT226g1/bYYw/PmDGj7TYiIrYpN9100z/bHhhe\nn3AhMWPGDFatWtV2GxER2xRJ941Uz+6miIioSkhERERVQiIiIqoSEhERUZWQiIiIqoRERERUbTEk\nJC2R9JCkH4+w7qOSLGmPsixJ50galHSbpP06xs6XtKbc5nfU95d0e3nMOZJU6rtLWlHGr5C0W2/e\nckREPFfPZUviImDu8KKk6cDhwM87ykcCs8ptIXBuGbs7sBg4EDgAWNzxR/9c4KSOxw291iLgWtuz\ngGvLckRE9NEWT6az/V1JM0ZYdTbwMeCqjto84BI332S0UtKukvYCDgZW2N4AIGkFMFfSdcDOtleW\n+iXAMcA15bkOLs97MXAdcOqo3t0ozFh09dZ66hHde9ZRfX29iIixGNMxCUnzgHW2fzRs1VTg/o7l\ntaW2ufraEeoAe9p+oNx/ENhzLL1GRMTYjfqyHJJ2Aj5Os6upL2xbUvV7ViUtpNm9xUtf+tJ+tRUR\nMeGNZUviFcBM4EeS7gWmATdL+jfAOmB6x9hppba5+rQR6gC/KLuqKD8fqjVk+zzbs23PHhjY5PpU\nERExRqMOCdu32/5d2zNsz6DZRbSf7QeBpcCJZZbTHODRsstoOXC4pN3KAevDgeVl3WOS5pRZTSfy\n7DGOpcDQLKj5bHzsIyIi+uC5TIG9FPghsLektZIWbGb4MuBuYBA4H/gAQDlg/SngxnI7feggdhlz\nQXnMz2gOWgOcBRwmaQ3wprIcERF99FxmN52whfUzOu4bOLkybgmwZIT6KmDfEeoPA4duqb+IiNh6\ncsZ1RERUJSQiIqIqIREREVUJiYiIqEpIREREVUIiIiKqEhIREVGVkIiIiKqEREREVCUkIiKiKiER\nERFVCYmIiKhKSERERFVCIiIiqhISERFRlZCIiIiqhERERFQlJCIioiohERERVQmJiIio2mJISFoi\n6SFJP+6ofUbSTyTdJulrknbtWHeapEFJd0k6oqM+t9QGJS3qqM+UdH2pXy5pSqnvUJYHy/oZvXrT\nERHx3DyXLYmLgLnDaiuAfW2/FvgpcBqApH2A44FXl8d8XtIkSZOAzwFHAvsAJ5SxAJ8Gzrb9SuAR\nYEGpLwAeKfWzy7iIiOijyVsaYPu7wz/F2/5Wx+JK4Nhyfx5wme0ngXskDQIHlHWDtu8GkHQZME/S\nncAhwJ+VMRcDfwWcW57rr0r9SuC/S5Jtj+L9RTFj0dV9fb17zzqqr68XEVtHL45JvA+4ptyfCtzf\nsW5tqdXqLwZ+afvpYfWNnqusf7SMj4iIPukqJCT9JfA08OXetDPmPhZKWiVp1fr169tsJSJiQhlz\nSEh6D3A08M6OXUDrgOkdw6aVWq3+MLCrpMnD6hs9V1m/Sxm/Cdvn2Z5te/bAwMBY31JERAwzppCQ\nNBf4GPBW2493rFoKHF9mJs0EZgE3ADcCs8pMpik0B7eXlnD5Ds8e05gPXNXxXPPL/WOBb+d4RERE\nf23xwLWkS4GDgT0krQUW08xm2gFYIQlgpe3/YHu1pCuAO2h2Q51s+5nyPKcAy4FJwBLbq8tLnApc\nJukM4BbgwlK/EPhSOfi9gSZYIiKij57L7KYTRihfOEJtaPyZwJkj1JcBy0ao382zM6A6608Ax22p\nv4iI2HpyxnVERFQlJCIioiohERERVQmJiIioSkhERERVQiIiIqoSEhERUZWQiIiIqoRERERUJSQi\nIqIqIREREVUJiYiIqEpIREREVUIiIiKqEhIREVGVkIiIiKqEREREVCUkIiKiKiERERFVCYmIiKhK\nSERERNUWQ0LSEkkPSfpxR213SSskrSk/dyt1STpH0qCk2yTt1/GY+WX8GknzO+r7S7q9POYcSdrc\na0RERP88ly2Ji4C5w2qLgGttzwKuLcsARwKzym0hcC40f/CBxcCBwAHA4o4/+ucCJ3U8bu4WXiMi\nIvpkiyFh+7vAhmHlecDF5f7FwDEd9UvcWAnsKmkv4Ahghe0Nth8BVgBzy7qdba+0beCSYc810mtE\nRESfjPWYxJ62Hyj3HwT2LPenAvd3jFtbapurrx2hvrnX2ISkhZJWSVq1fv36MbydiIgYSdcHrssW\ngHvQy5hfw/Z5tmfbnj0wMLA1W4mI2K6MNSR+UXYVUX4+VOrrgOkd46aV2ubq00aob+41IiKiT8Ya\nEkuBoRlK84GrOuonlllOc4BHyy6j5cDhknYrB6wPB5aXdY9JmlNmNZ047LlGeo2IiOiTyVsaIOlS\n4GBgD0lraWYpnQVcIWkBcB/wjjJ8GfBmYBB4HHgvgO0Nkj4F3FjGnW576GD4B2hmUO0IXFNubOY1\nIiKiT7YYErZPqKw6dISxBk6uPM8SYMkI9VXAviPUHx7pNSIion9yxnVERFQlJCIioiohERERVQmJ\niIioSkhERERVQiIiIqoSEhERUZWQiIiIqoRERERUJSQiIqIqIREREVUJiYiIqEpIREREVUIiIiKq\nEhIREVGVkIiIiKqEREREVCUkIiKiKiERERFVCYmIiKjqKiQkfUTSakk/lnSppBdIminpekmDki6X\nNKWM3aEsD5b1Mzqe57RSv0vSER31uaU2KGlRN71GRMTojTkkJE0FPgTMtr0vMAk4Hvg0cLbtVwKP\nAAvKQxYAj5T62WUckvYpj3s1MBf4vKRJkiYBnwOOBPYBTihjIyKiT7rd3TQZ2FHSZGAn4AHgEODK\nsv5i4Jhyf15Zpqw/VJJK/TLbT9q+BxgEDii3Qdt3234KuKyMjYiIPhlzSNheB/wt8HOacHgUuAn4\npe2ny7C1wNRyfypwf3ns02X8izvrwx5Tq0dERJ90s7tpN5pP9jOBlwAvpNld1HeSFkpaJWnV+vXr\n22ghImJC6mZ305uAe2yvt/0b4KvAQcCuZfcTwDRgXbm/DpgOUNbvAjzcWR/2mFp9E7bPsz3b9uyB\ngYEu3lJERHTqJiR+DsyRtFM5tnAocAfwHeDYMmY+cFW5v7QsU9Z/27ZL/fgy+2kmMAu4AbgRmFVm\nS02hObi9tIt+IyJilCZvecjIbF8v6UrgZuBp4BbgPOBq4DJJZ5TaheUhFwJfkjQIbKD5o4/t1ZKu\noAmYp4GTbT8DIOkUYDnNzKkltlePtd+IiBi9MYcEgO3FwOJh5btpZiYNH/sEcFzlec4EzhyhvgxY\n1k2PERExdjnjOiIiqhISERFRlZCIiIiqhERERFQlJCIioiohERERVQmJiIioSkhERERVQiIiIqoS\nEhERUZWQiIiIqoRERERUJSQiIqIqIREREVUJiYiIqEpIREREVUIiIiKqEhIREVGVkIiIiKqERERE\nVCUkIiKiqquQkLSrpCsl/UTSnZL+naTdJa2QtKb83K2MlaRzJA1Kuk3Sfh3PM7+MXyNpfkd9f0m3\nl8ecI0nd9BsREaPT7ZbE3wHftP0q4HXAncAi4Frbs4BryzLAkcCsclsInAsgaXdgMXAgcACweChY\nypiTOh43t8t+IyJiFMYcEpJ2Af4QuBDA9lO2fwnMAy4uwy4Gjin35wGXuLES2FXSXsARwArbG2w/\nAqwA5pZ1O9teadvAJR3PFRERfdDNlsRMYD3wRUm3SLpA0guBPW0/UMY8COxZ7k8F7u94/NpS21x9\n7Qj1TUhaKGmVpFXr16/v4i1FRESnbkJiMrAfcK7tNwC/5tldSwCULQB38RrPie3zbM+2PXtgYGBr\nv1xExHajm5BYC6y1fX1ZvpImNH5RdhVRfj5U1q8Dpnc8flqpba4+bYR6RET0yZhDwvaDwP2S9i6l\nQ4E7gKXA0Ayl+cBV5f5S4MQyy2kO8GjZLbUcOFzSbuWA9eHA8rLuMUlzyqymEzueKyIi+mByl4//\nIPBlSVOAu4H30gTPFZIWAPcB7yhjlwFvBgaBx8tYbG+Q9CngxjLudNsbyv0PABcBOwLXlFvEJmYs\nurpvr3XvWUf17bUi2tZVSNi+FZg9wqpDRxhr4OTK8ywBloxQXwXs202PERExdjnjOiIiqhISERFR\nlZCIiIiqhERERFQlJCIioiohERERVQmJiIioSkhERERVQiIiIqoSEhERUZWQiIiIqoRERERUdXsV\n2IjYyvp5hVvIVW5jY9mSiIiIqoRERERUJSQiIqIqIREREVUJiYiIqEpIREREVUIiIiKqug4JSZMk\n3SLpG2V5pqTrJQ1KulzSlFLfoSwPlvUzOp7jtFK/S9IRHfW5pTYoaVG3vUZExOj0Ykviw8CdHcuf\nBs62/UrgEWBBqS8AHin1s8s4JO0DHA+8GpgLfL4EzyTgc8CRwD7ACWVsRET0SVchIWkacBRwQVkW\ncAhwZRlyMXBMuT+vLFPWH1rGzwMus/2k7XuAQeCAchu0fbftp4DLytiIiOiTbrck/hvwMeBfy/KL\ngV/afrosrwWmlvtTgfsByvpHy/jf1oc9plbfhKSFklZJWrV+/fou31JERAwZc0hIOhp4yPZNPexn\nTGyfZ3u27dkDAwNttxMRMWF0c4G/g4C3Snoz8AJgZ+DvgF0lTS5bC9OAdWX8OmA6sFbSZGAX4OGO\n+pDOx9TqERHRB2PekrB9mu1ptmfQHHj+tu13At8Bji3D5gNXlftLyzJl/bdtu9SPL7OfZgKzgBuA\nG4FZZbbUlPIaS8fab0REjN7WuFT4qcBlks4AbgEuLPULgS9JGgQ20PzRx/ZqSVcAdwBPAyfbfgZA\n0inAcmASsMT26q3Qb0REVPQkJGxfB1xX7t9NMzNp+JgngOMqjz8TOHOE+jJgWS96jIiI0csZ1xER\nUZWQiIiIqnx9aUS0Kl/POr5lSyIiIqoSEhERUZWQiIiIqoRERERUJSQiIqIqIREREVUJiYiIqEpI\nREREVUIiIiKqEhIREVGVkIiIiKqEREREVCUkIiKiKiERERFVCYmIiKhKSERERFVCIiIiqsYcEpKm\nS/qOpDskrZb04VLfXdIKSWvKz91KXZLOkTQo6TZJ+3U81/wyfo2k+R31/SXdXh5zjiR182YjImJ0\nutmSeBr4qO19gDnAyZL2ARYB19qeBVxblgGOBGaV20LgXGhCBVgMHAgcACweCpYy5qSOx83tot+I\niBilMYeE7Qds31zu/wq4E5gKzAMuLsMuBo4p9+cBl7ixEthV0l7AEcAK2xtsPwKsAOaWdTvbXmnb\nwCUdzxUREX3Qk2MSkmYAbwCuB/a0/UBZ9SCwZ7k/Fbi/42FrS21z9bUj1CMiok+6DglJLwK+AvyF\n7cc615UtAHf7Gs+hh4WSVklatX79+q39chER242uQkLS82kC4su2v1rKvyi7iig/Hyr1dcD0jodP\nK7XN1aeNUN+E7fNsz7Y9e2BgoJu3FBERHbqZ3STgQuBO25/tWLUUGJqhNB+4qqN+YpnlNAd4tOyW\nWg4cLmm3csD6cGB5WfeYpDnltU7seK6IiOiDyV089iDg3cDtkm4ttY8DZwFXSFoA3Ae8o6xbBrwZ\nGAQeB94LYHuDpE8BN5Zxp9veUO5/ALgI2BG4ptwiIqJPxhwStr8H1M5bOHSE8QZOrjzXEmDJCPVV\nwL5j7TEiIrqTM64jIqIqIREREVXdHJOIiIgtmLHo6r6+3r1nHdXT58uWREREVCUkIiKiKiERERFV\nCYmIiKhKSERERFVCIiIiqhISERFRlZCIiIiqhERERFQlJCIioiohERERVQmJiIioSkhERERVQiIi\nIqoSEhERUZWQiIiIqoRERERUJSQiIqJq3IeEpLmS7pI0KGlR2/1ERGxPxnVISJoEfA44EtgHOEHS\nPu12FRGx/RjXIQEcAAzavtv2U8BlwLyWe4qI2G7Idts9VEk6Fphr+8/L8ruBA22fMmzcQmBhWdwb\nuKuPbe4B/HMfX6/fJvL7m8jvDfL+tnX9fn8vsz0wvDi5jw1sNbbPA85r47UlrbI9u43X7oeJ/P4m\n8nuDvL9t3Xh5f+N9d9M6YHrH8rRSi4iIPhjvIXEjMEvSTElTgOOBpS33FBGx3RjXu5tsPy3pFGA5\nMAlYYnt1y20N18purj6ayO9vIr83yPvb1o2L9zeuD1xHRES7xvvupoiIaFFCIiIiqhISoyTpLZLy\n3y0itgv5Yzd6fwqskfQ3kl7VdjNbk6TdJL227T56RY3pWx4ZEUMSEqNk+13AG4CfARdJ+qGkhZJ+\np+XWekLSdZJ2lrQ7cDNwvqTPtt1XL7iZpbGs7T62FkmTJP2k7T62Nkkvk/Smcn/HCfS7t6ekCyVd\nU5b3kbSg7b4SEmNg+zHgSpprSe0F/Alws6QPttpYb+xS3t/bgEtsHwi8qeWeeulmSb/fdhNbg+1n\ngLskvbTtXrYWSSfR/O59oZSmAV9vr6Oeuohmuv9LyvJPgb9orZsiITFKkt4q6WvAdcDzgQNsHwm8\nDvhom731yGRJewHvAL7RdjNbwYHADyX9TNJtkm6XdFvbTfXQbsBqSddKWjp0a7upHjoZOAh4DMD2\nGuB3W+2od/awfQXwr9CcJwY8025L4/xkunHq7cDZtr/bWbT9+HjYNOyB02k+zXzP9o2SXg6sabmn\nXjqi7Qa2sk+23cBW9qTtpyQBIGkyMFFO9vq1pBdT3o+kOcCj7baUk+nGRNKewNAuixtsP9RmPzE6\nkt4IzLL9RUkDwIts39N2X7Flkv4G+CVwIvBB4APAHbb/stXGekDSfsDfA/sCPwYGgGNtt7qlm5AY\nJUnHAX9Ls7tJwB8A/9n2lW321Svll/AM4F+AbwKvBT5i+3+22liPSFoMzAb2tv17kl4C/IPtg1pu\nrSfKp8+/B/4tMIXmcja/tr1zq431SJl+vgA4nOb3bzlwgSfIH7KyZbQ3zXu7y/ZvWm4pITFakn4E\nHDa09VA+if6j7de121lvSLrV9usl/QlwNPAfge9OpPdHMzvtZttvKLXbbE+Iqb6SVtFcCPMfaMLw\nROD3bJ/WamM9IultwNW2n2y7l14rH0C/aftXkj4B7AecYfvmNvvKgevRe96w3UsPM7H+Ow4dpzqK\n5hN26/tEe+yp8qlzaL/vC1vup+dsDwKTbD9j+4vA3LZ76qG3AD+V9CVJR5dP3hPFJ0tAvBE4FLgQ\nOLflnibUH7d++aak5ZLeI+k9NPPur2m5p176Rplrvz9wbdlSeqLlnnrpCklfAHYt0yn/ETi/5Z56\n6fFyWf1bywmfH2EC/Z7bfi/wSpotpROAn0m6oN2uemZoJtNRwPm2r6bZZdiq7G4ag7LJO7QP+59s\nT5R52gCUE+ketf1M+aT9O7YfbLuvXpF0GB37tG2vaLmlnpH0MuAXNH9cPgLsAny+bF1MGJKeT7OF\n9F7gD23v0XJLXZP0DZovVTuMZlfTv9BMjGl1V29C4jmS9D3bb5T0K5pdFepY/a/ABuAztj/fSoM9\nImknmuMQL7W9UNIsmoO8E/GciQlJ0o40///6+V3vfSHpSJpL4xxMM3nkCuBb5ZyCbVr53ZsL3G57\nTTlf6TW2v9VqXwmJ3ijzm39ge++2e+mGpMuBm4ATbe9b/uH+wPbrW26tJzpCvtOjwCrgo7bv7n9X\nvSPpLTSz76bYninp9cDptt/acms9IelS4HLgmoly8FrSzrYfK1vwm7C9od89dUpI9JCkvWw/0HYf\n3Rj68nVJt3TM/vlR25u8vSLpU8Ba4H/RbA0eD7yC5jpV77d9cHvddU/STcAhwHUd//9ut/2adjvr\nnYl2npKkb9g+WtI9bLqXwrZf3lJrwAQ6oDUebOsBUTxVdlcMzf55BTAhPrEVb7X9Bdu/sv2Y7fOA\nI2xfTnNJi23db0aYkTZhPgmWaaI3AMfRXDrmeknHtttVd0pACPgj2y+3PbPj1mpAQC7LEZtaTHMS\n3XRJX6Y5QP+eVjvqrcclvYPmInEAx/Ls7K2J8Md0taQ/AyaV40kfAn7Qck+99Ang94efp8Sz/z+3\nSbYt6Wpg3G3xZUsiNlJm+ryNJhguBWbbvq7NnnrsncC7gYdoZgG9G3hX2Xo6pc3GuiHpS+Xuz4BX\n02z9XUpzIbzWryTaQxP5PKVxeYXiHJOITUiaCryMji3N4Rc0jPFF0h00l3S/Bvjj4evbPvjZK5I+\nQ3OpmEtL6U+B22yf2l5XvVHOT3olcB/wa5pjE277agAJidiIpE/T/OKtplyymOYf6kSZHTMAnATM\nYOMQfF9bPfWCpA8B7wdeTjPX/rerGAcHP3tJ0tvZ+Dylr7XZT6+Uc1w2Yfu+fvfSKSERG5F0F/Da\niTK9cDhJPwD+iWaa72+v1W/7K6011UOSzrX9/rb7iLEpV4J9I83xse+3fd0mSEjEMOWrE4+z/f/a\n7mVrGLqAYdt9xOhUzm+BZ7eUtvmr3Er6LzSztr5aSsfQXD/tjPa6SkjEMJK+QvMte9fSMfXV9oda\na6qHJJ1Bc3LghP2u69g2la3419l+oizvCNza9gm6mQIbwy0tt4nqw8DHJT0J/IYJ9Ek0tnn/F3gB\nz07J3oGNjy+1IlsSsd0plz+YRfMLCYDt/9NeRxEg6es0Z5KvoNm1dhjNiYNrob2t+YREAM2lG9jM\nyWRtT8PrFUl/TrM1MQ24FZhDs/vp0FYbi+2epPmbW2/74n710im7m2LI0eXnyeXn0MlZ72JinIk8\n5MM0n9ZW2v5jSa8C/mvLPcV2TtIk4HDb72y7l+ESEgE8Oxdb0mFDF4YrTpV0M7Conc567gnbT0hC\n0g62fyJpm75yb2z7yne3vEzSFNtPtd1Pp4REDCdJB9n+fln490ycyx4ArJW0K/B1YIWkR2jOcI1o\n293A9yUtpTnjGgDbn22vpRyTiGEk7Q8soflGMwGPAO8bDyf19JqkP6J5n98cb5/eYvsjafFIddt/\n3e9eOiUkYkSSdgEY4bLTEbEdSUjEJiQdRXMl0c4poqe311HExCfpO4wwScT2IS2081s5JhEbkfQ/\ngJ1oriR6Ac33LdzQalMR24f/1HH/BcDbgda/uztbErERSbfZfm3HzxfRfJ/wH7TdW8T2RtINtg9o\ns4dsScRwQ5cEeFzSS4ANwF4t9hOxXShXAhjyPGA2zcSKViUkYrj/XaaIfga4mWYf6fntthSxXbiJ\n5vdNNNcVuxdY0GZDMLHmv0dv/AR4pny/wueAlTTnFETE1nUq8HrbM2muePBr4PF2W0pIxKY+aftX\nkt4IHEJz8PrclnuK2B58wvZj4+13LyERww19W9tRwPm2rwamtNhPxPZiXP7uJSRiuHWSvkDzPdfL\nJO1A/p1E9MO4/N3LFNjYiKSdgLnA7bbXSNoLeI3tb7XcWsSENl5/9xISERFR1fqmTEREjF8JiYiI\nqEpIREREVUIiIiKqEhIREVH1/wGfA/dLdXaziQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMVE3waNhuNj",
        "colab_type": "text"
      },
      "source": [
        "For performance reasons, we'll only use 2,000 sentences from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTM3hOHW4hUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1 = data.sample(n=8000, random_state=42);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRc2L89hh1Tf",
        "colab_type": "text"
      },
      "source": [
        "We can ask pandas how many sentences are labeled as \"positive\" (value 1) and how many are labeled \"negative\" (having the value 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgl8w2cS_aVq",
        "colab_type": "code",
        "outputId": "1bedee9a-654e-4e64-aea5-2c72cc8b3937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "batch_1.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36130</th>\n",
              "      <td>i just feel really helpless and heavy hearted</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138065</th>\n",
              "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146440</th>\n",
              "      <td>i gave up my internship with the dmrg and am f...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103337</th>\n",
              "      <td>i dont know i feel so lost</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315528</th>\n",
              "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions\n",
              "36130       i just feel really helpless and heavy hearted     fear\n",
              "138065  ive enjoyed being able to slouch about relax a...  sadness\n",
              "146440  i gave up my internship with the dmrg and am f...     fear\n",
              "103337                         i dont know i feel so lost  sadness\n",
              "315528  i am a kindergarten teacher and i am thoroughl...     fear"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_MO08_KiAOb",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Pre-trained BERT model\n",
        "Let's now load a pre-trained BERT model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1InADgf5xm2",
        "colab_type": "code",
        "outputId": "5c0fc686-20a2-4e80-9859-dd8d7717a08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "ff5b29b0733e40ae8d23cce9ce4003c5",
            "48ead982f18a4eed843c44342204790c",
            "248423a2601f4880a6bffda40aea4e52",
            "719a88ea41234522bbcfb7bfb0eaf16b",
            "f8c633c1ee0c4595af1bcfbca3904214",
            "9ee12e31d1434162ac4e6a3758f4bb34",
            "38bee730feb0407b96b4a89bd2315637",
            "7d6be8dfa06845bc80d6b593251ad962",
            "0139d43b9c7c4b5b9f69e5964e97ab0e",
            "0ad76070085b48e7b6122299f11046c3",
            "935c9abafa7e44228ada7b72ece67786",
            "f3f9ecc710ea457b82484ec3cc773318",
            "50d6067328554e31a530bae8d3ef29b7",
            "9393c26f5a9c4ba98021d5e3e70fb6c2",
            "a58980e728c14e0199b74d1d0ff2be59",
            "14482ac48fc543789b1c18bb688d92ab",
            "ad8e8218675644dcba9fd996d52cf409",
            "6245b3dab75d4436ae03edb19f85ec53",
            "5973195e2f6c414d9d1f8a78cd3b2e07",
            "ace120feb3eb438b8d3a4e466804a966",
            "60f7220508c84a6b8d18fbfa2eb8362f",
            "3a72a5ded28c436d86f2e3469a8b4e35",
            "5cfc0601de7147fd8599144add31dea2",
            "8bad1a3e28054968a45702f603aae455"
          ]
        }
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "## Want Roberta instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "BertModel = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff5b29b0733e40ae8d23cce9ce4003c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0139d43b9c7c4b5b9f69e5964e97ab0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=546, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad8e8218675644dcba9fd996d52cf409",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=267967963, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDBMn3wiSX6",
        "colab_type": "text"
      },
      "source": [
        "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
        "\n",
        "## Model #1: Preparing the Dataset\n",
        "Before we can hand our sentences to BERT, we need to so some minimal processing to put them in the format it requires.\n",
        "\n",
        "### Tokenization\n",
        "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg82ndBA5xlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized = batch_1['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHwjUwYgi-uL",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\" />\n",
        "\n",
        "### Padding\n",
        "After tokenization, `tokenized` is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URn-DWJt5xhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdi7uXo95xeq",
        "colab_type": "code",
        "outputId": "ba3bfb19-a01b-429b-f520-e8184351a971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZBsYSDjzDV",
        "colab_type": "text"
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_iGRNa_Ozc",
        "colab_type": "code",
        "outputId": "b4c6b149-6d20-4a57-ee71-08083c82b531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_lf3ikyauuq",
        "colab_type": "text"
      },
      "source": [
        "Convert to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI4g5ioGatDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-CQB9-kN99",
        "colab_type": "text"
      },
      "source": [
        "## Model #1: And Now, Deep Learning!\n",
        "Now that we have our model and inputs ready, let's run our model!\n",
        "\n",
        "<img src=\"http://127.0.0.1:4000/images/distilBERT/bert-distilbert-tutorial-sentence-embedding.png\" />\n",
        "\n",
        "The `model()` function runs our sentences through BERT. The results of the processing will be returned into `last_hidden_states`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39UVjAV56PJz",
        "colab_type": "code",
        "outputId": "d9710fce-521a-4ce4-9e3f-7d51bebe776d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = BertModel(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "print('Time taken for convert tokens to BERT vectos in sec {} \\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken for convert tokens to BERT vectos in sec 34.50823092460632 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoCep_WVuB3v",
        "colab_type": "text"
      },
      "source": [
        "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />\n",
        "\n",
        "We'll save those in the `features` variable, as they'll serve as the features to our logitics regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9t60At16PVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZVU66Gurr-",
        "colab_type": "text"
      },
      "source": [
        "The labels indicating which sentence is positive and negative now go into the `labels` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3fX2yh6PTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = batch_1['emotions']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoEvM2evRx1",
        "colab_type": "text"
      },
      "source": [
        "## Model #2: Train/Test Split\n",
        "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZLGgU2AZLK5",
        "colab_type": "text"
      },
      "source": [
        "Splite features and text with the same seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddAqbkoU6PP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5nZp5-zmwNQ",
        "colab_type": "code",
        "outputId": "5feeafba-4e99-4b98-b2e9-bb8c2da239c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "test_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05213079,  0.12589307, -0.01424439, ...,  0.01280174,\n",
              "         0.39185014,  0.48322433],\n",
              "       [ 0.1126171 ,  0.04323838, -0.38042873, ..., -0.00996881,\n",
              "         0.30511034,  0.47356904],\n",
              "       [ 0.09995174, -0.00733955,  0.13381942, ..., -0.02475775,\n",
              "         0.24149266,  0.1853386 ],\n",
              "       ...,\n",
              "       [ 0.06656996,  0.02826398,  0.1483224 , ..., -0.01892123,\n",
              "         0.48214912,  0.3743777 ],\n",
              "       [-0.02894961, -0.03782853, -0.19266544, ..., -0.11153548,\n",
              "         0.25140786,  0.15073338],\n",
              "       [ 0.06396559,  0.02125023, -0.04242096, ..., -0.01619827,\n",
              "         0.25751355,  0.17458858]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "82t1I4Y1bNkd",
        "colab": {}
      },
      "source": [
        "train_texts, test_texts = train_test_split(batch_1['text'],test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGidwCeXXBUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_token_tensor, test_token_tensor, train_mask_tensor, test_mask_tensor = train_test_split(input_ids,attention_mask,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b239Cyn_Xr9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9bhSJpcv1Bl",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://127.0.0.1:4000/images/distilBERT/bert-distilbert-train-test-split-sentence-embedding.png\" />\n",
        "\n",
        "### [Bonus] Grid Search for Parameters\n",
        "We can dive into Logistic regression directly with the Scikit Learn default parameters, but sometimes it's worth searching for the best value of the C parameter, which determines regularization strength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyEwr7yYD3Ci",
        "colab_type": "code",
        "outputId": "fb2fbc70-03e7-4c51-f0d5-4c8098d9285a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        " #parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        " #grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        " #grid_search.fit(train_features, train_labels)\n",
        "\n",
        " #print('best parameters: ', grid_search.best_params_)\n",
        " #print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 5.263252631578947}\n",
            "best scrores:  0.5479999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCT9u8vAwnID",
        "colab_type": "text"
      },
      "source": [
        "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rUMKuVgwzkY",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://127.0.0.1:4000/images/distilBERT/bert-training-logistic-regression.png\" />\n",
        "\n",
        "## Evaluating Model #2\n",
        "So how well does our model do in classifying sentences? One way is to check the accuracy against the testing dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFBRi117XW9e",
        "colab_type": "code",
        "outputId": "7c06ac1f-4fac-4361-c072-6e87f41f44db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_baseline_model=lr_clf.fit(train_features, train_labels)\n",
        "lr_baseline_predicted = lr_baseline_model.predict(test_features)\n",
        "print(classification_report(test_labels, lr_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.41      0.35      0.38        26\n",
            "        fear       0.55      0.30      0.39        20\n",
            "         joy       0.68      0.72      0.70        57\n",
            "        love       0.20      0.09      0.13        11\n",
            "     sadness       0.42      0.58      0.49        45\n",
            "    surprise       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.52       160\n",
            "   macro avg       0.38      0.34      0.35       160\n",
            "weighted avg       0.51      0.52      0.50       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCoyxRJ7ECTA",
        "colab_type": "code",
        "outputId": "637f1bc1-71f1-4cb3-cb12-fec21c527a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75oyhr3VxHoE",
        "colab_type": "text"
      },
      "source": [
        "How good is this score? What can we compare it against? Let's first look at a dummy classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnwgmqNG7i5l",
        "colab_type": "code",
        "outputId": "fe977f21-0cf0-486d-a206-f99bef8f9415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.236 (+/- 0.07)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cUSyvq2XvVc",
        "colab_type": "text"
      },
      "source": [
        "Comare to simple baseline bi-gram count model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUqOKTDEX7EY",
        "colab_type": "code",
        "outputId": "598db533-bfec-4b64-feaf-2dde9b514d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.33      0.04      0.07        26\n",
            "        fear       0.50      0.05      0.09        20\n",
            "         joy       0.49      0.84      0.62        57\n",
            "        love       0.00      0.00      0.00        11\n",
            "     sadness       0.48      0.60      0.53        45\n",
            "    surprise       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.48       160\n",
            "   macro avg       0.30      0.26      0.22       160\n",
            "weighted avg       0.43      0.48      0.39       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lg4LOpoxSOR",
        "colab_type": "text"
      },
      "source": [
        "So our model clearly does better than a dummy classifier. But how does it compare against the best models?\n",
        "\n",
        "## Proper SST2 scores\n",
        "For reference, the [highest accuracy score](http://nlpprogress.com/english/sentiment_analysis.html) for this dataset is currently **96.8**. DistilBERT can be trained to improve its score on this task – a process called **fine-tuning** which updates BERT’s weights to make it achieve a better performance in this sentence classification task (which we can call the downstream task). The fine-tuned DistilBERT turns out to achieve an accuracy score of **90.7**. The full size BERT model achieves **94.9**.\n",
        "\n",
        "\n",
        "\n",
        "And that’s it! That’s a good first contact with BERT. The next step would be to head over to the documentation and try your hand at [fine-tuning](https://huggingface.co/transformers/examples.html#glue). You can also go back and switch from distilBERT to BERT and see how that works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJQuqV6cnWQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOb9fatpE22n",
        "colab_type": "text"
      },
      "source": [
        "**BERT Fine Tune**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERM6JjX9hlzq"
      },
      "source": [
        "### 2.1 Init\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X19EOhMzhpUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=64\n",
        "EPOCHS =10\n",
        "HIDDEN_SIZE=768\n",
        "\n",
        "emotions=list(set(batch_1.emotions.unique()))\n",
        "OUTPUT_DIM= len(emotions)   #num of catagories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vXDaSYi45pyS"
      },
      "source": [
        "### 2.1 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_isxcZF5xjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in batch_1[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x59I4xUZ9Lnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_tensor=torch.max(target_tensor_bin,1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Tranform labels to float\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6n_dCSxImBa5",
        "colab": {}
      },
      "source": [
        "#target_num_tensor2=torch.tensor(LabelEncoder().fit_transform(batch_1['emotions']))\n",
        "#target_tensor2 = target_num_tensor2.reshape(-1,1).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHJlv4C2fS3x",
        "colab_type": "code",
        "outputId": "3146a50f-740e-4d27-a5c6-c21c12e1f0e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "target_tensor2[0:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuHU9QRriehQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wrq1bT6CgJYT"
      },
      "source": [
        "### 2.2 Convert to tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ2zgfHeiftx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens_tensor, test_tokens_tensor, train_masks_tensor, test_masks_tensor = train_test_split(input_ids,attention_mask,test_size=0.2,random_state=42)\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kwjR-vYWhFn1"
      },
      "source": [
        "### 2.3 Build DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVZMnQTEhu4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "afdeX1jOo09n"
      },
      "source": [
        "### 2.4 Define Model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdOjCoZRo_Sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rtyU2Nr5qit7"
      },
      "source": [
        "### 2.5 BERT Fine tune Training \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOm2kYTCqoo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf = BertMultiClassifier()\n",
        "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
        "criterion = torch.nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss.  Check BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esekZbEw2Txl",
        "colab_type": "code",
        "outputId": "ad80f6fc-acce-42cf-8c95-5c387e71c6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "losses = []\n",
        "steps = []\n",
        "step = 0\n",
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        batch_loss = criterion(probas, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        \n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        \n",
        "\n",
        "        #clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"{0}/{1} loss: {2} \".format(step_num, len(train_y_tensor) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
        "        losses.append(batch_loss.item())\n",
        "        steps.append(step)\n",
        "        step += 1\n",
        "\n",
        "#convert_to_pickle(bert_clf, \"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr10epochs.pkl\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  10\n",
            "99/100.0 loss: 0.17900597363710402 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vv0JzgZmsKX2"
      },
      "source": [
        "### 2.6 Evaluation \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl70xio3sUQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        \n",
        "        bert_predicted += list(torch.max(probas,1)[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p3aouuBFYwG",
        "colab_type": "code",
        "outputId": "2b236322-de48-4d0b-82b0-943272971f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93       229\n",
            "           1       0.82      0.90      0.86       175\n",
            "           2       0.91      0.91      0.91       517\n",
            "           3       0.75      0.76      0.75       129\n",
            "           4       0.95      0.96      0.95       485\n",
            "           5       0.87      0.71      0.78        65\n",
            "\n",
            "    accuracy                           0.90      1600\n",
            "   macro avg       0.87      0.86      0.86      1600\n",
            "weighted avg       0.90      0.90      0.90      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE5qvlp_zXHo",
        "colab_type": "code",
        "outputId": "1293e539-7962-4fb9-a115-c0bddbe66eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93       229\n",
            "           1       0.82      0.90      0.86       175\n",
            "           2       0.91      0.91      0.91       517\n",
            "           3       0.75      0.76      0.75       129\n",
            "           4       0.95      0.96      0.95       485\n",
            "           5       0.87      0.71      0.78        65\n",
            "\n",
            "    accuracy                           0.90      1600\n",
            "   macro avg       0.87      0.86      0.86      1600\n",
            "weighted avg       0.90      0.90      0.90      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDJ3A5LyRTNQ",
        "colab_type": "code",
        "outputId": "1480fc78-789d-42aa-c418-fb6cb240ce1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(confusion_matrix(test_y_tensor, bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[169  14   4   4  38   0]\n",
            " [  7 142   3   0  20   3]\n",
            " [  7   5 431  48  24   2]\n",
            " [  1   2  35  84   7   0]\n",
            " [  1  18  12   5 449   0]\n",
            " [  0  16   7   1   6  35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t_vq3SGGp1GL"
      },
      "source": [
        "**Logistic Distilation with BERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY3Ld9UPLzoe",
        "colab_type": "text"
      },
      "source": [
        "Need to define class BertMultiClass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSwwEzkzL7TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertMultiClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertMultiClassifier, self).__init__()\n",
        "        # Need to define the right layer \n",
        "        self.bert = model_class.from_pretrained(pretrained_weights)\n",
        "        #self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_DIM)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = last_hidden_states[0][:,0,:]\n",
        "        #dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return linear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vA0AfhKrQKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf = load_from_pickle(\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr5epochs.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B9SxFXzOJbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OJvy3PMMe7R",
        "colab_type": "text"
      },
      "source": [
        "Bimarization of lables and create target_tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cUBKhDVBMkgM",
        "colab": {}
      },
      "source": [
        "emotions=list(set(batch_1.emotions.unique()))\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in batch_1[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFFKBTJpMww_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_tensor=torch.max(target_tensor_bin,1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrosUSumcB5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=64\n",
        "train_tokens_tensor, test_tokens_tensor, train_masks_tensor, test_masks_tensor = train_test_split(input_ids,attention_mask,test_size=0.2,random_state=42)\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=0.2,random_state=42)\n",
        "\n",
        "train_dataset_for_distill = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_dataloader_for_distill = DataLoader(train_dataset_for_distill, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP178NXud0-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf.eval()\n",
        "train_logits = []\n",
        "bert_predicted = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(train_dataloader_for_distill):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "        train_logits += list(logits)\n",
        "\n",
        "        bert_predicted += list(torch.max(logits,1)[1])\n",
        "\n",
        "#train_logits = np.vstack(train_logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw9-fSzLemKF",
        "colab_type": "code",
        "outputId": "943ce7ab-a72b-40c6-c2c7-6db071203c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(train_y_tensor, bert_predicted))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       864\n",
            "           1       0.92      0.96      0.94       754\n",
            "           2       0.97      0.96      0.97      2188\n",
            "           3       0.89      0.89      0.89       498\n",
            "           4       0.98      0.98      0.98      1866\n",
            "           5       0.90      0.87      0.88       230\n",
            "\n",
            "    accuracy                           0.96      6400\n",
            "   macro avg       0.94      0.94      0.94      6400\n",
            "weighted avg       0.96      0.96      0.96      6400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VyBgyPFjcgv",
        "colab_type": "text"
      },
      "source": [
        "**Use regression to predicte Logits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mArUUo0jX86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCk0rAESlL9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(batch_1['text'],batch_1['emotions'], test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ1cDt0Nd2gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_logits_numpy= (i.numpy() for i in train_logits)\n",
        "train_logits = np.vstack(train_logits_numpy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8YWtuGNdr5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "45a0bb38-ef71-408b-b353-342bd8db5aef"
      },
      "source": [
        "train_logits "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6896763 , -0.5345181 ,  5.1783304 , -1.7711558 , -2.2541738 ,\n",
              "         0.7234218 ],\n",
              "       [-1.8258332 , -3.205102  ,  4.873008  , -0.5550477 ,  1.0797815 ,\n",
              "        -1.4393263 ],\n",
              "       [-2.2791028 , -2.1062865 ,  5.665677  , -0.75003266, -0.7649366 ,\n",
              "        -0.8934874 ],\n",
              "       ...,\n",
              "       [-1.0118906 , -1.3638008 , -0.13120678, -0.3857909 ,  4.7568655 ,\n",
              "        -2.6017396 ],\n",
              "       [ 0.07644066,  4.6670856 , -1.1762648 , -1.2533344 , -2.2330873 ,\n",
              "         1.7640835 ],\n",
              "       [-0.9474587 , -2.4521034 ,  5.0374484 , -1.1121345 , -1.3535795 ,\n",
              "         0.43836874]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqmyIg3gjnc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distilled_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(train_texts, train_logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6svyXGKgnHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distilled_predicted_logits = distilled_model.predict(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4TRNy5RhF42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distilled_bert_predicted=torch.max(torch.tensor(distilled_predicted_logits),1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpUo3erxgm7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "38a972b3-9669-442c-f264-4cd7aad0202f"
      },
      "source": [
        "print(classification_report(test_y_tensor, distilled_bert_predicted))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86       229\n",
            "           1       0.81      0.79      0.80       175\n",
            "           2       0.79      0.94      0.86       517\n",
            "           3       0.85      0.52      0.64       129\n",
            "           4       0.88      0.91      0.90       485\n",
            "           5       0.87      0.52      0.65        65\n",
            "\n",
            "    accuracy                           0.84      1600\n",
            "   macro avg       0.86      0.75      0.79      1600\n",
            "weighted avg       0.85      0.84      0.84      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJOxtpcXkMcm",
        "colab_type": "code",
        "outputId": "f4fb3ca9-ee4e-4f1b-852f-160039d1826e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor, distilled_bert_predicted))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86       229\n",
            "           1       0.81      0.79      0.80       175\n",
            "           2       0.79      0.94      0.86       517\n",
            "           3       0.85      0.52      0.64       129\n",
            "           4       0.88      0.91      0.90       485\n",
            "           5       0.87      0.52      0.65        65\n",
            "\n",
            "    accuracy                           0.84      1600\n",
            "   macro avg       0.86      0.75      0.79      1600\n",
            "weighted avg       0.85      0.84      0.84      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY11TYZFj22i",
        "colab_type": "code",
        "outputId": "0f4d19da-ae84-4ccc-b8a0-e1c309ee14c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(train_logits[:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 409., 1688.,  705.,  923., 1109.,  574.,  223.,  258.,  273.,\n",
              "         238.]),\n",
              " array([-2.459845  , -1.8476666 , -1.2354882 , -0.6233098 , -0.01113138,\n",
              "         0.60104704,  1.2132255 ,  1.8254039 ,  2.4375823 ,  3.0497608 ,\n",
              "         3.6619391 ], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYuhLUkcMfUnqiKEvSR35//ouA1oTPogUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1taE8wEoKz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gwGXcoZ3oCuK"
      },
      "source": [
        "**Use unlabeled data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXpSHH1noMHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_data = data.sample(n=8000, random_state=42);     \n",
        "train_texts, test_texts = train_test_split(labeled_data['text'],test_size=0.2,random_state=42)\n",
        "\n",
        "all_ulabeled_data = data.drop(labeled_data.index)['text']\n",
        "\n",
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "#all_ulabeled_data[\"token_size\"] = all_ulabeled_data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "#all_ulabeled_data = all_ulabeled_data.loc[all_ulabeled_data['token_size'] <= 70].copy()\n",
        "\n",
        "unlabeled_texts=all_ulabeled_data.sample(n=64000, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35pBsX9hakPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in labeled_data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_emotions.tolist())\n",
        "\n",
        "target_tensor=torch.max(target_tensor_bin,1)[1]\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=0.2,random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc-yPXRQy2OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_tokenized = unlabeled_texts.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfICfmOEzD67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in unlabeled_tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "unlabeled_padded = np.array([i + [0]*(max_len-len(i)) for i in unlabeled_tokenized.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OitY9rcuzMWM",
        "colab_type": "code",
        "outputId": "c343390f-1e50-4d81-f764-b768739f1b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "unlabeled_attention_mask = np.where(unlabeled_padded != 0, 1, 0)\n",
        "unlabeled_attention_mask.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64000, 185)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsKZOj6zY59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_input_ids = torch.tensor(unlabeled_padded)  \n",
        "unlabeled_attention_mask = torch.tensor(unlabeled_attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU1zxPb6zwIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_tokens_tensor = torch.tensor(unlabeled_input_ids)\n",
        "unlabeled_masks_tensor = torch.tensor(unlabeled_attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO1DlO9n0Q90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=64\n",
        "unlabeled_dataset = TensorDataset(unlabeled_tokens_tensor, unlabeled_masks_tensor)\n",
        "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHNpZ5M0mez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8257b3d-8816-47a9-9486-a0e57773df62"
      },
      "source": [
        "bert_clf.eval()\n",
        "unlabeled_logits = []\n",
        "#unlabeled_bert_predicted = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(unlabeled_dataloader):\n",
        "\n",
        "        token_ids, masks = tuple(t for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "        unlabeled_logits += list(logits)\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        print(\"{0}/{1}\".format(step_num, len(unlabeled_dataset) / BATCH_SIZE))\n",
        "\n",
        "        #unlabeled_bert_predicted += list(torch.max(logits,1)[1])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "999/1000.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF47sfDA2aFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_logits_numpy= (i.numpy() for i in unlabeled_logits)\n",
        "unlabeled_logits = np.vstack(unlabeled_logits_numpy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz_VnnX91GNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(unlabeled_texts, unlabeled_logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmaKwujU1Ljl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_predicted_logits = unlabeled_model.predict(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaaUhkXx461Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_bert_predicted=torch.max(torch.tensor(unlabeled_predicted_logits),1)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SADVrOW5CRk",
        "colab_type": "code",
        "outputId": "d38871a9-81dd-42d8-d571-3a7e45a8a3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(test_y_tensor,unlabeled_bert_predicted))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83       229\n",
            "           1       0.75      0.73      0.74       175\n",
            "           2       0.79      0.92      0.85       517\n",
            "           3       0.81      0.53      0.64       129\n",
            "           4       0.85      0.93      0.89       485\n",
            "           5       0.85      0.34      0.48        65\n",
            "\n",
            "    accuracy                           0.82      1600\n",
            "   macro avg       0.83      0.70      0.74      1600\n",
            "weighted avg       0.83      0.82      0.81      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bF0CbciFhJ02"
      },
      "source": [
        "**Use unlabeled data (load from pkl)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27eBD2Zbmwpr",
        "colab_type": "text"
      },
      "source": [
        "Init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cybgMdaEp-XL",
        "colab_type": "text"
      },
      "source": [
        "Init/Load logits for labeled and unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE9k0NZqNDMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert_to_pickle([train_logits, unlabeled_logits], \"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr10epochsLogistList.pkl\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2P-nz8AbT-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_logits_load, unlabeled_logits_load = load_from_pickle(\"/gdrive/My Drive/Colab Notebooks/DAIR/EmotionDataSet/DistilBERTfineTune6400tr10epochsLogistList.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3kzujX8qLHL",
        "colab_type": "text"
      },
      "source": [
        "Init/Set train/test texts and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghEquYptn3k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(batch_1['text'], batch_1['emotions'],test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5joH5Wipzal",
        "colab_type": "text"
      },
      "source": [
        "Init/Build train_y_tensor and test_y_tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPOudbwQpRJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotions=list(set(batch_1.emotions.unique()))\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in batch_1[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor_bin = torch.tensor(bin_emotions.tolist())\n",
        "target_tensor=torch.max(target_tensor_bin,1)[1]\n",
        "train_y_tensor, test_y_tensor  = train_test_split(target_tensor,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVtGjEc6mKoR",
        "colab_type": "text"
      },
      "source": [
        "Simple regression - baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FvU9B4QmVu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngramCount_baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)\n",
        "ngramCount_baseline_predicted = ngramCount_baseline_model.predict(test_texts)\n",
        "print(classification_report(test_labels, ngramCount_baseline_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co5kizj3mrPo",
        "colab_type": "text"
      },
      "source": [
        "Distill with training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk96hkalmV0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distilled_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LinearRegression()).fit(train_texts, train_logits)\n",
        "distilled_predicted_logits = distilled_model.predict(test_texts)\n",
        "distilled_bert_predicted=torch.max(torch.tensor(distilled_predicted_logits),1)[1]\n",
        "print(classification_report(test_y_tensor, distilled_bert_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlmjlC_7qiy2",
        "colab_type": "text"
      },
      "source": [
        "Distill with 6400 unlabeled samples "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGxDvMWMqvfd",
        "colab_type": "text"
      },
      "source": [
        "Distill with 12800 unlabeled samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfbsSdA8q0Rt",
        "colab_type": "text"
      },
      "source": [
        "Distill with 6400 unlabeled samples + training "
      ]
    }
  ]
}